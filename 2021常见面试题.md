# 常见面试题

## Java基础

* **jdk8的新特性**

* **== 和 equals()区别**

  ==：对于基本数据类型比较的是值是否相等；

  ​		对于引用数据类型比较的是内存地址是否相同；

  equals(): 只有引用类型有意义；属于Object的方法，当中就是==比较，但是如String类重写了此方法，比较的是值

* **两个对象的hashCode()相同，则equals()也一定为true吗**

  （谈重写hashcode是针对映射相关的操作（Map接口））

  两个对象equals返回true，那么hashcode一定相等；两个对象的hashcode相等，那么equals不一定为true。
  重写equals()方法，则hashCode()方法也必须重写，这样才能保证equals()方法返回true时，hashcode的值相等。

* **java是值传递还是引用传递**

  1.这个题目出的不严谨，但是很好(因为涉及了 Java 内存模型)
  2.就 Java 语言本身来说，只有值传递，没有引用传递。
  3.根据 值传递，引用传递的定义来说：
          Java 中的基本类型，属于值传递。
          Java 中的引用类型，属于引用传递。
          Java 中的 String 及包装类，属于特殊群体，作为形参时，由于每次赋值都相当于重新创建了对象，因此看起来像值传递，但是其特性已经破坏了，值传递、引用传递的定义。因此他们属于引用传递的定义，却表现为值传递。

* **关键字**

  * **final**

  1、用来修饰一个引用
   如果引用为基本数据类型，则该引用为常量，该值无法修改；
   如果引用为引用数据类型，比如对象、数组，则该对象、数组本身可以修改，但指向该对象或数组的地址的引用不能修改。
   如果引用时类的成员变量，则必须当场赋值，否则编译会报错。

   2.用来修饰一个方法
      当使用final修饰方法时，这个方法将成为最终方法，无法被子类重写。但是，该方法仍然可以被继承。

  3.用来修饰类
   当用final修改类时，该类成为最终类，无法被继承。简称为“断子绝孙类”。

  * **transient**

    1.只能修饰变量，而不能修饰方法和类。注意，本地变量是不能被transient关键字修饰的。变量如果是用户自定义类变量，则该类需要实现Serializable接口。

    2.被transient修饰的变量不参与对象的序列化和反序列化

    3.static修饰的变量无论有没有被transient修饰都不参与序列化和反序列化，因static修饰的变量属于类，不属于对象。

    2的例外：

    ​	java中有两种序列化的方式。

    1. 实现Serializable接口。

       ​	不需要默认空参构造器。

       ​	有两种方式：

       ​	a，无需任何，所有没被transient修饰的字段都参与序列化

       ​	b，编写私有无返回方法，指定哪些字段参与。

       ```java
       	private void writeObject(ObjectOutputStream oos) throws IOException {
       		// oos.defaultWriteObject();
       		oos.writeObject(name);
       		oos.writeObject(isbn);
       	}
       
       	private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException {
       		// ois.defaultReadObject();
       		name = (String) ois.readObject();
       		isbn = (String) ois.readObject();
       	}
       ```

    2. 实现Externalizable接口。

       ​	需要默认空参构造器。

       ```java
       public interface Externalizable extends java.io.Serializable {
        
           void writeExternal(ObjectOutput out) throws IOException;
       
          
           void readExternal(ObjectInput in) throws IOException, ClassNotFoundException;
       }
       ```

       需要实现两个方法来指定需要序列化的字段。被transient修饰也没有

* **java中 Math.round（-1.5）等于多少**

  -1。四舍五入。

* **java中操作字符串的类有哪些，之间的区别**

  String 声明的是不可变的对象，每次操作都会生成新的 String 对象

  StringBuffer、StringBuilder 可以在原有对象的基础上进行操作,前者线程安全适合多线程中，后者线程不安全，多在单线程中使用

* **String str = “i" 和 String str = new String（"i"）一样吗**

  通过字面量的方式。先看常量池中是否已经存在相同字符串 (equals())，若存在，返回常量池中的引用。若不存在，在常量池中创建字符串对象并返回其引用。

  通过显式创建字符串对象的方式。先在堆中创建一个对象。再看常量池中是否已经存在相同字符串，若存在，直接返回堆中的引用。若不存在，在常量池中创建字符串对象并返回堆中的引用。

* **如何实现字符串的反转**

  ```java
      public static String reverse1(String str) {
          return new StringBuilder(str).reverse().toString();
      }
      public static String reverse2(String str) {
          String rs = "";
          char[] chars = str.toCharArray();
          for (int i = 0; i < chars.length; i++) {
              rs = chars[i] + rs;
          }
          return rs;
      }
      public static String reverse3(String str) {
          String reverse = "";
          int length = str.length();
          for (int i = 0; i < length; i++) {
              reverse = str.charAt(i) + reverse;
          }
          return reverse;
      }
  ```

  

* **String类常用的方法有哪些**

  equals：字符串是否相同
  equalsIgnoreCase：忽略大小写后字符串是否相同
  compareTo：根据字符串中每个字符的Unicode编码进行比较
  compareToIgnoreCase：根据字符串中每个字符的Unicode编码进行忽略大小写比较
  indexOf：目标字符或字符串在源字符串中位置下标
  lastIndexOf：目标字符或字符串在源字符串中最后一次出现的位置下标
  valueOf：其他类型转字符串
  charAt：获取指定下标位置的字符
  codePointAt：指定下标的字符的Unicode编码
  concat：追加字符串到当前字符串
  isEmpty：字符串长度是否为0
  contains：是否包含目标字符串
  startsWith：是否以目标字符串开头
  endsWith：是否以目标字符串结束
  format：格式化字符串
  getBytes：获取字符串的字节数组
  getChars：获取字符串的指定长度字符数组
  toCharArray：获取字符串的字符数组
  join：以某字符串，连接某字符串数组
  length：字符串字符数
  matches：字符串是否匹配正则表达式
  replace：字符串替换
  replaceAll：带正则字符串替换
  replaceFirst：替换第一个出现的目标字符串
  split：以某正则表达式分割字符串
  substring：截取字符串
  toLowerCase：字符串转小写
  toUpperCase：字符串转大写
  trim：去字符串首尾空格

* **抽象类必须有抽象的方法吗**

  no，但是如果一个类包含抽象方法，则该类必须是抽象类

* **普通类和抽象类的区别**

  抽象类不能被实例化；

  抽象方法不能被private、final、static修饰（被static修饰的方法不能被重写）

* **接口和抽象类有什么区别**

  抽象类：可以有非抽象的方法，可以提高代码的复用性，这是抽象类的优势；

  接口：只能有抽象方法；

  java单继承、多实现。

* **java中IO流分为几种**

  字节bai流类
  抽象父类： InputStream,OutputStream

  字符流
  抽象父类：Reader, Writer

  一般操作流的步骤：
  （1）创建源
  （2）选择流
  （3）操作流（读取|写出）
  （4）释放资源

* **BIO、NIO、AIO有什么区别**

  Java 中的 BIO、NIO和 AIO 理解为是 Java 语言对操作系统的各种 IO 模型的封装。

  举个生活中简单的例子，你妈妈让你烧水，小时候你比较笨啊，在哪里傻等着水开（**同步阻塞**）。等你稍微再长大一点，你知道每次烧水的空隙可以去干点其他事，然后只需要时不时来看看水开了没有（**同步非阻塞**）。后来，你们家用上了水开了会发出声音的壶，这样你就只需要听到响声后就知道水开了，在这期间你可以随便干自己的事情，你需要去倒水了（**异步非阻塞**）。

  BIO-同步阻塞 适合活动链接数不高

  NIO-同步非阻塞

  AIO-（NIO 2 jdk 7）异步非阻塞

  [详细内容参考](https://blog.csdn.net/m0_38109046/article/details/89449305)

* **创建对象的几种方式**

  创建对象的方式：new、反射、clone()，反序列化、第三方库

* **Java 数组最大长度**
  库函数里的数组最大数量都是指定为Integer.MAX_VALUE-8。按注释所说，8是为对象头预留的，对象头在64位虚拟机下占16个字节，8一定不是指字节数，如果指的是字长，那么这个数字应该是可以更小的。

* **String有最大长度限制吗？**

  String 的长度是有限制的。

  - 编译期的限制：字符串的UTF8编码值的字节数不能超过65535，字符串的长度不能超过65534；

  - 运行时限制：字符串的长度不能超过2^31-1，占用的内存数不能超过虚拟机能够提供的最大值。

    

## JVM

* **JVM内存模型**

  1.堆
  Java虚拟机所管理内存中的最大的一块，在虚拟机启动时创建，被所有线程共享。
  2.虚拟机栈

  （其中有局部变量表

  操作数栈

  动态链接）

  虚拟机栈是一个线程执行的区域，保存着一个线程中方法的调用状态。虚拟机栈式线程所私有的，独有的，随着线程的创建而创建。每一个线程执行的方法，为该栈中的栈帧，即每一个方法对应一个栈帧。
  3.方法区

  Person p = new Person()

  方法区 栈  堆

  方法区是所有线程所共享的内存区域，在虚拟机启动的时候创建。保存类信息，静态变量
  4.程序计数器
  程序技术器占用的内存空间很小，在任意时刻，一个处理器只会执行一条线程中的指令，因此，为了线程切换后能够恢复到正确的执行位置，每条线程需要有一个独立的程序计数器（线程私有）。如果线程正在执行Java方法，则程序计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，则这个计数器为空。
  5.本地方法栈
  如果当前线程执行的方法是Native类型，这些方法就会在本地方法栈中执行

* **JVM三种运行模式：**

  　　解释模式（Interpreted Mode）：只使用解释器（-Xint强制JVM使用解释模式），执行一行JVM字节码就编译一行为机器码。（可以马上看到效果，但是运行过程比较慢）

    　　编译模式（Compiled Mode）：（也叫即时编译技术JIT）只使用编译器（-Xcomp强制JVM使用编译模式），先将所有JVM字节码一次性编译为机器码，然后一次性执行所有机器码。（启动时间比较长，但是运行过程快）

    　　混合模式（Mixed Mode）：依然使用解释模式执行代码，但是对于一些“热点”代码采用编译模式，JVM一般采用混合模式执行代码。即引入了两种即使编译器：C1 C2。C1编译器称为client编译器，面向对启动性能有要求的用户端，编译时间段，优化策略简单；C2称为Serve驳岸一起面向对峰值性能有要求的服务器端，编译时间长，优化策略复杂。具体的在编译热点方法的时候先采用C1编译器，热点方法中的热点方法会被C2编译器再次编译。

  c1优化弱，但是更快编译。c2，编译久，优化后效率更高。

  hotspot是两者都用。解释器可以先不用等待代码全部编译好，省去等待时间，而随着时间，代码编译好，转化为编译执行。并且当编译执行的优化失败，可以回到解释执行。

  什么时候用编译执行？热点探测。栈上替换（OSR）编译。

  热点？hotspot VM通过基于计数器进行热点探测：

  方法调用计数器：统计方法调用次数

  回边计数器：统计循环体执行的循环次数

* **GC机制和原理**[详细参考](https://www.cnblogs.com/dmzna/archive/2020/05/18/12913458.html)

  - 发生区域

    堆

  - 堆内存结构

    在JDK1.8之后，堆的永久区取消了由元空间取代

    Java将堆内存分为：新生代 8:1:1（Eden、S0、S1(Survivor)三个区、老年代

    1.为什么有Survivor区？减少对象进入老年代，减少FullGC。这样设计可以使对象每熬过一次GC，增加一个年龄，到达设定值才进入老年代。

    2.为什么Survivor是两个？根据其原理，可解决内存碎片导致内存不连续的问题。

    3.为什么Survivor不是多个？会导致每个Survivor都很小，容易满。

  - 堆内存上对象的分配与回收

    可设置-XX:PretenureSizeThreadhold参数，令大于这个参数值的对象直接在老年代中分配，避免在Eden区和两个Survivor区发生大量的内存拷贝。

    YGC（MinorGC）：频繁发生，速度快

    ​	发生在新生代。

    ​	Eden空间不足的时候发生；

    ​	一次长一岁，默认15岁，去老年代。-XX:MaxTenuringThreshold设置晋升年龄。

    ​	动态对象年龄判定：

    ​		如果Survivor空间中相同年龄所有对象的大小总和大于Survivor空间的一半，那么年龄大于等于该对象年龄的对象即可晋升		到老年代，不必要等到-XX:MaxTenuringThreshold。

    ​	空间分配担保：

    ​		发生Minor GC时，虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代的剩余空间大小。如果大于，则进行一次		Full GC（老年代GC），如果小于，则查看HandlePromotionFailure设置是否允许担保失败，如果允许，那只会进行一次		Minor GC，如果不允许，则改为进行一次Full GC。

    *（可忽略）MajorGC：很少发生，速度慢

    ​	发生在老年代。发年代空间不足时发生。

    FullGC：很少发生，速度慢

    ​	看作包含以上两种GC。发生Full GC一般都会有一次Minor GC。

    ​	1.System.gc()方法的调用，此方法是建议JVM进行Full GC,虽然只是建议而非一定

    ​	2.老年代的内存空间不足

    ​	3.当Minor GC时，老年代的剩余空间小于历次从新生代往老年代中移的对象的平均内存空间大小时

    ​	4.方法区内存不足：JDK7包含7有永久代

    ​	5.堆中分配很大的对象。虽有足够空间，但是没有足够大的连续空间。

  - 标记阶段算法

    为了解决**JVM如何判定一个对象是否应该被回收**

    引用计数法：
    是一种比较古老的回收算法。原理是此对象有一个引用，即增加一个计数，删除一个引用则减少一个计数。垃圾回收时，只需要收集计数为0的对象。

    优点：实现简单，垃圾对象便于标识；判定效率高，回收没有延迟性

    缺点：1、需要计数器额外占用空间；2、需要加减越算，增加时间复杂度3、（最重要的）无法解决循环引用的问题。所以java中没有使用该算法。

    可达性分析算法：

    以根节点GC Roots为起始点，按照从上而下的方式搜索被根对象集合所连接的目标对象是否可达。

  - 清楚阶段算法

    标记-清除算法（Mark-Sweep）：

    第一阶段：从引用根节点开始标记所有被引用的对象，

    第二阶段：遍历整个堆，把未标记的对象清除。此算法需要暂停整个应用，并且会产生内存碎片。

    缺点：执行效率不稳定，会因为对象数量增长，效率变低，清除后内存不连续，产生内存碎片。需要维护一个空闲列表。

    优点：简单

    复制（Copying）算法：

    复制算法把内存空间划为两个相等的区域，每次只使用其中一个区域。垃圾回收时，遍历当前使用区域，把正在使用中的对象复制到另外一个区域中。复制算法每次只处理正在使用中的对象，因此复制成本比较小，同时复制过去以后还能进行相应的内存整理，不会出现“碎片”问题。当然，此算法的缺点也是很明显的，就是需要两倍内存空间。

    优点：没有标记和清除过程，实现简单，运行高效；空间连续，不会有碎片问题。
    缺点：需要两倍内存空间。如果系统中存活对象特别多，这个算法也不理想。

    标记-压缩（标记-整理，Mark-Compact）算法：

    标记-整理算法结合了“标记-清除”和“复制”两个算法的优点。也是分两阶段，

    第一阶段从根节点开始标记所有被引用对象，

    第二阶段遍历整个堆，清除未标记对象并且把存活对象“压缩”到堆的其中一块，按顺序排放。此算法避免了“标记-清除”的碎片问题，同时也避免了“复制”算法的空间问题。

    优点：内存连续，分配新对象，jvm只需要持有一个内存的起始地址即可。不必内存减半
    缺点：相比其他效率最差。移动对象时，如果对象被其他对象引用，则还需要调整引用的地址；移动过程中，需要暂停用户应用程序。即STW

    最好的算法？
    分代收集算法：
    年轻代：朝生夕死，存活率低，回收频繁。复制算法
    老年代：多数都是存活的，回收不频繁，标记清除或标记清除和标记整理混合使用
    Mark阶段的开销与存活对象数量成正比；
    Sweep阶段的开销与所管理的区域的大小成正相关。
    Compact阶段的开销与存活对象的数据成正比。
    增量收集算法：分阶段标记-清除和标记-整理，不用Stop the World
    缺点是线程转换，上下文转换，成本上升，系统吞吐量下降
    分区算法
    将堆空间划分为连续的独立的小空间，每个小区间独立使用独立回收
    好处：可以控制一次回收多少个小区间

* **垃圾收集器**

  ![](https://img2020.cnblogs.com/blog/1863208/202005/1863208-20200518221710647-576582447.png)

  * **1、Serial收集器：**

    Serial收集器是**一个单线程的垃圾收集器**，并且在执行垃圾回收的时候需要 **Stop The World**。虚拟机运行在**Client模式**下的默认新生代收集器。Serial收集器的优点是简单高效，对于限定在单个CPU环境来说，Serial收集器没有多线程交互的开销。缺点：交互较强的应用不行，STW久

    复制算法

    **2、Serial Old收集器：**

    Serial Old是Serial收集器的老年代版本，也是**一个单线程收集器**。主要也是给在Client模式下的虚拟机使用。在Server模式下存在主要是做为CMS垃圾收集器的后备预案，**当CMS并发收集发生Concurrent Mode Failure时使用。**

    标记-整理

    **3、ParNew收集器：**

    ParNew是Serial收集器的**多线程**版本，新生代是并行的（多线程的），可以使用参数：**-XX：UseParNewGC使用该收集器，使用 -XX：ParallelGCThreads可以限制线程数量。**

    复制算法

    **4、Parallel Scavenge垃圾收集器：**

    Parallel Scavenge是一种新生代收集器，而且是**并行的多线程收集器。**Paralle收集器特点是更加关注吞吐量（吞吐量就是cpu用于运行用户代码的时间与cpu总消耗时间的比值）。可以通过**-XX:MaxGCPauseMillis参数控制最大垃圾收集停顿时间；通过-XX:GCTimeRatio参数直接设置吞吐量大小；通过-XX:+UseAdaptiveSizePolicy参数可以打开GC自适应调节策略，**该参数打开之后虚拟机会根据系统的运行情况收集性能监控信息，动态调整虚拟机参数以提供最合适的停顿时间或者最大的吞吐量。**自适应调节策略**是Parallel Scavenge收集器和ParNew的主要区别之一。

    复制算法

    **5、Parallel Old收集器：**

    Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和标记-整理算法。

    **6、CMS（Concurrent Mark Sweep）收集器（并发标记清除）**

  CMS收集器是**一种以获取最短回收停顿时间为目标**的收集器。CMS收集器是基于**标记-清除算法**实现的，是一种老年代收集器，通常与**ParNew**一起使用。

  **CMS的垃圾收集过程分为4步：**

  - **初始标记**：需要“Stop the World”，初始标记仅仅只是标记一下GC Root能直接关联到的对象，速度很快。

    - **并发标记**：是主要标记过程，这个标记过程是和用户线程并发执行的。

  - **重新标记**：需要“Stop the World”，为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录（停顿时间比初始标记长，但比并发标记短得多）。

    - **并发清除**：和用户线程并发执行的，基于标记结果来清理对象。

     ![img](https://img2020.cnblogs.com/blog/1863208/202005/1863208-20200518221735413-1771145268.png)

     

     

    那么问题来了，**如果在重新标记之前刚好发生了一次MinorGC，会不会导致重新标记阶段Stop the World时间太长？**

    答：不会的，在并发标记阶段其实还包括了一次并发的**预清理阶段**，虚拟机会主动**等待年轻代发生垃圾回收**，这样可以将重新标记对象引用关系的步骤放在并发标记阶段，有效降低重新标记阶段Stop The World的时间。

    #### **CMS垃圾回收器的优缺点分析：**

    CMS以降低垃圾回收的停顿时间为目的，很显然其具有并发收集，停顿时间低的优点。

    #### **缺点主要包括如下：**

    - **对CPU资源非常敏感**，因为并发标记和并发清理阶段和用户线程一起运行，当CPU数变小时，性能容易出现问题。

  - 收集过程中会产生**浮动垃圾**，所以不可以在老年代内存不够用了才进行垃圾回收，必须提前进行垃圾收集。通过参数**-XX:CMSInitiatingOccupancyFraction**的值来控制内存使用百分比。如果该值设置的太高，那么在CMS运行期间预留的内存可能无法满足程序所需，会出现**Concurrent Mode Failure失败，之后会临时使用Serial Old收集器做为老年代收集器**，会产生更长时间的停顿。

    - **标记-清除方式会产生内存碎片**，可以使用参数**-XX：UseCMSCompactAtFullCollection**来控制是否开启内存整理（无法并发，默认是开启的）。参数**-XX:CMSFullGCsBeforeCompaction**用于设置执行多少次不压缩的Full GC后进行一次带压缩的内存碎片整理（默认值是0）。

    接下来，我们先看下上边介绍的浮动垃圾是怎么产生的吧。

    **浮动垃圾：**

    由于在应用运行的同时进行垃圾回收，所以有些垃圾可能在垃圾回收进行完成时产生，这样就造成了**“Floating Garbage”**，这些垃圾需要在下次垃圾回收周期时才能回收掉。所以，**并发收集器一般需要20%的预留空间**用于这些浮动垃圾。

    并发标记阶段如果产生新垃圾，无法对其标记。只能下次gc了。（Remark是把之前标记为垃圾的，修改为不是垃圾，而不是垃圾的，没有处理）

    **7、G1（Garbage-First）收集器：**

  G1收集器将新生代和老年代取消了，取而代之的是**将堆划分为若干的区域**，每个区域都可以根据需要扮演新生代的Eden和Survivor区或者老年代空间，仍然属于分代收集器，区域的一部分包含新生代，新生代采用复制算法，老年代采用标记-整理算法。

  通过**将JVM堆分为一个个的区域（region）**,G1收集器可以避免在Java堆中进行全区域的垃圾收集。G1跟踪各个region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次**根据回收时间来优先回收价值最大的region。**

    **G1收集器的特点：**

    - **并行与并发**：G1能充分利用多CPU，多核环境下的硬件优势，来缩短Stop the World，是并发的收集器。

  - **分代收集**：G1不需要其他收集器就能独立管理整个GC堆，能够采用不同的方式去处理新建对象、存活一段时间的对象和熬过多次GC的对象。

    - **空间整合**：G1从整体来看是基于标记-整理算法，从局部（两个Region）上看基于复制算法实现，G1运作期间不会产生内存空间碎片。
    - **可预测的停顿**：能够建立可以预测的停顿时间模型，预测停顿时间。

    **和CMS收集器类似，G1收集器的垃圾回收工作也分为了四个阶段：**

    - 初始标记
    - 并发标记
    - 最终标记
    - 筛选回收

    其中，筛选回收阶段首先对各个Region的回收价值和成本进行计算，根据用户期望的GC停顿时间来制定回收计划。

    java -XX:+PrintCommandLineFlags -version

    jdk1.8默认的新生代垃圾收集器：Parallel Scavenge，老年代：Parallel Old

    jdk1.9 默认垃圾收集器G1

* **JVM中几种classloader，为什么会有多种**

  启动类加载器（Bootstrap ClassLoader 根加载器）

  ​	它用来加载 Java 的核心类，是用原生代码来实现的，并不继承自 java.lang.ClassLoader（负责加载$JAVA_HOME中jre/lib/rt.jar里所有的class，由C++实现，不是ClassLoader子类）。由于引导类加载器涉及到虚拟机本地实现细节，开发者无法直接获取到启动类加载器的引用，所以不允许直接通过引用进行操作。

  扩展类加载器（Extension ClassLoader）

  ​	它负责加载JRE的扩展目录，lib/ext或者由java.ext.dirs系统属性指定的目录中的JAR包的类。由Java语言实现，父类加载器为null。继承抽象类ClassLoader

  应用程序类加载器(Application ClassLoader也叫系统类加载器 System ClassLoader)

  ​	负责加载用户类路径(classpath)上的指定类库，我们可以直接使用这个类加载器。一般情况，如果我们没有自定义类加载器默认就是用这个加载器。

  ​	还可以自定义类加载器

  1.加载

  ​	指的是将类的class文件读入到内存，并为之创建一个java.lang.Class对象

      类的加载由类加载器完成，类加载器通常由JVM提供，这些类加载器也是前面所有程序运行的基础，JVM提供的这些类加载器通常被称为系统类加载器。除此之外，开发者可以通过继承ClassLoader基类来创建自己的类加载器。
      
      通过使用不同的类加载器，可以从不同来源加载类的二进制数据，通常有如下几种来源。

  2.链接

  ​	验证：

  ​	准备：类准备阶段负责为类的静态变量分配内存，并设置默认初始值。

  ​	解析

  3.初始化

  ​	初始化是为类的静态变量赋予正确的初始值，准备阶段和初始化阶段看似有点矛盾，其实是不矛盾的，如果类中有语句：private static int a = 10，它的执行过程是这样的，首先字节码文件被加载到内存后，先进行链接的验证这一步骤，验证通过后准备阶段，给a分配内存，因为变量a是static的，所以此时a等于int类型的默认初始值0，即a=0,然后到解析（后面在说），到初始化这一步骤时，才把a的真正的值10赋给a,此时a=10。

* **类加载 过程**

  类加载器加载Class大致要经过如下8个步骤：

  检测此Class是否载入过，即在缓冲区中是否有此Class，如果有直接进入第8步，否则进入第2步。
  如果没有父类加载器，则要么Parent是根类加载器，要么本身就是根类加载器，则跳到第4步，如果父类加载器存在，则进入第3步。
  请求使用父类加载器去载入目标类，如果载入成功则跳至第8步，否则接着执行第5步。
  请求使用根类加载器去载入目标类，如果载入成功则跳至第8步，否则跳至第7步。
  当前类加载器尝试寻找Class文件，如果找到则执行第6步，如果找不到则执行第7步。
  从文件中载入Class，成功后跳至第8步。

* **类记载机制**

  全盘负责：所谓全盘负责，就是当一个类加载器负责加载某个Class时，该Class所依赖和引用其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入。
  双亲委派：所谓的双亲委派，则是先让父类加载器试图加载该Class，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类。通俗的讲，就是某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父加载器，依次递归，如果父加载器可以完成类加载任务，就成功返回；只有父加载器无法完成此加载任务时，才自己去加载。
  缓存机制。缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区中搜寻该Class，只有当缓存区中不存在该Class对象时，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓冲区中。这就是为很么修改了Class后，必须重新启动JVM，程序所做的修改才会生效的原因。

* **什么是双亲委派机制？介绍一下运作流程，双亲委派模型的好处，什么情况下需要破坏双亲委派模型**

  * 双亲委派机制：

  <img src="https://images2015.cnblogs.com/blog/731716/201607/731716-20160701132830015-300463923.png" style="zoom:50%;" />

  上图展示的类加载器之间的这种层次关系，称为类加载器的双亲委派模型。双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。这里类加载器之间的父子关系一般不会以继承的关系来实现，而是都使用组合关系来复用父加载器的代码。

  * 好处

    1.避免类的重复加载（父加载器加载过，就不用再加载）

    2.可以防止核心API库被随意篡改。

  * 破坏双亲委派模型

    打破双亲委派机制则不仅要继承ClassLoader类，还要重写loadClass和findClass方法。

    使用线程上下文类加载器

    第一次被破坏

    ​	因为双亲委派模型是JDK1.2之后才被引入，而类加载器和抽象类java.lang.ClassLoader则在JDK1.0时就已经存在，所以在面对已存在的用户自定义类加载器的实现代码时，Java设计者引入双亲委派模型时不得不做出一些妥协。在此之前，用户去继承java.lang.ClassLoader的唯一目的就是为了重写loadClass()方法，这是源于虚拟机进行类加载的时候会调用加载器的私有方法loadClassInternal()，而这个方法的唯一逻辑就是去调用自己的loadClass()。

    第二次被破坏

    ​	如JNDI服务，使用线程上下文类加载器

    第三次被破坏

    ​	由于用户对程序的动态性的追求导致的，例如OSGi的出现。在OSGi环境下，类加载器不再是双亲委派模型中的树状结构，而是进一步发展为网状结构。

* **java的引用类型**

  强引用StrongReference：类似：Object o = new Object(),只有引用在，就不会被回收

  软引用SoftReference 内存溢出前，考虑回收。即，内存不足即回收。不一定是oom才回收

  弱引用WeakReference 垃圾收集器收集就回收。

  虚引用PhantomReference 无法获得一个对象实例。唯一目的是，它被收集时收到一个系统通知

* **常见的JVM调优工具有哪些**

  Jconsole : jdk自带，功能简单，但是可以在系统有一定负荷的情况下使用。对垃圾回收算法有很详细的跟踪。详细说明参考这里

  JProfiler：商业软件，需要付费。功能强大。详细说明参考这里

  VisualVM：JDK自带，功能强大，与JProfiler类似。推荐。

* **常见的JVM调优方法有哪些，可以具体到调整哪个参数，调成什么值**

  * 查出问题

    内存：检查内存释放情况、老年代年轻代分配是否合理、内存泄露、垃圾回收算法是否合理

    线程：线程状态监控、死锁。

    热点分析：

    ​	CPU热点：那些方法占用CPU时间多、

    ​	内存热点：那些对象占用内存多

  * 解决问题

    * 将新对象预留在新生代

    * 将大对象放入老年代：因为大对象进入新生代，放不下会导致小对象进入老年代，扰乱了GC。

    * 设置对象进入老年代的合适年龄

    * 稳定与震荡的堆大小。稳定的堆大小对垃圾回收是有利的，获得一个稳定堆大小的方法就是设置 -Xmx 和 -Xms 一样的值。不稳定的堆也不是木有用处，让堆大小在一个区间内震荡，在系统不需要使用大内存时压缩堆空间，使 GC 应对一个较小的堆，可以加快单次 GC 的速度。基于这种思想，JVM 提供了两个参数用于压缩和扩展堆空间，参数如下：

      -XX：MinHeapFreeRatio：设置堆空间最小空闲比例，默认是 40 ，当堆空间的空闲比例小于这个值时，JVM 便会扩展堆空间

      -XX：MaxHeapFreeRatio：设置堆空间的最大空闲比例，默认是 70，当堆空间的空闲比例大于这个值时，JVM 便会压缩堆空间，得到一个较小的堆

      注意：当 -Xms 和 -Xmx 相等时，-XX：MinHeapFreeRatio 和 -XX：MaxHeapFreeRatio 这两个参数无效

    * 吞吐量优先设置

      机器配置是 4G 内存 和 32 核 CPU，配置参数如下：

      -Xms3800m  -Xmx3800m（堆的初始值和最大值一样） 

      -Xmn2g（新生代大小）

      -Xss128k（线程栈大小，减少它使剩余的系统内存支持更多的线程） 

      -XX：+UseParallelGC（新生代使用并行回收收集器）

       -XX：ParallelGCThreads=20（垃圾回收的线程数）

       -XX：+UseParallelOldGC （老年代使用并行回收收集器）

    * 使用大页案例

      使用大的内存分页可以增强 CPU 的内存寻址能力，从而提高系统的性能，参数设置如下：

      -XX：LargePageSizeInBytes：设置大页的大小

    * 降低停顿案例

      为了降低应用软件在垃圾回收时的停顿，首先考虑的使用关注系统停顿的 CMS 回收器，为了减少 Full GC 的次数，应尽可能将对象预留在新生代，新生代 Minor GC 的成本远远小于老年代的 Full GC

      -Xms3800m  -Xmx3800m（堆的初始值和最大值一样） 

      -Xmn2g（新生代大小）

      -Xss128k（线程栈大小，减少它使剩余的系统内存支持更多的线程）

      -XX：ParallelGCThreads=20（垃圾回收的线程数）

      -XX：+UseConcMarkSweepGC（老年代使用 CMS 收集器）

       -XX：+UseParNewGC（新生代使用并行收集器）

      -XX：SurvivorRatio=8（设置 eden ： survivor = 8 : 1）

      -XX：TargetSurvivorRatio（设置 survivor 的使用率为 90%，默认是50%，提高了survivor 区的使用率，当存放的对象超过这个数值，则对象会向老年代压缩）

      -XX：MaxTenuringThreshold=31（设置年轻对象晋升到老年代的最大年龄是31，默认是15，设为31是尽可能地将对象留在新生代

    * 常用JVM设置参数

      1、JIT编译参数

      JVM 的 JIT（Just-In-Time）编译器，可以在运行时将字节码编译成本地代码，从而提高函数的执行效率。参数设置如下

      -XX：CompileThreshold：JIT 编译的阀值，当函数的调用超过这个值时，JIT 就将字节码编译成本地机器码。在 client 模式下，取值是 1500，在 server 模式下，取值是 10000

      2、堆快照（堆 Dump）
      	-XX：+HeapDumpOnOutOfMemoryError（开启堆快照）

      ​	-XX：HeapDumpPath=C:/m.hprof（保存文件到哪个目录）

      3、错误处理

      系统发生 OOM 错误时，JVM 在错误发生时运行一段第三方脚本，重置系统，设置参数如下：

      -XX：OnOutOfMemoryError=C:\reset.bat


      4、获取 GC 信息
    
      获取 GC 信息是 java 应用程序调优最重要的一环，下面介绍一些常用的设置参数：
    
      -XX：+PrintGC（-verbose：gc）：输出打印简要的 GC 信息，包括 GC 前的堆栈情况和 GC 后的堆栈大小和堆栈的总大小
    
      -XX：+PrintGCDetails：输出打印详细的 GC 信息，不仅包括基本信息，还给出了新生代、老年代和永久区各自的 GC 信息
    
      -XX：+PrintGCTimeStamps：额外输出 GC 发生的时间，可以推断出 GC 的频率和间隔
    
      -XX：+PrintTenuringDistribution  -XX：MaxTenuringThreshold=18：查看新生代晋升老年代的实际阀值（-XX：+PrintTenuringDistribution），设置的最大年龄为18（ -XX：MaxTenuringThreshold=18）
    
      -XX：+PrintHeapAtGC：每次 GC 时都会打印堆的详细使用情况，输出量很巨大。它分为两个部分：GC 前的堆信息和 GC 后的堆信息，这里包含了新生代、老年代和永久区的使用大小和使用率，还包括了新生代中 eden 区和 survivor 区的使用情况
    
      -XX：+PrintGCApplicationStoppedTime：应用程序在 GC 发生时的停顿时间
    
      -XX：+PrintGCApplicationConcurrentTime：应用程序在 GC 停顿期间的执行时间
    
      -Xloggc：C:/gc.log：将 GC 日志信息输出到具体位置的文件中，便于日后日志分析
    
      注意：详细的 GC 信息是进行 JVM 调优的重要参考信息，可以根据 GC 日志，设置合理的堆大小及相关垃圾回收器的参数


      5、类和对象跟踪
    
      JVM 提供了一组参数，用于获取系统运行时加载、卸载类的信息，参数设置如下：
    
      -XX：TraceClassLoading：跟踪类加载情况
    
      -XX：TraceClassUnloading：跟踪类的卸载情况
    
      -verbose：class：相当于同时设置  -XX：TraceClassLoading 和 -XX：TraceClassUnloading 两个参数
    
      -XX：+PrintClassHistogram：打印运行时实例的信息，当设置此参数后，使用 Ctrl +    Break 会输出系统内类的统计信息，从左到右依次显示了序号、实例数量、总大小和类名等信息


      6、控制GC
    
      -XX：DisableExplicitGC：禁止 GC 操作，即禁止在程序中使用 System.gc() 触发 Full GC
    
      -Xnoclassgc：禁止类的回收
    
      -Xingc：增量式的 GC ，增量式的 GC 使用特定的算法让 GC 线程和应用程序线程交叉执行，从而减少应用程序因 GC 产生的停顿时间
    
      -Xverify：none：关闭类校验器
    
      -XX：+UseLargePages：启用大页，使用大页后，内存分页的表项就会减少，从而提升CPU从虚拟内存地址映射到物理内存地址的能力
    
      -XX：LargePageSizeInBytes：指定大页的大小

* **int a = 1;jvm如何取得a的值**

  1 a作为类的成员变量，存放于方法区中；1保存在堆(Heap)的实例中
  2 a作为方法局部变量，存放于Java虚拟机栈(JVM Stacks)的局部变量表中；1也保存在栈内存中

* **逃逸分析（JDK7以后默认开启）**

  逃逸是指在某个方法之内创建的对象，除了在方法体之内被引用之外，还在方法体之外被其它变量引用到；这样带来的后果是在该方法执行完毕之后，该方法中创建的对象将无法被GC回收，由于其被其它变量引用。正常的方法调用中，方法体中创建的对象将在执行完毕之后，将回收其中创建的对象；故由于无法回收，即成为逃逸。

  如果开启JVM逃逸分析可以优化JVM，但是目前不成熟。

  ​	一、同步省略。如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步。

  ​	二、将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配。节省对内存减少GC。

  ​	三、分离对象或标量替换。有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中。

  ​			标量（Scalar）是指一个无法再分解成更小的数据的数据。Java中的原始数据类型就是标量。相对的，那些还可以分解的数据叫做聚合量（Aggregate），Java中的对象就是聚合量，因为他可以分解成其他聚合量和标量。

  在JIT阶段，如果经过逃逸分析，发现一个对象不会被外界访问的话，那么经过JIT优化，就会把这个对象拆解成若干个其中包含的若干个成员变量来代替。这个过程就是标量替换。

  public static void main(String[] args) {
     alloc();
  }

  private static void alloc() {
     Point point = new Point（1,2）;
     System.out.println("point.x="+point.x+"; point.y="+point.y);
  }
  class Point{
      private int x;
      private int y;
  }
  以上代码中，point对象并没有逃逸出alloc方法，并且point对象是可以拆解成标量的。那么，JIT就会不会直接创建Point对象，而是直接使用两个标量int x ，int y来替代Point对象。

  以上代码，经过标量替换后，就会变成：

  private static void alloc() {
     int x = 1;
     int y = 2;
     System.out.println("point.x="+x+"; point.y="+y);
  }
  可以看到，Point这个聚合量经过逃逸分析后，发现他并没有逃逸，就被替换成两个聚合量了。那么标量替换有什么好处呢？就是可以大大减少堆内存的占用。因为一旦不需要创建对象了，那么就不再需要分配堆内存了。

  标量替换为栈上分配提供了很好的基础。
  
  

  在Java代码运行时，通过JVM参数可指定是否开启逃逸分析，

  -XX:+DoEscapeAnalysis ： 表示开启逃逸分析

  -XX:-DoEscapeAnalysis ： 表示关闭逃逸分析 从jdk 1.7开始已经默认开始逃逸分析，如需关闭，需要指定-XX:-DoEscapeAnalysis

* **jvm调优调的哪些参数？我说初始堆大小和最大堆大小一样，问这样有什么好处**

  主要调：堆的初始和最大内存（堆的最小和最大空闲时间）（新生代的大小）、线程栈的大小、垃圾收集器的选择。

  设置初始和最大堆一样的好处：

  ​	一般情况下，在生产环境中，初始堆大小-Xms与最大堆大小-Xmx被设置为相等。假设如果在生产环境中，初始堆大小-Xms与最大堆大小-Xmx是不等的，那么JVM就会根据堆内存的使用情况，动态的向操作系统申请内存，扩大或者是缩小，以-Xmx和-Xms的值为上下界，这里的每一次调整都会产生一定的系统开销，虽然做到了动态申请堆大小的能力，不过生产环境中，很少说一台机器跑好多个JAVA程序，一般情况下都是一对一，那么动态申请调整堆大小就没有意义了，因为不管内存申请的多还是少，都只是这个JAVA程序在用，不需要给其他的程序腾出空间，相反的，如果把初始堆大小-Xms与最大堆大小-Xmx设置成不相等，那么反而画蛇添足，因为如果初始堆大小-Xms与最大堆大小-Xmx不相等，那么就会需要申请空间时，而每次申请空间，就会产生相应的系统开销，同时如果一开始堆大小是-Xms，会增加程序运行时进行垃圾回收的次数，降低程序的性能。

  

## 容器

* **Collection和Collections有什么区别**

  ![](https://img-blog.csdnimg.cn/20200410211055784.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMTM2NTc4,size_16,color_FFFFFF,t_70)

  1、java.util.Collection 是一个集合接口。它提供了对集合对象进行基本操作的通用接口方法。Collection接口在Java 类库中有很多具体的实现。Collection接口的意义是为各种具体的集合提供了最大化的统一操作方式。

  List，Set，Queue接口都继承Collection。
  直接实现该接口的类只有AbstractCollection类，该类也只是一个抽象类，提供了对集合类操作的一些基本实现。List和Set的具体实现类基本上都直接或间接的继承了该类。

  2、java.util.Collections 是一个包装类。它包含有各种有关集合操作的静态方法（对集合的搜索、排序、线程安全化等），大多数方法都是用来处理线性表的。此类不能实例化，就像一个工具类，服务于Java的Collection框架。

* **HashMap和HashTable区别**

  * 父类不同

    HashTable：继承自Dictionary（已被废弃）

    HashMap：继承自AbstractMap类

    不过它们都实现了同时实现了map、Cloneable（可复制）、Serializable（可序列化）这三个接口。

    Hashtable比HashMap多提供了elments() 和contains() 两个方法。

        elments() 方法继承自Hashtable的父类Dictionnary。elements() 方法用于返回此Hashtable中的value的枚举。

       contains()方法判断该Hashtable是否包含传入的value。它的作用与containsValue()一致。事实上，contansValue() 就只是调用了一下contains() 方法。

  * null值问题

    HashTable：不能有null值null键

    HashMap：可以有一个null值，支持null键。

    当get()方法返回null值时，可能是 HashMap中没有该键，也可能使该键所对应的值为null。因此，在HashMap中不能由get()方法来判断HashMap中是否存在某个键， 而应该用containsKey()方法来判断。

  * 线程安全性

    HashTable：线程安全，它的每个方法中都加入了Synchronize方法。

    ​	但基本由于性能问题，已被弃用。ConcurrentHashMap因为ConcurrentHashMap使用了分段锁，并不对整个数据进行锁定。

    HashMap：单线程使用性能更好，多线程不安全，还可能造成死锁。

  * 遍历方式不同

  * 初始容量不同

    Hashtable的初始长度是11，之后每次扩充容量变为之前的2n+1（n为上一次的长度）

    而HashMap的初始长度为16，之后每次扩充变为原来的两倍

    创建时，如果给定了容量初始值，那么Hashtable会直接使用你给定的大小，而HashMap会将其扩充为2的幂次方大小。

  * 计算hash值方式不同

    为了得到元素的位置，首先需要根据元素的 KEY计算出一个hash值，然后再用这个hash值来计算得到最终的位置

    Hashtable直接使用对象的hashCode。hashCode是JDK根据对象的地址或者字符串或者数字算出来的int类型的数值。然后再使用除留余数发来获得最终的位置。 然而除法运算是非常耗费时间的。效率很低

    HashMap为了提高计算效率，将哈希表的大小固定为了2的幂，这样在取模预算时，不需要做除法，只需要做位运算。位运算比除法的效率要高很多。

* **HashMap数据结构和实现原理，以及有什么并发问题**

  [详细参考](https://juejin.cn/post/6844903646212128776)

  * 公共：

    * 负载因子：0.75

    ​		为什么是0.75？ 

    ​			时间和空间的权衡。如果为1，增加了hash冲突，增加了红黑树的复杂度。如果为0.5，hash冲突降低了，浪费了更多的空间。

    ​			源码上说了，负载因子是0.75的时候，空间利用率比较高，而且避免了相当多的Hash冲突，使得底层的链表或者是红黑树的高度比较低，提升了空间效率。

    * 初始容量：16 

    ​		若指定容量，变成他的2的指数次幂。（为了性能，尽量提前预估大小，而且要考虑实际元素大小要 小于 HashMap算得2指数次幂*0.75，否则容易触发扩容机制）

    ​		为什么2的指数次幂容量，及二倍扩容？

    ​			计算索引：当 length 为 2 的次幂时，num & (length - 1) = num % length 等式成立，位运算更高效

    * 懒加载（延时加载）

      put()调用的时候先判断初始数组是否为空，如果为空，则初始化。

  * 1.7

    * 插入方式：头插

      为什么头插？考虑一般使用不扩容的情况时，头插方便，不需要遍历链表。

      隐患：并发出现循环链表

    * 数据结构：数组+链表

    * 节点：Entry

    * hash()

      ​	**高低位扰动计算**，降低了了发生hash冲突的几率。

      ```java
          h ^= (h >>> 20) ^ (h >>> 12);
          return h ^ (h >>> 7) ^ (h >>> 4);
      ```

    * 这是什么？index = hash&length-1，所有hash低位相同，高位不同导致hash冲突，性能保险，再次进行一种算法的hash运算。

    * put（）过程：

      		1.判断当前数组是否需要初始化。
       	  2.如果 key 为空，则 put 一个空值进去。
       	  3.根据 key 计算出 hashcode。
       	  4.根据计算出的 hashcode 定位出所在桶。
       	  5.如果桶是一个链表则需要遍历判断里面的 hashcode、key 是否和传入 key 相等，如果相等则进行覆盖，并返回原来的值。
       	  6.如果桶是空的，说明当前位置没有数据存入；新增一个 Entry 对象写入当前位置。
       		7.当调用 addEntry 写入 Entry 时需要判断是否需要扩容。
       	    如果需要就进行两倍扩充，并将当前的 key 重新 hash 并定位。
       	    而在 createEntry 中会将当前位置的桶传入到新建的桶中，如果当前桶有值就会在位置形成链表。

    * get（）过程：

      ```
      首先也是根据 key 计算出 hashcode，然后定位到具体的桶中。
      判断该位置是否为链表。
      不是链表就根据 key、key 的 hashcode 是否相等来返回值。
      为链表则需要遍历直到 key 及 hashcode 相等时候就返回值。
      啥都没取到就直接返回 null 。
      ```

      

    * 扩容时机：

      ​		先判断扩容，后插入。

      ​			为什么这个顺序？因为JDK7头插，如果先插入后扩容，而扩容时还要遍历元素，重新整顿，没必要先插入。

      ​		(size>=threshold)&&(null !=table[bucketIndex])
      ​        1、 存放新值的时候当前已有元素的个数必须大于等于阈值
      ​		2、 存放新值的时候当前存放数据发生hash碰撞（当前key计算的hash值换算出来的数组下标位置已经存在值）

    * rehash：这个定义指扩容时重新计算索引

      扩容导致时，将原有的对象重新计算hash值重新的分配并加入新的桶内。

      （再一次调用int i = indexFor(e.hash,newCapacity);

      目的：为了解决数量增多，导致一些链表太长，时间复杂度O(n)的问题

      

  * 1.8

    * 插入方式：尾插

      ​	为什么尾插？因为在resize()的时候，头插方式，同一Entry链上的元素，重新计算索引位置时，顺序有变，导致出现并发问题，形成循环链表。尾插，扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了。

      ​	但put和get没有锁机制，依然无法保证多线程情况下的安全。

    * 数据结构：数组+链表+红黑树

      ​	红黑树时间复杂度O(logn)

    *  节点：Node

    * 计算hash：

      首先，在高位扰动方面，只是简单的h = h ^ (h >>> 16)，没有再做那么多的扰动，就得到了hash值。其次，去掉了indexFor这个专门定位的函数，而是在put,get等操作中直接定位，可以看到这些函数中都有这两行
      我自己的理解是，由于用红黑树优化了冲突很多，链很长的情况，所以没必要做那么多的高低位扰动了。有了冲突也可以处理。

    * put（）过程：

    		1.判断当前桶为空，为空初始化。
    		
    		2.计算key的hashcode，定位具体的桶，若痛为null，则没有hash冲突，直接创建一个新桶即可。
    		
    		3.若桶不为空（hash冲突），则比较当前桶中的 key、key 的 hashcode 与写入的 key 是否相等，相等就赋值给 e，
    		
    		4.若不相等，如果当前桶为红黑树，按照红黑树方式写入数据。
    		
    		5.如果当前桶为链表，就需要将当前的 key、value 封装成一个新节点写入到当前桶的后面
    		
    		6.接着判断当前链表的大小是否大于预设的阈值，大于时就要转换为红黑树。
    		
    		7.如果在遍历过程中找到 key 相同时直接退出遍历。
    		8.如果 e != null 就相当于存在相同的 key,那就需要将值覆盖。
    		9.最后判断是否需要进行扩容。（插入后的size>阈值）

    * get（）过程:

      ```
      首先将 key hash 之后取得所定位的桶。
      如果桶为空则直接返回 null 。
      否则判断桶的第一个位置(有可能是链表、红黑树)的 key 是否为查询的 key，是就直接返回 value。
      如果第一个不匹配，则判断它的下一个是红黑树还是链表。
      红黑树就按照树的查找方式返回值。
      不然就按照链表的方式遍历匹配返回值。
      ```

    * 扩容时机：

      先插入，后判断扩容

      ​	为什么这个顺序？因为JDK8尾插，如果先扩容后，而插入时还要遍历元素，扩容还要遍历一遍，没必要遍历两次啊。

      两种情况下扩容：1,初始化时。2,插入后的size>阈值。

    * rehash：

      不需要重新计算hash，而是巧妙的使用了：原来的hash值&原数组长度 来判断：

      即e.hash&oldCap 如果结果等于0位置相同，如果不等于0，位置等于原来索引+原数组长度

    * 树化机制

      阈值：当前链表长度大于8

      ​	为什么是8？源码上说，为了配合使用分布良好的hashCode，树节点很少使用。并且在理想状态下，受随机分布的hashCode影响，链表中的节点遵循泊松分布，而且根据统计，链表中节点数是8的概率已经接近千分之一，而且此时链表的性能已经很差了。所以在这种比较罕见和极端的情况下，才会把链表转变为红黑树。因为链表转换为红黑树也是需要消耗性能的，特殊情况特殊处理，为了挽回性能，权衡之下，才使用红黑树，提高性能。也就是大部分情况下，hashmap还是使用的链表，如果是理想的均匀分布，节点数不到8，hashmap就自动扩容了。

      条件：先判断table的长度是否大于64 && 链表长度超过阈值

    * 树退化机制

      阈值：当前树节点数小于6

      ​	为什么是6？避免来回转化。

      ​	因为树节点所占空间是普通节点的两倍，所以只有当节点足够多的时候，才会使用树节点。也就是说，节点少的时候，尽管时间复杂度上，红黑树比链表好一点，但是红黑树所占空间比较大，综合考虑，认为只能在节点太多的时候，红黑树占空间大这一劣势不太明显的时候，才会舍弃链表，使用红黑树。

      条件：

      ​	1.remove():

      ​	在红黑树的root节点为空 或者root的右节点、root的左节点、root左节点的左节点为空时 说明树都比较小了

      ​	2.resize():

      ​	当红黑树节点元素小于等于6时(只有resize()才用到了这个6)

* **ConcurrentHashMap的原理**

  * 1.7

    是由 Segment 数组、HashEntry 组成，和 HashMap 一样，仍然是数组加链表。

    分段锁技术，其中 Segment 继承于 ReentrantLock。不会像 HashTable 那样不管是 put 还是 get 操作都需要做同步处理，理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment。

  * 1.8

    抛弃了原有的 Segment 分段锁，节点改为Node，数组加链表+红黑树，而采用了 CAS + synchronized 来保证并发安全性。

* **如何决定使用HashMap还是TreeMap**

  HashMap基于散列桶（数组和链表）实现；TreeMap基于红黑树实现。
  HashMap不支持排序；TreeMap默认是按照Key值升序排序的，可指定排序的比较器，主要用于存入元素时对元素进行自动排序。
  HashMap大多数情况下有更好的性能，尤其是读数据。在没有排序要求的情况下，使用HashMap。
  都是非线程安全。

* **LinkedHashMap的应用**

  数据结构：可以认为是HashMap+LinkedList，即它既使用HashMap操作数据结构，又使用LinkedList维护插入元素的先后顺序。

  迭代顺序：插入顺序。如果启动了访问顺序，最近访问的会排到尾部。

  put():用hashMap的put方法，

  ​	插入新值

  ```java
  //中间调用了自己重写了的newNode()
  Node<K,V> newNode(int hash, K key, V value, Node<K,V> e) {
          LinkedHashMap.Entry<K,V> p =
              new LinkedHashMap.Entry<K,V>(hash, key, value, e);
              //将节点插入链尾
          linkNodeLast(p);
          return p;
      }
  
  ```

  ​	更新值

  ```java
  void afterNodeAccess(Node<K,V> e) { 
    //将值覆盖
  ```

  ​	此外，HashMap.put中的putVal 还调用了afterNodeInsertion()方法，在HashMap中这个方法是空的，但LinkedHashMap重写了

  ```java
  void afterNodeInsertion(boolean evict) { // possibly remove eldest
          LinkedHashMap.Entry<K,V> first;
          if (evict && (first = head) != null && removeEldestEntry(first)) {
              K key = first.key;
              removeNode(hash(key), key, null, false, true);
          }
      }
  //removeEldestEntry：LinkedHashMap的此方法是返回false，需要子类继承以便扩展。
  ```

  

  get()：重写了HashMap的get，实现了LRU

  ```java
  public V get(Object key) {
      Node<K,V> e;
      if ((e = getNode(hash(key), key)) == null)
          return null;
      if (accessOrder)
          afterNodeAccess(e);
      return e.value;
  }
  ```

  remove()：

  ​	也是调用的HashMap的remove，过程中调afterNodeRemoval，此方法在LinkedHashMap中实现了

  应用：LruCache 不经常使用的删掉

  ```java
      @Override
  		protected boolean removeEldestEntry(Entry<K, V> eldest) {
          return this.size() > this.maxSize;
      }
  ```

  

* **HashSet实现原理**

  ```
  * HashSet
  
    内部用HashMap的key存储，而value为一个object
  	add()是调用内部HashMap的put
    不保证迭代的顺序，不可重复，无索引，允许为null但只能有一个.
    操作都是基于HashMap的
  
  * LinkedHashSet 
  
    内部中LinkedHashMap，Entry节点，双向链表
  
    保证迭代的顺序，不可重复，无索引，允许为null但只能有一个
  
  * TreeSet
  
    SortedSet接口的唯一实现类，是基于二叉树实现的。TreeSet可以确保集合元素处于排序状态。TreeSet支持两种排序方式，自然排序 和定制排序，其中自然排序为默认的排序方式。向TreeSet中加入的应该是同一个类的对象。
  	自然排序：指已经实现了Comparable接口的类的插入，如String，Integer
  	定制排序：指手动实现了Comparable接口。
    保证迭代的顺序，不可重复，无索引，不允许为null值，
  ```

* **ArrayList和LinkedList区别**

  * ArrayList:

    基于数组。

    优点：get、set 通过索引定位更快 O(1)

    缺点：add、remove。改变了一些元素的下标，要执行System.arrayCopy

    ArrayList需要一份连续的内存空间，LinkedList不需要连续的内存空间（特别地，当创建一个ArrayList集合的时候，连续的内存空间必须要大于等于创建的容量）

    fail-fast的保护机制：

    之所以会抛出ConcurrentModificationException异常，是因为我们的代码中使用了增强for循环，而在增强for循环中，集合遍历是通过iterator进行的，但是元素的add/remove却是直接使用的集合类自己的方法。这就导致iterator在遍历的时候，会发现有一个元素在自己不知不觉的情况下就被删除/添加了，就会抛出一个异常，用来提示可能发生了并发修改！所以，在使用Java的集合类的时候，如果发生ConcurrentModificationException，优先考虑fail-fast有关的情况，实际上这可能并没有真的发生并发，只是Iterator使用了fail-fast的保护机制，只要他发现有某一次修改是未经过自己进行的，那么就会抛出异常。

    扩容：初始容量为10。

    ​	第一次add minCapacity=10     newCapacity = 10

    ​	第二次add minCapacity = 2	 newCapacity = 10

    ​	第十次add minCapacity = 10   newCapacity = 10

    ​	第十一add 触发grow() （未必add多少个） minCapacity = n	newCapacity =  1.5倍扩容，若newCapacity<minCapacity 则newCapacity = minCapacity，详细：

    ```java
        private void grow(int minCapacity) {
            // overflow-conscious code
            int oldCapacity = elementData.length;
            int newCapacity = oldCapacity + (oldCapacity >> 1);
            if (newCapacity - minCapacity < 0)
                newCapacity = minCapacity;
            if (newCapacity - MAX_ARRAY_SIZE > 0)
                newCapacity = hugeCapacity(minCapacity);
            // minCapacity is usually close to size, so this is a win:
            elementData = Arrays.copyOf(elementData, newCapacity);
        }
    
        private static int hugeCapacity(int minCapacity) {
            if (minCapacity < 0) // overflow
                throw new OutOfMemoryError();
            return (minCapacity > MAX_ARRAY_SIZE) ?
                Integer.MAX_VALUE :
                MAX_ARRAY_SIZE;
        }
    ```

    扩容倍数： grow()是有逻辑判断的，刚开始偶数1.5倍（奇数1.5倍-1），后续逻辑也可能是扩容更多。

  * LinkedList：

    基于双向链表。

    优点：add、remove 、对于两端的操作。

    双向链表查找index位置的节点时，有一个加速动作：若index < 双向链表长度的1/2，则从前向后查找; 否则，从后向前查找。

    额外常用方法：

    ​	添加：

    ​		push(E)：添加到头

    ​		add(E)：添加到尾

    ​		offer(E): =add()

    ​	获取：

    ​		pop(): 获取头元素，并移除。如果获取的为null，报错。

    ​		poll(): 获取头元素，并移除。如果为null，就返回null，

    ​		peek()：获取头元素，不移除，如果为null，就返回null

    ​		remove():=pop()

    ### 时间复杂度

    | 操作     | 数组 | 链表 |
    | -------- | ---- | ---: |
    | 随机访问 | O(1) | O(N) |
    | 头部插入 | O(N) | O(1) |
    | 头部删除 | O(N) | O(1) |
    | 尾部插入 | O(1) | O(1) |
    | 尾部删除 | O(1) | O(1) |
    | 随机插入 | O(n) | O(n) |
    | 随机删除 | O(n) | O(n) |

    ​	后两个是数组更快，原因是，当数据量大的时候，system.arraycopy的效率要比每次插入LinkedList都需要从端查找index和分         配节点node来的更快。

* **如何实现数组和List之间的转化**

  ```java
  //三种方式：
  public void test5() {
      Integer[] arr = {1, 2, 4};
      List<Integer> list = Arrays.asList(arr);
      Integer[] toArray = list.toArray(new Integer[0]);
    	Collections.addAll(list, arr);
  }
  ```

* **ArrayList和Vector区别**

  Vector：

  ​	数据结构一样。

  ​	线程安全：很多方法都有synchronized修饰。

  ​	扩容：2倍扩容，也支持按capacityIncrement（构造器传入）增长量扩容。

* **Array和ArrayList区别**

  ​	性能：对于引用类型来说没差别；但对于基本数据类型，List会引起拆箱和装箱，频繁操作影响效率。

  ​	数据结构：Array是本地程序数据结构；ArrayList是基于Array的一个java集合类。

  ​	功能：Array固定长度。ArrayList实现了自动扩容，并且封装了更多的方法。

* **Queue中poll()和remove()区别**

  poll() 和 remove() 都是从队列中取出一个元素，但是 poll() 在获取元素失败的时候会返回空，但是 remove() 失败的时候会抛出异常。

* **哪些集合类是线程安全的**

  * 早期：

  Vector：就比Arraylist多了个同步化机制（线程安全）。

  Hashtable：就比Hashmap多了个线程安全。

  Stack：栈，也是线程安全的，继承于Vector。

  * Collections包装方法：

    List<E> synArrayList = Collections.synchronizedList(new ArrayList<E>());

    Set<E> synHashSet = Collections.synchronizedSet(new HashSet<E>());

    Map<K,V> synHashMap = Collections.synchronizedMap(new HashMap<K,V>());

    Collections针对每种集合都声明了一个线程安全的包装类，在原集合的基础上添加了锁对象，集合中的每个方法都通过这个锁对象实现同步。(synchronized修饰方法)

  * java.util.concurrent包下的集合类

  ​	1.ConcurrentHashMap

  ConcurrentHashMap和HashTable都是线程安全的集合，它们的不同主要是加锁粒度上的不同。HashTable的加锁方法是给每个方法加上synchronized关键字，这样锁住的是整个Table对象。而ConcurrentHashMap是更细粒度的加锁 
  在JDK1.8之前，ConcurrentHashMap加的是分段锁，也就是Segment锁，每个Segment含有整个table的一部分，这样不同分段之间的并发操作就互不影响 
  JDK1.8对此做了进一步的改进，它取消了Segment字段，直接在table元素上加锁，实现对每一行进行加锁，进一步减小了并发冲突的概率

  2.CopyOnWriteArrayList和CopyOnWriteArraySet

  它们是加了写锁的ArrayList和ArraySet，锁住的是整个对象，但读操作可以并发执行

  3.

  除此之外还有ConcurrentSkipListMap、ConcurrentSkipListSet、ConcurrentLinkedQueue、ConcurrentLinkedDeque等，至于为什么没有ConcurrentArrayList，原因是无法设计一个通用的而且可以规避ArrayList的并发瓶颈的线程安全的集合类，只能锁住整个list，这用Collections里的包装类就能办到
  
* **迭代器Iterator是什么？怎么使用，有什么特点？**

  定义：

  ​	首先说一下迭代器模式，它是 Java 中常用的设计模式之一。用于顺序访问集合对象的元素，无需知道集合对象的底层实现。 

  Iterator 是可以遍历集合的对象，为各种容器提供了公共的操作接口，隔离对容器的遍历操作和底层实现，从而解耦。

  缺点是增加新的集合类需要对应增加新的迭代器类，迭代器类与集合类成对增加。

  ```java
      boolean hasNext();
      E next();
      default void remove(){...}
  ```

  使用：

  ```java
  public class LinkList<T> implements Iterable<T>{
      @Override
      public Iterator<T> iterator() {
          return new MyLinkIterator();
      }
        private class MyLinkIterator implements Iterator{
  
          private Node n;
  
          public MyLinkIterator() {
              this.n = head;
          }
  
          @Override
          public boolean hasNext() {
              return n.next != null;
          }
  
          @Override
          public Object next() {
              n = n.next;
              return n.item;
          }
      }
      public void print() {
        //即可使用Iterable.forEach
          forEach(t -> {
              if (t instanceof Integer) {
                  System.out.println((Integer) t);
              }
          });
      }
  }
  ```

  ArrayList的Iterator：（fail-fast机制：ConcurrentModificationException）

  ​	Iterator的特点：Iterator 的特点是更加安全，因为它可以确保，在当前遍历的集合元素被更改的时候，就会抛出 ConcurrentModificationException 异常。

  ```java
  public boolean hasNext()
  {
      return cursor != size;//当cursor不等于size时，表示仍有索引元素
  }
  public E next() //返回下一个元素
      {
              checkForComodification();
              int i = cursor;
              if (i >= size)
                  throw new NoSuchElementException();
              Object[] elementData = ArrayList.this.elementData;
              if (i >= elementData.length)
                  throw new ConcurrentModificationException();
              cursor = i + 1;
              return (E) elementData[lastRet = i];
      }
  在next()方法中有一个checkForComodification()方法，其实现为：
  final void checkForComodification()
    {
         if (modCount != expectedModCount)
            throw new ConcurrentModificationException();
    }
  可以看到，该函数是用来判断集合的修改次数是否合法。
  
  　　在集合内部维护一个字段modCount用于记录集合被修改的次数，每当集合内部结构发生变化(add,remove，set)时，modCount+1。
  
  　　在迭代器内部也维护一个字段expectedModCount，同样记录当前集合修改的次数，初始化为集合的modCount值。当我们在调用Iterator进行遍历操作时，如果有其他线程修改list会出现modCount!=expectedModCount的情况，就会报并发修改异常java.util.ConcurrentModificationException。下面为示例代码：
    public static void main(String[] args)
      {
           ArrayList<String> aList=new ArrayList<String>();
           aList.add("bbc");
           aList.add("abc");
           aList.add("ysc");
           aList.add("saa");
           System.out.println("移除前："+aList);
      
           Iterator<String> it=aList.iterator();
           while(it.hasNext())
           {
               if("abc".equals(it.next()))
               {
                  aList.remove("abc");  //如果我们只使用迭代器来进行删除，则不会出现并发修改异常错误。改为：it.remove();      
               }
           }
           System.out.println("移除后："+aList);
    }
  迭代器的remove（）：
    public void remove()
       {
              if (lastRet < 0)
                  throw new IllegalStateException();
              checkForComodification();
              try {
                  ArrayList.this.remove(lastRet);
                  cursor = lastRet;
                  lastRet = -1;
                  expectedModCount = modCount;
              } catch (IndexOutOfBoundsException ex) {
                  throw new ConcurrentModificationException();
              }
       }
  ```

  

* **Iterator和ListIterator的区别**

  1.Iterator 可以遍历 Set 和 List 集合，而 ListIterator 只能遍历 List。
  2.Iterator 只能单向遍历，而 ListIterator 可以双向遍历（向前/后遍历）。
  3.ListIterator 从 Iterator 接口继承，然后添加了一些额外的功能，比如添加一个元素、替换一个元素、获取前面或后面元素的索引位置。
  4.ListIterator 可以使用set()方法替换它访问过的最后一个元素.
  5.ListIterator 可以使用add()方法在next()方法返回的元素之前或previous()方法返回的元素之后插入一个元素.
  ListIterator ArrayList的实现双向遍历：实现ListIterator的类，可以自定义指针位置来实现的。

* **怎么确保一个集合不能被修改**

  （1）通过 Collections. unmodifiableCollection(Collection c)

  ```java
  public static <T> Collection<T> unmodifiableCollection(Collection<? extends T> c) {
          return new UnmodifiableCollection<>(c);
      }
  static class UnmodifiableCollection<E> implements Collection<E>, Serializable {
          private static final long serialVersionUID = 1820017752578914078L;
  
          final Collection<? extends E> c;
  
          UnmodifiableCollection(Collection<? extends E> c) {
              if (c==null)
                  throw new NullPointerException();
              this.c = c;
          }
  
          public int size()                   {return c.size();}
          public boolean isEmpty()            {return c.isEmpty();}
          public boolean contains(Object o)   {return c.contains(o);}
          public Object[] toArray()           {return c.toArray();}
          public <T> T[] toArray(T[] a)       {return c.toArray(a);}
          public String toString()            {return c.toString();}
  
          public Iterator<E> iterator() {
              return new Iterator<E>() {
                  private final Iterator<? extends E> i = c.iterator();
  
                  public boolean hasNext() {return i.hasNext();}
                  public E next()          {return i.next();}
                  public void remove() {
                      throw new UnsupportedOperationException();
                  }
                  @Override
                  public void forEachRemaining(Consumer<? super E> action) {
                      // Use backing collection version
                      i.forEachRemaining(action);
                  }
              };
          }
  
          public boolean add(E e) {
              throw new UnsupportedOperationException();
          }
          public boolean remove(Object o) {
              throw new UnsupportedOperationException();
          }
  
          public boolean containsAll(Collection<?> coll) {
              return c.containsAll(coll);
          }
          public boolean addAll(Collection<? extends E> coll) {
              throw new UnsupportedOperationException();
          }
          public boolean removeAll(Collection<?> coll) {
              throw new UnsupportedOperationException();
          }
          public boolean retainAll(Collection<?> coll) {
              throw new UnsupportedOperationException();
          }
          public void clear() {
              throw new UnsupportedOperationException();
          }
  ```

  （2）通过Arrays.asList创建的集合

  ​	实际是创建了一个Arrays内部的ArrayList 他继承抽象类AbstractList，AbstractList当中修改的方法 都throw new UnsupportedOperationException();

## 异常

* **throw和throws区别**

  throw是语句抛出一个异常。如 throws new Exception();

  throws是方法可能抛出异常的声明。用在声明方法上。

* **final、finally、finalize有什么区别**

  final：关键字

  finally，try...catch体中，一定会执行的代码块。

  finalize：Object的一个方法。是gc之前被finalizer线程调用一次。一般用于整理系统资源或者执行其他整理工作。

* **try-catch-finally中，如果catch中return了，finally还是执行吗**

  try-catch-finally中return的执行情况：
  在try中没有异常的情况下try、catch、finally的执行顺序 try --- finally

  如果try中有异常，执行顺序是try --- catch --- finally

  如果try中没有异常并且try中有return这时候正常执行顺序是try ---- finally --- return

  如果try中有异常并且try中有return这时候正常执行顺序是try----catch---finally--- return

  总之 finally 永远执行！

  **注意的地方**：

  不管有没有异常，finally中的代码都会执行

  当try、catch中有return时，finally中的代码依然会继续执行

  finally是在return后面的表达式运算之后执行的，此时并没有返回运算之后的值，而是把值保存起来，不管finally对该值做任何的改变，返回的值都不会改变，依然返回保存起来的值。也就是说方法的返回值是在finally运算之前就确定了的。

  如果return的数据是引用数据类型，而在finally中对该引用数据类型的属性值的改变起作用，try中的return语句返回的就是在finally中改变后的该属性的值。

  finally代码中最好不要包含return，程序会提前退出，也就是说返回的值不是try或catch中的值

* **常见的异常类有哪些**

  异常非常多，Throwable 是异常的根类。

  Throwable 包含子类 错误-Error 和 异常-Exception 。

  Error：程序无法处理的系统错误，编译器不做检查；

  Exception：程序可以处理的异常，捕获后可能恢复；

  总结：前者是程序无法处理的错误，后者是可以处理的异常。

  Exception 又分为 一般异常和运行时异常 RuntimeException。

  运行时异常不需要代码显式捕获处理。

   

  下图是常见异常类及其父子关系：
  Throwable
  |　　├ Error  

  |　　│ ├ NoClassDefFoundError

  |　　│ ├ StackOverflowError

  |　　│ ├ OutOfMemoryError

  |　　│ 

  |　　├ Exception  

  |　　│ ├ CloneNotSupportedException

  |　　│ ├ DataFormatException

  |　　│ ├ InterruptedException

  |　　│ ├ IOException

  |　　│ ├ ClassNotFoundException

  |　　│ ├ RuntimeException 

  |　　│    ├ NumberFormatException

  |　　│    ├ ClassCastException

  |　　│    ├ ConcurrentModificationException

  |　　│    ├ IllegalArgumentException

  |　　│    ├ IndexOutOfBoundsException

  |　　│    ├ NoSuchElementException

  |　　│    ├ NullPointerException

  |　　│　└ SecurityException

  |　　│ └  SQLException

## 网络

* **http状态码，以及301和302区别**

  | 分类 | 分类描述                                       | 常见                                                         |
  | :--- | :--------------------------------------------- | ------------------------------------------------------------ |
  | 1**  | 信息，服务器收到请求，需要请求者继续执行操作   | 100，101                                                     |
  | 2**  | 成功，操作被成功接收并处理                     | 200请求成功                                                  |
  | 3**  | 重定向，需要进一步的操作以完成请求             | 300多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择；301永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替临时移动。302，与301类似。但资源只是临时被移动。客户端应继续使用原有URI |
  | 4**  | 客户端错误，请求包含语法错误或无法完成请求     | 400 Bad Request 客户端请求的语法错误，服务器无法理解；401 Unauthorized 请求要求用户的身份认证402 Payment Required 保留，将来使用。403 Forbidden 服务器理解请求客户端的请求，但是拒绝执行此请求 404 Not Found 服务器无法根据客户端的请求找到资源 405 Method Not Allowed 客户端请求中的方法被禁止 |
  | 5**  | 服务器错误，服务器在处理请求的过程中发生了错误 | 500 Internal Server Error 服务器内部错误，无法完成请求 501 Not Implemented 服务器不支持请求的功能，无法完成请求 502 Bad Gateway 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 504 Gateway Time-out 充当网关或代理的服务器，未及时从远端服务器获取请求 |

* **forward和redirect的区别**

  1、请求方不同

  redirect：客户端发起的请求

  forward：服务端发起的请求

  2、浏览器地址表现不同

  redirect：浏览器地址显示被请求的

  forward：浏览器地址不显示被请求的url

* **简述tcp和udp的区别**

  tcp：传输控制协议）是面向连接的协议

  udp：用户数据报协议

  1.基于连接与无连接；
  2.对系统资源的要求（TCP较多，UDP少）；
  3.UDP程序结构较简单；
  4.流模式与数据报模式 ；

  5.TCP保证数据正确性，UDP可能丢包，TCP保证数据顺序，UDP不保证。

  使用场景：比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。 在日常生活中，常见使用TCP协议的应用如下： 浏览器，用的HTTP FlashFXP，用的FTP Outlook，用的POP、SMTP Putty，用的Telnet、SSH QQ文件传输 ………… 什么时候应该使用UDP： 当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。 比如，日常生活中，常见使用UDP协议的应用如下： QQ语音 QQ视频。ping命令也是udp。原理就是向对方主机发送UDP数据包，然后对方主机确认收到数据包， 如果数据包是否到达的消息及时反馈回来，那么网络就是通的。

* **tcp为什么三次握手，两次不行吗**

  建立连接的三次握手：

  ​	第一次握手：主机A通过向主机B 发送一个含有同步序列号的标志位的数据段给主机B，向主机B 请求建立连接，通过这个数据段， 主机A告诉主机B 两件事：我想要和你通信；你可以用哪个序列号作为起始数据段来回应我。

  第二次握手：主机B 收到主机A的请求后，用一个带有确认应答（ACK）和同步序列号（SYN）标志位的数据段响应主机A，也告诉主机A两件事：我已经收到你的请求了，你可以传输数据了；你要用那个序列号作为起始数据段来回应我

  第三次握手：主机A收到这个数据段后，再发送一个确认应答，确认已收到主机B 的数据段："我已收到回复，我现在要开始传输实际数据了，这样3次握手就完成了，主机A和主机B 就可以传输数据了。

  TCP建立连接要进行3次握手，而断开连接要进行4次
  第一次： 当主机A完成数据传输后,将控制位FIN置1，提出停止TCP连接的请求 ；

  第二次： 主机B收到FIN后对其作出响应，确认这一方向上的TCP连接将关闭,将ACK置1；

  第三次： 由B 端再提出反方向的关闭请求,将FIN置1 ；

  第四次： 主机A对主机B的请求进行确认，将ACK置1，双方向的关闭结束.。

  由TCP的三次握手和四次断开可以看出，TCP使用面向连接的通信方式， 大大提高了数据通信的可靠性，使发送数据端和接收端在数据正式传输前就有了交互， 为数据正式传输打下了可靠的基础。

  1.**三次握手的作用有两个**

  （1）让Client和Server双方都知道双方可以发送和接收到对方的消息；

  （2）避免网络堵塞时，Client以为没有连接上，发送多次请求，而Server会为前面多次无效请求创建连接，造成资源浪费；

  2.**具体说明**

  2.1 **三次握手确认双方都能接收和发送消息**

  （1）第一次握手，Client发送给Server：你好，能听到我的声音吗？；    》server如果收到，Server知道了能接收到client发送的消息

  （2）第二次握手，Server发送给Client ：你好，我能听到你的声音（确认ACK），你能听到我的声音吗？     》Client如果能收到，说明Client知道Server能发送和接收消息；现在还有一点没有确认就是Server不知道Client能否接收Server发送消息？Client的可能电话设置静音了，听不到Server的声音。这样沟通就无效了。所以需要第三次握手。

  （3）第三次握手，Client发送给Server：我能听到你的声音，我告诉你一个重大的密码……     》Server收到，Server知道client具体接收能力；

   

  2.2**避免Server 为无效的连接创建资源**

  Client发送给Server请求连接，如果因为网络堵塞，这个请求阻塞在传输过程中，Client以为没有发过去，又发了一个请求。第一个请求又发送到了服务器，Server又会创建两个连接，第一个连接是无效的，客户端不会通过这个连接去发送消息，这样就造成了服务器资源的浪费。所以需要三次握手，确定连接是否是有效连接。

  高级解释：为了实现可靠数据传输， TCP 协议的通信双方， 都必须维护一个序列号， 以标识发送出去的数据包中， 哪些是已经被对方收到的。 三次握手的过程即是通信双方相互告知序列号起始值， 并确认对方已经收到了序列号起始值的必经步骤
  如果只是两次握手， 至多只有连接发起方的起始序列号能被确认， 另一方选择的序列号则得不到确认

* **说一下tcp的粘包是怎么产生的**

  TCP粘包是什么？
  粘包发生在发送或接收缓冲区中；应用程序从缓冲区中取数据是整个缓冲区中有多少取多少；那么就有可能第一个数据的尾部和第二个数据的头部同时存在缓冲区，而TCP是流式的，数据无边界，这时发生粘包。


  二、TCP粘包的产生
  1.发送方产生粘包
  采用TCP协议传输数据的客户端与服务器经常是保持一个长连接的状态（一次连接发一次数据不存在粘包），双方在连接不断开的情况下，可以一直传输数据；但当发送的数据包过于的小时，那么TCP协议默认的会启用Nagle算法，将这些较小的数据包进行合并发送（缓冲区数据发送是一个堆压的过程）；这个合并过程就是在发送缓冲区中进行的，也就是说数据发送出来它已经是粘包的状态了；

  2.接收方产生粘包
  接收方采用TCP协议接收数据时的过程是这样的：数据到底接收方，从网络模型的下方传递至传输层，传输层的TCP协议处理是将其放置接收缓冲区，然后由应用层来主动获取（C语言用recv、read等函数）；这时会出现一个问题，就是我们在程序中调用的读取数据函数不能及时的把缓冲区中的数据拿出来，而下一个数据又到来并有一部分放入的缓冲区末尾，等我们读取数据时就是一个粘包；（放数据的速度 > 应用层拿数据速度）

  TCP粘包解决方案
  目前应用最广泛的是在消息的头部添加数据包长度，接收方根据消息长度进行接收；在一条TCP连接上，数据的流式传输在接收缓冲区里是有序的，其主要的问题就是第一个包的包尾与第二个包的包头共存接收缓冲区，所以根据长度读取是十分合适的；

  1.解决发送方粘包
  （1）发送产生是因为Nagle算法合并小数据包，那么可以禁用掉该算法；
  （2）TCP提供了强制数据立即传送的操作指令push，当填入数据后调用操作指令就可以立即将数据发送，而不必等待发送缓冲区填充自动发送；
  （3）数据包中加头，头部信息为整个数据的长度（最广泛最常用）；
  2.解决接收方粘包
  （1）解析数据包头部信息，根据长度来接收；
  （2）自定义数据格式：在数据中放入开始、结束标识；解析时根据格式抓取数据，缺点是数据内不能含有开始或结束标识；
  （3）短连接传输，建立一次连接只传输一次数据就关闭；（不推荐）

* **OSI的7层模型都有哪些**

  [参考](https://blog.csdn.net/meism5/article/details/90414270)

  物理层 数据链路层 网络层 传输层 会话层 表示层 应用层

* **get和post的请求有哪些区别**

  [参考](https://www.cnblogs.com/mjtabu/p/12090419.html)

* **如何实现跨域、JSONP实现原理**

  [参考](https://www.cnblogs.com/fundebug/p/10329202.html)

  ****

## Spring

* **spring有哪些优势**

  [向Spring大佬低头——大量源码流出解析 ](https://www.sohu.com/a/230831412_505825)

  Spring是一种轻量级框架，旨在提高开发人员的开发效率以及系统的可维护性。

  - 由于 Spring Frameworks 的分层架构，用户可以自由选择自己需要的组件。

* **StringIOC**

  控制反转，一种设计思想。

  利用java的反射来创建对象。

  程序中原本手动创建对象的控制权交给Spring来管理，依赖关系也交给Spring管理。当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。大大增加了项目的可维护性且降低了开发难度。

* **StringAOP**

  面向切面编程。能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可扩展性和可维护性。

  Spring AOP是基于动态代理的，如果要代理的对象实现了某个接口，那么Spring AOP就会使用JDK动态代理去创建代理对象；而对于没有实现接口的对象，就无法使用JDK动态代理，转而使用CGlib动态代理生成一个被代理对象的子类来作为代理。

  当然也可以使用AspectJ，Spring AOP中已经集成了AspectJ，AspectJ应该算得上是Java生态系统中最完整的AOP框架了。使用AOP之后我们可以把一些通用功能抽象出来，在需要用到的地方直接使用即可，这样可以大大简化代码量。我们需要增加新功能也方便，提高了系统的扩展性。日志功能、事务管理和权限管理等场景都用到了AOP。

  **Spring AOP和AspectJ AOP有什么区别？**

  Spring AOP是属于运行时增强，而AspectJ是编译时增强。Spring AOP基于代理（Proxying），而AspectJ基于字节码操作（Bytecode Manipulation）。Spring AOP 基于动态代理方式实现；AspectJ 基于静态代理方式实现。

  Spring AOP已经集成了AspectJ，AspectJ应该算得上是Java生态系统中最完整的AOP框架了。AspectJ相比于Spring AOP功能更加强大，但是Spring AOP相对来说更简单。

  如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择AspectJ，它比SpringAOP快很多。

* **Spring中Bean的作用域**

  1. singleton，prototype，
  2. request，session，application，websocket（这几个只有在web开发中用到）

* **Spring单例模式下的线程不安全问题**

  因为成员变量是存放在堆内存中，而堆内存又是线程共享的，这就造成了线程安全问题

  因为Spring中的Bean默认是单例的，所以在定义成员变量时也有可能会发生线程安全问题。

  解决：1使用prototype 2使用ThreadLocal

* **Spring中Bean的生命周期**

  根据配置进行Bean的实例化 ->属性注入 -> 调用初始化的一些方法 -> 可以使用 -> 容器关闭，则调用销毁的方法，销毁

* **Spring5比Spring4做了哪些改进**

  1.响应式编程：新的spring-webflux模块

  2.函数式web框架

  3.至少要是jdk8版本。和J2EE 7

* **Spring中BeanFactory和FactoryBean的区别**

  都是一个接口。

  **BeanFactory**:

  ​	也就是IOC容器或对象工厂.所有的Bean都是由BeanFactory(也就是IOC容器)来进行管理的。

  ​	是spring中比较原始的Factory。如XMLBeanFactory就是一种典型的BeanFactory。原始的BeanFactory无法支持spring的许多插件，如AOP功能、Web应用等。 

  ​	注意，BeanFactory 只能管理单例（Singleton）Bean 的生命周期。它不能管理原型(prototype,非单例)Bean 的生命周期。这是因为原型 Bean 实例被创建之后便被传给了客户端,容器失去了对它们的引用。

  ​	这是一个工厂模式的工厂接口。

  ​	BeanFactory最常见的实现类为XmlBeanFactory，可以从classpath或文件系统等获取资源。可以加载xml的配置文件

  \1. XmlBeanFactory通过Resource装载Spring配置信息冰启动IoC容器，然后就可以通过factory.getBean从IoC容器中获取Bean了。
  \2. 通过BeanFactory启动IoC容器时，并不会初始化配置文件中定义的Bean，初始化动作发生在第一个调用时。
  \3. 对于单实例（singleton）的Bean来说，BeanFactory会缓存Bean实例，所以第二次使用getBean时直接从IoC容器缓存中获取Bean。

  

  **FactoryBean**:

  ​	这个Bean不是简单的Bean，而是一个能生产或者修饰对象生成的工厂Bean,它的实现与设计模式中的工厂模式和修饰器模式类似 

  **ApplicationContext**:

  [参考](https://www.cnblogs.com/xiaoxi/p/5846416.html)

  ​	ApplicationContext接口,如果说BeanFactory是Spring的心脏，那么ApplicationContext就是完整的躯体了，ApplicationContext由BeanFactory派生而来，提供了更多面向实际应用的功能。在BeanFactory中，很多功能需要以编程的方式实现，而在ApplicationContext中则可以通过配置实现。通常建议比BeanFactory优先。

  BeanFactorty接口提供了配置框架及基本功能，但是无法支持spring的aop功能和web应用。而ApplicationContext接口作为BeanFactory的派生，因而提供BeanFactory所有的功能。而且ApplicationContext还在功能上做了扩展，相较于BeanFactorty，ApplicationContext还提供了以下的功能： 

  （1）MessageSource, 提供国际化的消息访问 
  （2）资源访问，如URL和文件 
  （3）事件传播特性，即支持aop特性
  （4）载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web层 

  ApplicationContext：是IOC容器另一个重要接口， 它继承了BeanFactory的基本功能， 同时也继承了容器的高级功能，如：MessageSource（国际化资源接口）、ResourceLoader（资源加载接口）、ApplicationEventPublisher（应用事件发布接口）等。

  注意：

  下面对吗？

  start》

  如果你使用ApplicationContext作为Spring Bean的工厂类，则又分为以下几种情况：
  1）如果bean的scope是singleton的，并且lazy-init为false（默认是false，所以可以不用设置），则ApplicationContext启动的时候就实例化该bean，并且将实例化的bean放在一个线程安全的 ConcurrentHashMap 结构的缓存中，下次再使用该Bean的时候，直接从这个缓存中取 。
  2）如果bean的scope是singleton的，并且lazy-init为true，则该bean的实例化是在第一次使用该bean的时候进行实例化 。
  3）如果bean的scope是prototype的，则该bean的实例化是在第一次使用该Bean的时候进行实例化 。
  是不是就是说，使用ApplicationContext作为Spring Bean的工厂类，并不总是在容器启动时，一次性创建了所有的Bean。

  《〈end 还是下面对

  应该是，IOC容器的启动其实主要是里面的refresh方法。主要完成IOC容器的初始化。具体获取bean则要通过getBean方法。Bean的实例化就是你上面的情况。如果是BeanFactory的方式，那实例化Bean的过程发生在getBean的时候，也就是容器初始化之后。而ApplicatonContext的方式的话，AbstractApplicatonContext中的refresh加上了对lazy-init懒加载属性的判断处理。3种判断情况。总体来说就和你说的是那样的。如果是单例不设置懒加载属性的话，那就是在refresh中会进行bean的初始化。而设置了的话，就在getBean的时候进行初始化。

  **三、二者区别**

  1.BeanFactroy采用的是延迟加载形式来注入Bean的，即只有在使用到某个Bean时(调用getBean())，才对该Bean进行加载实例化，这样，我们就不能发现一些存在的Spring的配置问题。而ApplicationContext则相反，它是在容器启动时，一次性创建了所有的Bean。这样，在容器启动时，我们就可以发现Spring中存在的配置错误。 相对于基本的BeanFactory，ApplicationContext 唯一的不足是占用内存空间。当应用程序配置Bean较多时，程序启动较慢。

  BeanFacotry延迟加载,如果Bean的某一个属性没有注入，BeanFacotry加载后，直至第一次使用调用getBean方法才会抛出异常；而ApplicationContext则在初始化自身是检验，这样有利于检查所依赖属性是否注入；所以通常情况下我们选择使用 ApplicationContext。
  应用上下文则会在上下文启动后预载入所有的单实例Bean。通过预载入单实例bean ,确保当你需要的时候，你就不用等待，因为它们已经创建好了。

  2.BeanFactory和ApplicationContext都支持BeanPostProcessor、BeanFactoryPostProcessor的使用，但两者之间的区别是：BeanFactory需要手动注册，而ApplicationContext则是自动注册。（Applicationcontext比 beanFactory 加入了一些更好使用的功能。而且 beanFactory 的许多功能需要通过编程实现而 Applicationcontext 可以通过配置实现。比如后处理 bean ， Applicationcontext 直接配置在配置文件即可而 beanFactory 这要在代码中显示的写出来才可以被容器识别。 ）

  3.beanFactory主要是面对与 spring 框架的基础设施，面对 spring 自己。而 Applicationcontex 主要面对与 spring 使用的开发者。基本都会使用 Applicationcontex 并非 beanFactory 。

  **四、总结**

  作用：
  \1. BeanFactory负责读取bean配置文档，管理bean的加载，实例化，维护bean之间的依赖关系，负责bean的声明周期。

  \2. ApplicationContext除了提供上述BeanFactory所能提供的功能之外，还提供了更完整的框架功能：
  a. 国际化支持
  b. 资源访问：Resource rs = ctx. getResource(“classpath:config.properties”), “file:c:/config.properties”
  c. 事件传递：通过实现ApplicationContextAware接口

  \3. 常用的获取ApplicationContext

  FileSystemXmlApplicationContext：从文件系统或者url指定的xml配置文件创建，参数为配置文件名或文件名数组，有相对路径与绝对路径。

  ```
  ApplicationContext factory=new FileSystemXmlApplicationContext("src/applicationContext.xml");
  ApplicationContext factory=new FileSystemXmlApplicationContext("E:/Workspaces/MyEclipse 8.5/Hello/src/applicationContext.xml");
  ```

  ClassPathXmlApplicationContext：从classpath的xml配置文件创建，可以从jar包中读取配置文件。ClassPathXmlApplicationContext 编译路径总有三种方式：

  ```
  ApplicationContext factory = new ClassPathXmlApplicationContext("classpath:applicationContext.xml");
  ApplicationContext factory = new ClassPathXmlApplicationContext("applicationContext.xml"); 
  ApplicationContext factory = new ClassPathXmlApplicationContext("file:E:/Workspaces/MyEclipse 8.5/Hello/src/applicationContext.xml");
  ```

  XmlWebApplicationContext：从web应用的根目录读取配置文件，需要先在web.xml中配置，可以配置监听器或者servlet来实现

  ```
  <listener>
  <listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>
  </listener>
  ```

  或

  ```
  <servlet>
  <servlet-name>context</servlet-name>
  <servlet-class>org.springframework.web.context.ContextLoaderServlet</servlet-class>
  <load-on-startup>1</load-on-startup>
  </servlet>
  ```

  这两种方式都默认配置文件为web-inf/applicationContext.xml，也可使用context-param指定配置文件

  ```
  <context-param>
  <param-name>contextConfigLocation</param-name>
  <param-value>/WEB-INF/myApplicationContext.xml</param-value>
  </context-param>
  ```

* **Spring中使用到的设计模式**

  1.工厂设计模式：Spring使用工厂模式通过BeanFactory和ApplicationContext创建bean对象。

  2.代理设计模式：Spring AOP功能的实现。

  3.单例设计模式：Spring中的bean默认都是单例的。

  4.模板方法模式：Spring中的jdbcTemplate、hibernateTemplate等以Template结尾的对数据库操作的类，它们就使用到了模板模式。

  5.包装器设计模式：我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。

  6.观察者模式：Spring事件驱动模型就是观察者模式很经典的一个应用。

  7.适配器模式：Spring AOP的增强或通知（Advice）使用到了适配器模式、Spring MVC中也是用到了适配器模式适配Controller。

  。。。

* **@Component和@Bean的区别是什么**

  1.作用对象不同。@Component注解作用于类，而@Bean注解作用于方法。

  2.@Component注解通常是通过类路径扫描来自动侦测以及自动装配到Spring容器中（我们可以使用@ComponentScan注解定义要扫描的路径）。@Bean注解通常是在标有该注解的方法中定义产生这个bean，告诉Spring这是某个类的实例，当我需要用它的时候还给我。

  3.@Bean注解比@Component注解的自定义性更强，而且很多地方只能通过@Bean注解来注册bean。比如当引用第三方库的类需要装配到Spring容器的时候，就只能通过@Bean注解来实现。

* **将一个类声明为Spring的bean的注解有哪些？**

  我们一般使用@Autowired注解去自动装配bean。而想要把一个类标识为可以用@Autowired注解自动装配的bean，可以采用以下的注解实现：

  1.@Component注解。通用的注解，可标注任意类为Spring组件。如果一个Bean不知道属于哪一个层，可以使用@Component注解标注。

  2.@Repository注解。对应持久层，即Dao层，主要用于数据库相关操作。

  3.@Service注解。对应服务层，即Service层，主要涉及一些复杂的逻辑，需要用到Dao层（注入）。

  4.@Controller注解。对应Spring MVC的控制层，即Controller层，主要用于接受用户请求并调用Service层的方法返回数据给前端页面。

* **Bean的装配**

  在Spring中有三种装配方式：

  1.在xml中显示装配

  2.在java中显示装配

  3.隐式自动装配bean：byName和byType（会自动从上下文找）

  @Autowired 可以在属性上和set方法上，前提ioc容器中有，先byType，如果有多个用@qualifier()byName。

  @Resource先byName，找不到byType，还是找不到就完蛋了 

* **Spring事务管理的方式有几种？**

  1.编程式事务：在代码中硬编码（不推荐使用）。

  2.声明式事务：在配置文件中配置（推荐使用），分为基于XML的声明式事务和基于注解的声明式事务。

* **Spring事务中的隔离级别有哪几种？**

  在TransactionDefinition接口中定义了五个表示隔离级别的常量：

  ISOLATION_DEFAULT：使用后端数据库默认的隔离级别，Mysql默认采用的REPEATABLE_READ隔离级别；Oracle默认采用的READ_COMMITTED隔离级别。

  ISOLATION_READ_UNCOMMITTED：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。

  ISOLATION_READ_COMMITTED：允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生

  ISOLATION_REPEATABLE_READ：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。

  ISOLATION_SERIALIZABLE：最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。

* **Spring事务中有哪几种事务传播行为？**

  在TransactionDefinition接口中定义了八个表示事务传播行为的常量。

  支持当前事务的情况：

  PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。

  PROPAGATION_SUPPORTS： 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。

  PROPAGATION_MANDATORY： 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性）。

  不支持当前事务的情况：

  PROPAGATION_REQUIRES_NEW： 创建一个新的事务，如果当前存在事务，则把当前事务挂起。

  PROPAGATION_NOT_SUPPORTED： 以非事务方式运行，如果当前存在事务，则把当前事务挂起。

  PROPAGATION_NEVER： 以非事务方式运行，如果当前存在事务，则抛出异常。

  其他情况：

  PROPAGATION_NESTED： 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于PROPAGATION_REQUIRED。

* **spring有哪些常用注解？（我一紧张说了springboot的注解）**

  @Controller
  
  @RequestMapping
  
  @Resource和@Autowired
  
  @PathVariable
  
  @requestParam
  
  @ResponseBody
  
  @Component
  
  @Repository
  
  springboot独有的：
  
  @RestController
  
  @SpringBootApplication
  
  @ConfigurationProperties
  
  @Enable...
  
  

## SpringMVC

* **springMVC原理**

  1.客户端（浏览器）发送请求，直接请求到DispatcherServlet。

  2.DispatcherServlet根据请求信息调用HandlerMapping，解析请求对应的Handler。

  3.解析到对应的Handler（也就是我们平常说的Controller控制器）。

  4.HandlerAdapter会根据Handler来调用真正的处理器来处理请求和执行相对应的业务逻辑。

  5.处理器处理完业务后，会返回一个ModelAndView对象，Model是返回的数据对象，View是逻辑上的View。

  6.ViewResolver会根据逻辑View去查找实际的View。

  7.DispatcherServlet把返回的Model传给View（视图渲染）。

  8.把View返回给请求者（浏览器）。

## SpringBoot

* **什么是springboot，为什么要用springboot**

  `Spring Boot`是一款集成框架。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。

  拥有超多集成依赖，不需要自己去导入或者查找，直接引入即可，非常方便。

  约定大于配置。

* **springboot的核心配置文件是什么，有哪几种类型，及区别**

  application 配置文件这个容易理解，主要用于 Spring Boot 项目的自动化配置。
  bootstrap 配置文件有以下几个应用场景。
  使用 Spring Cloud Config 配置中心时，这时需要在 bootstrap 配置文件中添加连接到配置中心的配置属性来加载外部配置中心的配置信息；
  一些固定的不能被覆盖的属性；
  一些加密/解密的场景；

  类型：

  properties和yml

  区别：

  1.bootstrap.yml（bootstrap.properties）先加载
  application.yml（application.properties）后加载

  2.bootstrap.yml 是系统级别的一些参数配置，这些参数一般是不变的。
  application.yml 一般用来定义单个应用级别的，如果搭配 spring-cloud-config 使用 application.yml 里面定义的文件可以实现动态替换。

  3.一旦bootStrap.yml 被加载，则内容不会被覆盖，即便后期加载的application.yml的内容标签与bootstrap的标签一致，application 也不会覆盖bootstrap, 而application.yml 里面的内容可以动态替换。

* **springboot实现热部署的方式**

  目前的 Java 虚拟机只能实现方法体的修改热部署，对于整个类的结构修改，仍然需要重启虚拟机，对类重新加载才能完成更新操作。

  深层原理是使用了两个ClassLoader，一个Classloader加载那些不会改变的类（第三方Jar包），另一个ClassLoader加载会更改的类，称为restart ClassLoader,这样在有代码更改的时候，原来的restart ClassLoader 被丢弃，重新创建一个restart ClassLoader，由于需要加载的类相比较少，所以实现了较快的重启时间。

## SpringCloud

* **什么是springcloud？核心组件有哪些？**

  为开发人员提供了快速构建分布式系统中一些常见模式的工具（例如配置管理，服务发现，断路器，智能路由，微代理，控制总线）。

  Eureka：
  服务启动的时候，服务上的Eureka客户端会把自身注册到Eureka服务端，并且可以通过Eureka服务端知道其他注册的服务
  Ribbon：
  服务间发起请求的时候，服务消费者方基于Ribbon服务做到负载均衡，从服务提供者存储的多台机器中选择一台，如果一个服务只在一台机器上面，那就用不到Ribbon选择机器了，如果有多台机器，那就需要使用Ribbon选择之后再去使用
  Feign：
  Feign使用的时候会集成Ribbon，Ribbon去Eureka服务端中找到服务提供者的所在的服务器信息，然后根据随机策略选择一个，拼接Url地址后发起请求
  Hystrix：
  发起的请求是通过Hystrix的线程池去访问服务，不同的服务通过不同的线程池，实现了不同的服务调度隔离，如果服务出现故障，通过服务熔断，避免服务雪崩的问题 ，并且通过服务降级，保证可以手动实现服务正常功能
  Zuul：
  类似Nginx。如果前端调用后台系统，统一走zull网关进入，通过zull网关转发请求给对应的服务

* **springcloud的断路器的作用**

  解决服务器雪崩问题

  Hystrix是隔离、熔断以及降级的一个框架，说白了就是Hystrix会搞很多小线程池然后让这些小线程池去请求服务，返回结果，Hystrix相当于是个中间过滤区，如果我们的积分服务挂了，那我们请求积分服务直接就返回了，不需要等待超时时间结束抛出异常，这就是所谓的熔断，但是也不能啥都不干就返回啊，不然我们之后手动加积分咋整啊，那我们每次调用积分服务就在数据库里记录一条消息，这就是所谓的降级，

* **Feign客户端的远程调用是怎么实现的?协议是什么？**

  Feign的一个机制就是使用了动态代理：

  - 首先，如果你对某个接口定义了@FeignClient注解，Feign就会针对这个接口创建一个动态代理
  - 接着你要是调用那个接口，本质就是会调用 Feign创建的动态代理，这是核心中的核心
  - Feign的动态代理会根据你在接口上的@RequestMapping等注解，来动态构造出你要请求的服务的地址
  - 最后针对这个地址，发起请求、解析响应。（http协议）

## Dubbo

* **springcloud和dubbo如何选择，什么场景下使用springcloud**

  Dubbo是一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。

  dubbo的优势

  单一应用架构，当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的 数据访问框架（ORM）是关键。
  垂直应用架构，当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的 Web框架（MVC）是关键。
  分布式服务架构，当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的 分布式服务框架（RPC）是关键。
  流动计算架构当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的 资源调度和治理中心（SOA）是关键。

  、dubbo
   协议，是默认的基于TCP 

  （一共9种协议，

  1、dubbo 协议 (默认)
  2、rmi 协议
  3、hessian 协议
  4、http 协议
  5、webservice 协议
  6、thrift 协议
  7、memcached 协议
  8、redis 协议
  9、rest ( 就是 RestFull)） 

  传输协议的长连接，NIO
   异步通信，适合于小数据量高并发的场景以及服务消费者机器数远大于服务提供者机器数的情况。

   ，不适合大文件，视频的传输

   连接个数：单连接

   连接方式：长连接

   传输协议：TCP

   传输方式：NIO
   异步传输

   序列化：Hessian
   二进制序列化

   适用范围：传入传出参数数据包较小（建议小于100K
   ），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用dubbo
   协议传输大文件或超大字符串。

   适用场景：常规远程服务方法调用Http
   协议

   采用Spring
   的HttpInvoker
   实现

   基于http
   表单的远程调用协议。

    

   连接个数：多连接

   连接方式：短连接

   传输协议：HTTP

   传输方式：同步传输

   序列化：表单序列化（JSON
   ）

   适用范围：传入传出参数数据包大小混合，提供者比消费者个数多，可用浏览器查看，可用表单或URL
   传入参数，暂不支持传文件。

   适用场景：需同时给应用程序和浏览器JS
   使用的服务。

  SpringCloud是一系列框架的有序集合。它基于SpringBoot的便利性融合了一整套实现微服务的框架并提供了服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等组件。

  1：约定优于配置

  2：开箱即用、快速启动

  3：适用于各种环境

  4：轻量级的组件

  5：组件支持丰富，功能齐全

  整体比较

  1、dubbo由于是二进制的传输，占用带宽会更少

  2、springCloud是http协议传输，带宽会比较多，同时使用http协议一般会使用JSON报文，消耗会更大

  3、dubbo的开发难度较大，原因是dubbo的jar包依赖问题很多大型工程无法解决

  4、springcloud的接口协议约定比较自由且松散，需要有强有力的行政措施来限制接口无序升级

  5、dubbo的注册中心可以选择zk,redis等，springcloud的注册中心用eureka或者Consul

  **如何选择？**

  [参考](https://blog.csdn.net/qq_17231297/article/details/106184746)

  ​	1.开发难度：Dubbo开发难度大，原因是 Dubbo 的 jar 包依赖问题很多大型工程无法解决

  ​	2.公司发展：我不会选择很久没人维护的 Dubbo，重启之后也未必是原班人马。

  ​	3.招聘难度：招 Spring Cloud 的程序员会更好招，因为更新更炫。

  ​	4.系统结构简易程度：Spring Cloud的系统结构更简单，“注册+springmvc=springcloud”，而 Dubbo 各种复杂的 URL、protocol、register、invocation、dubbofilter、dubboSPI，dubbo序列化……炫技的成分更多一些。

  ​	5.性能：Dubbo 的网络消耗小于 Spring Cloud，但是在国内95%的公司内，网络消耗不是什么太大问题。如果真的成了问题，通过压缩、二进制、高速缓存、分段降级等方法，很容易解。

  ​	6.后续改进：Dubbo 的改进是通过 dubbofilter，很多东西没有，需要自己继承，如监控、日志、限流、追踪。Spring Cloud 自己带了很多监控、限流措施，但是功能可能和欧美习惯相同，国内需要进行适当改造，但更简单，就是 ServletFilter 而已，但是总归比 Dubbo 多一些东西是好的。

* **rpc框架都有哪些**

  **RPC**是远程过程调用的简称：

  ​	springcloud：具体是当中的Feign组件

  ​	dubbo：
  
  ​	其他：

## Mybatis

* **#{}和${}区别**

  a、#{}是预编译处理，${}是字符串替换。

  b、Mybatis 在处理#{}时，会将 sql 中的#{}替换为?号，调用 PreparedStatement 的 set 方法来赋值；
  c、Mybatis 在处理${}时，就是把${}替换成变量的值。
  d、使用#{}可以有效的防止 SQL 注入，提高系统安全性。

* **mybatis的执行过程**
  1.加载 conf.xml xxxMapper.xml，封装到Configuration，再封装到DefaultSqlSessionFactory，最终返回SqlSessionFactory。
  2.通过SqlSessionFactory拿到SqlSession，实际拿到的是DefaultSqlSession（其中包含Configuration，Executor执行器）
  3.执行器根据入参(默认是SimpleExecutor,共有3种类型)执行 MappedStatement（底层是<select>等标签），并且接受返回值。
  4.通过SqlSession获取动态代理接口，（包含SqlSession，动态代理接口对象，methodCache(存放查询缓存，底层是ConCurrentHashMap)）


* **mybatis中有几种分页方式**

  **逻辑分页：** 使用 MyBatis 自带的 RowBounds 进行分页，它是一次性查询很多数据，然后在数据中再进行检索。

  **物理分页：** 自己手写 SQL 分页或使用分页插件 PageHelper，去数据库查询指定条数的分页数据的形式。

* **MyBatis 逻辑分页和物理分页的区别是什么？**

  逻辑分页是一次性查询很多数据，然后再在结果中检索分页的数据。这样做弊端是需要消耗大量的内存、有内存溢出的风险、对数据库压力较大。
  物理分页是从数据库查询指定条数的数据，弥补了一次性全部查出的所有数据的种种缺点，比如需要大量的内存，对数据库查询压力较大等问题。

* **RowBounds是一次性查询全部结果吗？为什么？**

  RowBounds 表面是在“所有”数据中检索数据，其实并非是一次性查询出所有数据。因为 MyBatis 是对 JDBC 的封装，在 JDBC 驱动中有一个 Fetch Size 的配置，它规定了每次最多从数据库查询多少条数据，假如你要查询更多数据，它会在执行 next() 的时候，去查询更多的数据。 就好比你去自动取款机取 10000 元，但取款机每次最多能取 2500 元，要取 4 次才能把钱取完。对于 JDBC 来说也是一样，这样做的好处是可以有效的防止内存溢出。

* **mybatis是否支持延迟加载？延迟加载的原理**

  MyBatis 支持延迟加载，设置 lazyLoadingEnabled=true 即可。

  延迟加载的原理的是调用的时候触发加载，而不是在初始化的时候就加载信息。

* **说一下mybatis的一级缓存和二级缓存**

  一级缓存：基于 PerpetualCache 的 HashMap 本地缓存，它的声明周期是和 SQLSession 一致的，有多个 SQLSession 或者分布式的环境中数据库操作，可能会出现脏数据。当 Session flush 或 close 之后，该 Session 中的所有 Cache 就将清空，默认一级缓存是开启的。
  二级缓存：也是基于 PerpetualCache 的 HashMap 本地缓存，不同在于其存储作用域为 Mapper 级别的，如果多个SQLSession之间需要共享缓存，则需要使用到二级缓存，并且二级缓存可自定义存储源，如 Ehcache。默认不打开二级缓存，要开启二级缓存，使用二级缓存属性类需要实现 Serializable 序列化接口(可用来保存对象的状态)。
  开启二级缓存数据查询流程：二级缓存 -> 一级缓存 -> 数据库。

  二级缓存也可以使用第三方的缓存，比如，使用 Ehcache 作为二级缓存。

  缓存更新机制：当某一个作用域(一级缓存 Session/二级缓存 Mapper)进行了C/U/D 操作后，默认该作用域下所有 select 中的缓存将被 clear。

  **笔记**：

  二级（装饰者模式）：通过序列化的方式的。namespace级别的：注意，每次update会清空缓存（二级和一级），commit，才会填充缓存。

  一级：session级别，每次commit，update会清空

  总结：Mybatis在多表查询时，极大可能会出现脏数据。在分布式环境下，由于默认的Mybatis Cache实现都是基于本地的，分布式环境下必然会出现读取到脏数据，需要使用集中式缓存将Mybatis的Cache接口实现，有一定的开发成本，不如直接用Redis，Memcache实现业务上的缓存就好了。

  Mybatis的缓存机制设计的不是很完善，在使用上容易引起脏数据问题，个人建议不要使用Mybatis缓存，在业务层面上使用其他机制实现需要的缓存功能，让Mybatis老老实实做它的ORM框架就好了哈哈。

* **mybatis和hibernate的区别**

  灵活性：MyBatis 更加灵活，自己可以写 SQL 语句，使用起来比较方便。
  可移植性：MyBatis 有很多自己写的 SQL，因为每个数据库的 SQL 可以不相同，所以可移植性比较差。
  学习和使用门槛：MyBatis 入门比较简单，使用门槛也更低。
  二级缓存：hibernate 拥有更好的二级缓存，它的二级缓存可以自行更换为第三方的二级缓存。

* **mybatis有哪些执行器（Executor发音 [ɪɡˈzekjətə(r)] ）**

  1、SimpleExecutor：每执行一次update或select，就开启一个Statement对象，用完立刻关闭Statement对象。

  2、ReuseExecutor：执行update或select，以sql作为key查找Statement对象，存在就使用，不存在就创建，用完后，不关闭Statement对象，而是放置于Map内，供下一次使用。简言之，就是重复使用Statement对象。

  3、BatchExecutor：执行update（没有select，JDBC批处理不支持select），将所有sql都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个Statement对象，每个Statement对象都是addBatch()完毕后，等待逐一执行executeBatch()批处理。与JDBC批处理相同。 

  作用范围：Executor的这些特点，都严格限制在SqlSession生命周期范围内。

  默认是SimplExcutor，需要配置在创建SqlSession对象的时候指定执行器的类型即可。

  Mybatis中如何指定使用哪一种Executor执行器？

  答：在Mybatis配置文件中，可以指定默认的ExecutorType执行器类型，也可以手动给DefaultSqlSessionFactory的创建SqlSession的方法传递ExecutorType类型参数。

* **MyBatis 有哪些拦截器？如何实现拦截功能？**

  答：MyBatis 提供的连接器有以下 4 种。

  Executor：拦截内部执行器，它负责调用 StatementHandler 操作数据库，并把结果集通过 ResultSetHandler 进行自动映射，另外它还处理了二级缓存的操作。
  StatementHandler：拦截 SQL 语法构建的处理，它是 MyBatis 直接和数据库执行 SQL 脚本的对象，另外它也实现了 MyBatis 的一级缓存。
  ParameterHandler：拦截参数的处理。
  ResultSetHandler：拦截结果集的处理。

* **mybatis分页插件的实现原理**

  首先，在MyBatis内部定义了一个拦截器接口

  所有的插件都要实现该接口，来，我们看看这个接口的定义

  ```text
  public interface Interceptor {
  
    Object intercept(Invocation invocation) throws Throwable;
  
    Object plugin(Object target);
  
    void setProperties(Properties properties);
  
  }
  ```

  那么其中一个关键的方法就是intercept，从而实现拦截

  分页插件的原理就是使用MyBatis提供的插件接口，实现自定义插件，在插件的拦截方法内，拦截待执行的SQL，然后根据设置的dialect（方言），和设置的分页参数，重写SQL ，生成带有分页语句的SQL，执行重写后的SQL，从而实现分页

  所以原理还是基于拦截器,代理模式。

  将此拦截器添加到拦截器链中。

  至此我们发现PageHelper分页的实现原来是在我们执行SQL语句之前动态的将SQL语句拼接了分页的语句，从而实现了从数据库中分页获取的过程。

* **mybatis如何编写一个自定义插件**

  1、新建类实现 Interceptor 接口，并指定想要拦截的方法签名

  ```java
  /**
  
   * MyBatis 插件
     */
     @Intercepts({@Signature(type = Executor.class, method = "query", args = {MappedStatement.class, 						 Object.class, RowBounds.class, ResultHandler.class})})
     public class ExamplePlugin implements Interceptor {
  
     @Override
     public Object intercept(Invocation invocation) throws Throwable {
         for (Object arg : invocation.getArgs()) {
             System.out.println("参数：" + arg);
         }
         System.out.println("方法：" + invocation.getMethod());
         System.out.println("目标对象：" + invocation.getTarget());
         Object result = invocation.proceed();
  
         //只获取第一个数据
         if (result instanceof List){
             System.out.println("原集合数据：" + result);
             System.out.println("只获取第一个对象");
             List list = (List)result;
             return Arrays.asList(list.get(0));
         }
         return result;
  
     }
     }
  ```

  


  2、MyBatis 配置文件中添加该插件

  <plugins>
      <plugin interceptor="constxiong.plugin.ExamplePlugin">
      </plugin>
  </plugins>

  ```java
  //测试代码
  
  System.out.println("------userMapper.deleteUsers()------");
  //删除 user
  userMapper.deleteUsers();
  
  System.out.println("------userMapper.insertUser()------");
  //插入 user
  for (int i = 1; i <= 5; i++) {
      userMapper.insertUser(new User(i, "ConstXiong" + i));
  }
  
  System.out.println("------userMapper.selectUsers()------");
  //查询所有 user
  List<User> users = userMapper.selectUsers();
  System.out.println(users);
  
  
  //打印结果
  
  ------userMapper.deleteUsers()------
  ------userMapper.insertUser()------
  ------userMapper.selectUsers()------
  参数：org.apache.ibatis.mapping.MappedStatement@58c1c010
  参数：null
  参数：org.apache.ibatis.session.RowBounds@b7f23d9
  参数：null
  方法：public abstract java.util.List org.apache.ibatis.executor.Executor.query(org.apache.ibatis.mapping.MappedStatement,java.lang.Object,org.apache.ibatis.session.RowBounds,org.apache.ibatis.session.ResultHandler) throws java.sql.SQLException
  目标对象：org.apache.ibatis.executor.CachingExecutor@61d47554
  原集合数据：[User{id=1, name='ConstXiong1', mc='null'}, User{id=2, name='ConstXiong2', mc='null'}, User{id=3, name='ConstXiong3', mc='null'}, User{id=4, name='ConstXiong4', mc='null'}, User{id=5, name='ConstXiong5', mc='null'}]
  只获取第一个对象
  [User{id=1, name='ConstXiong1', mc='null'}]
  
  
  ```

  

## 多线程

* **并行和并发的区别**

  并行：多个处理器或者多核处理器同时执行多个任务。

  ​	真正意义的同时进行。

  并发：一个核心的处理器，执行多个任务。多个线程抢占cpu，在同一时刻只能有一条指令执行

* **线程和进程**

  进程：进程是一个具有一定独立功能的程序在一个数据集上的一次动态执行的过程，是操作系统进行资源分配和调度的一个独立单位，是应用。进程是资源分配的最小单位。

  线程：线程是CPU调度的最小单位

  \2. 一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线

  \3. 进程之间相互独立，但同一进程下的各个线程之间共享程序的内存空间(包括代码段，数据集，堆等)及一些进程级的资源(如打开文件和信

  号等)，某进程内的线程在其他进程不可见；

  \4. 调度和切换：线程上下文切换比进程上下文切换要快得多

* **守护线程是什么**

  java里线程分2种，
  1、守护线程，比如垃圾回收线程，就是最典型的守护线程。因为当所有非守护线程结束时，没有了被守护者，守护线程也就没有工作可做了，也就没有继续运行程序的必要了，程序也就终止了，同时会“杀死”所有守护线程。 典型如垃圾回收线程。

  2、用户线程，就是应用程序里的自定义线程。只要有任何非守护线程还在运行，程序就不会终止。

* **创建线程有哪几种方式**

  一、继承Thread类创建线程类

  （1）定义Thread类的子类，并重写该类的run方法，该run方法的方法体就代表了线程要完成的任务。因此把run()方法称为执行体。

  （2）创建Thread子类的实例，即创建了线程对象。

  （3）调用线程对象的start()方法来启动该线程。

  二、通过Runnable接口创建线程类 

  （1）定义runnable接口的实现类，并重写该接口的run()方法，该run()方法的方法体同样是该线程的线程执行体。

  （2）创建 Runnable实现类的实例，并依此实例作为Thread的target来创建Thread对象，该Thread对象才是真正的线程对象。

  （3）调用线程对象的start()方法来启动该线程。

  三、通过Callable和Future创建线程

  （1）创建Callable接口的实现类，并实现call()方法，该call()方法将作为线程执行体，并且有返回值。

  （2）创建Callable实现类的实例，使用FutureTask类来包装Callable对象，该FutureTask对象封装了该Callable对象的call()方法的返回值。

  （3）使用FutureTask对象作为Thread对象的target创建并启动新线程。

  （4）调用FutureTask对象的get()方法来获得子线程执行结束后的返回值

  ```java
  public class CallableThreadTest implements Callable<Integer> {
  
      public static void main(String[] args) {
          CallableThreadTest ctt = new CallableThreadTest();
          FutureTask<Integer> ft = new FutureTask<>(ctt);
          for (int i = 0; i < 100; i++) {
              System.out.println(Thread.currentThread().getName() + " 的循环变量i的值" + i);
              if (i == 20) {
                  new Thread(ft, "有返回值的线程").start();
              }
          }
          try {
              System.out.println("子线程的返回值：" + ft.get());
          } catch (InterruptedException e) {
              e.printStackTrace();
          } catch (ExecutionException e) {
              e.printStackTrace();
          }
  
      }
      @Override
      public Integer call() throws Exception {
          int i = 0;
          for (; i < 100; i++) {
              System.out.println(Thread.currentThread().getName() + " " + i);
          }
          return i;
      }
  
  }
  ```

  **三种方式对比：**

  采用实现Runnable、Callable接口的方式创见多线程时，优势是：

  线程类只是实现了Runnable接口或Callable接口，还可以继承其他类。

  在这种方式下，多个线程可以共享同一个target对象，所以非常适合多个相同线程来处理同一份资源的情况，从而可以将CPU、代码和数据分开，形成清晰的模型，较好地体现了面向对象的思想。

  劣势是：

  编程稍微复杂，如果要访问当前线程，则必须使用Thread.currentThread()方法。

  使用继承Thread类的方式创建多线程时优势是：

  编写简单，如果需要访问当前线程，则无需使用Thread.currentThread()方法，直接使用this即可获得当前线程。

  劣势是：

  线程类已经继承了Thread类，所以不能再继承其他父类。

* **线程有哪些状态/线程的生命周期，什么时候会出现进程僵死**
  大致5种状态

  ![](https://img-blog.csdnimg.cn/20190527224156530.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3E2NjkyMzk3OTk=,size_16,color_FFFFFF,t_70)

  \1. **新建(NEW)**：新创建了一个线程对象。

  \2. **可运行(RUNNABLE)**：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu 的使用权 。
  

\3. **运行(RUNNING)**：可运行状态(runnable)的线程获得了cpu 时间片（timeslice） ，执行程序代码。
  \4. **阻塞(BLOCKED)**：阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。阻塞的情况分三种： 

  > (一). 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。
> (二). 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。
  > (三). 其他阻塞：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。

  \5. **死亡(DEAD)**：线程run()、main() 方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。

  另外：

   一个线程会因为以下原因而放弃CPU：

  1. 时间片用完了，java虚拟机让当前线程暂时放弃CPU,转到就绪状态,使其它线程获得运行机会。
  2. 当前线程因为某些原因而进入阻塞状态
  3. 线程结束运行

  进程的停止，当一个进程中所有的前台线程停止后，该进程结束。

  如果希望明确地让一个线程给另外一个线程运行的机会，可以采取以下办法。
  1. 调整各个线程的优先级
  2. 让处于运行状态的线程调用Thread.sleep()方法
  3. 让处于运行状态的线程调用Thread.yield()方法
  4. 让处于运行状态的线程调用另一个线程的join()方法

* **什么是线程安全，如何实现线程安全**

  线程安全：

  多线程访问的时候，保证原子性，可见性，有序性是安全的。或者说多线程访问一个对象的时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象就是线程安全的。

  如何实现线程安全：

  ​	1.阻塞同步。

  如Synchronized

  ​	2.非阻塞同步。

  如CAS：它有三个操作数：内存位置，旧的预期值，新值，在执行CAS操作时，当且仅当内存地址的值符合旧的预期值的时候，才会用新值来更新内存地址的值，否则就不执行更新。

  ​	3.不同步方案。

  线程本地存储：将共享数据的可见范围限制在一个线程中。这样无需同步也能保证线程之间不出现数据争用问题。

  经常使用的就是ThreadLocal类

  ThreadLocal类 最常见的ThreadLocal使用场景为 用来解决数据库连接、Session管理等。

* **sleep()和wait()的区别**

  sleep是Thread的方法，wait是Object的方法

  区别一，sleep（）线程控制自身流程。wait（）用来线程间通信，使拥有该对象锁的线程等待直到指定时间或notify（）。

  区别二，sleep（）方法的线程不会释放对象锁。wait（）方法的线程会释放对象锁。

  wait可以代替sleep吗？
  答案不可以，如果直接调用wait会报出java.lang.IllegalMonitorStateException异常，原因是还没有得到对象锁，所以无法释放锁。

* **notity()和notifyAll()的区别**

  - notifyAll使所有**原来在该对象上等待**被notify的**所有线程统统退出wait的状态**，变成**等待该对象上的锁**，**一旦该对象被解锁**，他们就会去**竞争**。

  - notify则文明得多，它只是选择一个wait状态线程进行通知，并使它获得该对象上的锁，但不惊动其他同样在等待被该对象notify的线程们，当第一个线程运行完毕以后释放对象上的锁此时如果该对象没有再次使用notify语句，则即便该对象已经空闲，其他wait状态等待的线程由于没有得到该对象的通知，继续处在wait状态，直到这个对象发出一个notify或notifyAll，它们等待的是被notify或notifyAll，而不是锁。

    注意：必须在synchronized中 才能使用 wait(),notity(), wait（）会释放锁，如果唤醒后，需要重新获得锁才能继续执行

* **线程的run()和start()的区别**

  一个是线程执行的方法；

  一个是启动线程，使其到达可运行的状态；

* **为什么需要线程池**

  - **它帮我们管理线程，避免增加创建线程和销毁线程的资源损耗**。因为线程其实也是一个对象，创建一个对象，需要经过类加载过程，销毁一个对象，需要走GC垃圾回收流程，都是需要资源开销的。

  - **提高响应速度。** 如果任务到达了，相对于从线程池拿线程，重新去创建一条线程执行，速度肯定慢很多。

  - **重复利用。** 线程用完，再放回池子，可以达到重复利用的效果，节省资源。

    总结：

    1. 线程复用
    2. 控制最大并发数
    3. 管理线程

* **创建线程池有哪几种方式**

  1.`Executors`是一个线程相关的工具类。

  2.ThreadPoolExecutor

* **线程池的几个重要参数，如何合理配置线程池的大小**

  几个核心参数的作用：

  - **corePoolSize：** 线程池核心线程数最大值

    CPU核数 = Runtime.getRuntime().availableProcessors()

    分析下线程池处理的程序是CPU密集型还是IO密集型

    CPU密集型：corePoolSize = CPU核数 + 1 

    ​	cpu占用率高，尽量少开线程。

    IO密集型：corePoolSize = CPU核数 * 2
    	因为IO操作不占用CPU，不要让CPU闲下来，应加大线程数量，增加cpu的利用率。

  - **maximumPoolSize：** 线程池最大线程数大小

  - **keepAliveTime：** 线程池中非核心线程空闲的存活时间大小

  - **unit：** 线程空闲存活时间单位

  - **workQueue：** 存放任务的阻塞队列

  - **threadFactory：** 用于设置创建线程的工厂，可以给创建的线程设置有意义的名字，可方便排查问题。

  - **handler：** 线城池的饱和策略事件，主要有四种类型。

    如何设置参数
    默认值：

    corePoolSize = 1

    maxPoolSize = Integer.MAX_VALUE

    queueCapacity = Integer.MAX_VALUE

    keepAliveTime = 60s

    allowCoreThreadTimeout = false

    rejectedExecutionHandler = AbortPolicy()

    **如何来设置呢？**

    需要根据几个值来决定

    tasks ：每秒的任务数，假设为500~1000

    taskcost：每个任务花费时间，假设为0.1s

    responsetime：系统允许容忍的最大响应时间，假设为1s

    做几个计算

    corePoolSize = 每秒需要多少个线程处理？

    threadcount = tasks/(1/taskcost) = tasks*taskcout = (500 ~ 1000)*0.1 = 50~100 个线程。

    corePoolSize设置应该大于50。

    根据8020原则，如果80%的每秒任务数小于800，那么corePoolSize设置为80即可。

    queueCapacity = (coreSizePool/taskcost)*responsetime

    计算可得 queueCapacity = 80/0.1*1 = 800。意思是队列里的线程可以等待1s，超过了的需要新开线程来执行。

    切记不能设置为Integer.MAX_VALUE，这样队列会很大，线程数只会保持在corePoolSize大小，当任务陡增时，不能新开线程来执行，响应时间会随之陡增。

    maxPoolSize 最大线程数在生产环境上我们往往设置成corePoolSize一样，这样可以减少在处理过程中创建线程的开销。

    rejectedExecutionHandler：根据具体情况来决定，任务不重要可丢弃，任务重要则要利用一些缓冲机制来处理。

    keepAliveTime和allowCoreThreadTimeout采用默认通常能满足。

    以上都是理想值，实际情况下要根据机器性能来决定。如果在未达到最大线程数的情况机器cpu load已经满了，则需要通过升级硬件和优化代码，降低taskcost来处理。
    队列的选择：主要有3种类型的BlockingQueue可供选择：

    `无界队列`，可能导致oom，导致cpu和内存飙升服务器挂掉。例如，在 Web 页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。

    `有界队列`当使用有限的 maximumPoolSizes 时，有界队列有助于防止资源耗尽，但是可能较难调整和控制。常用的有两类，一类是遵循FIFO原则的队列如ArrayBlockingQueue，另一类是优先级队列如PriorityBlockingQueue。PriorityBlockingQueue中的优先级由任务的Comparator决定。

    使用有界队列时队列大小需和线程池大小互相配合，线程池较小有界队列较大时可减少内存消耗，降低cpu使用率和上下文切换，但是可能会限制系统吞吐量。

    `同步移交`如果不希望任务在队列中等待而是希望将任务直接移交给工作线程，可使用SynchronousQueue作为等待队列。SynchronousQueue不是一个真正的队列，而是一种线程之间移交的机制。要将一个元素放入SynchronousQueue中，必须有另一个线程正在等待接收这个元素。只有在使用无界线程池或者有饱和策略时才建议使用该队列。

* **线程池的实现原理和线程的调度过程**

  1. 线程复用

  2. 控制最大并发数

  3. 管理线程

     调度过程：

     - 提交一个任务，线程池里存活的核心线程数小于线程数corePoolSize时，线程池会创建一个核心线程去处理提交的任务。
     - 如果线程池核心线程数已满，即线程数已经等于corePoolSize，一个新提交的任务，会被放进任务队列workQueue排队等待执行。
     - 当线程池里面存活的线程数已经等于corePoolSize了,并且任务队列workQueue也满，判断线程数是否达到maximumPoolSize，即最大线程数是否已满，如果没到达，创建一个非核心线程执行提交的任务。
     - 如果当前的线程数达到了maximumPoolSize，还有新的任务过来的话，直接采用拒绝策略处理。

* **线程池有哪些状态**

  **RUNNING**

  - 该状态的线程池会接收新任务，并处理阻塞队列中的任务;
  - 调用线程池的shutdown()方法，可以切换到SHUTDOWN状态;
  - 调用线程池的shutdownNow()方法，可以切换到STOP状态;

  **SHUTDOWN**

  - 该状态的线程池不会接收新任务，但会处理阻塞队列中的任务；
  - 队列为空，并且线程池中执行的任务也为空,进入TIDYING状态;

  **STOP**

  - 该状态的线程不会接收新任务，也不会处理阻塞队列中的任务，而且会中断正在运行的任务；
  - 线程池中执行的任务为空,进入TIDYING状态;

  **TIDYING**

  - 该状态表明所有的任务已经运行终止，记录的任务数量为0。
  - terminated()执行完毕，进入TERMINATED状态

  **TERMINATED**

  - 该状态表示线程池彻底终止

* **线程池的submit()和execute()的区别**

  execute()方法实际上是Executor中声明的方法，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，通过这个方法可以向线程池提交一个任务，交由线程池去执行。

  submit()方法是在ExecutorService中声明的方法，在AbstractExecutorService就已经有了具体的实现，在ThreadPoolExecutor中并没有对其进行重写，这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果，去看submit()方法的实现，会发现它实际上还是调用的execute()方法，只不过它利用了Future来获取任务执行结果

* **在java程序中怎么保证多线程的运行安全**

  1. 使用synchronied关键字，可以用于代码块，方法（静态方法，同步锁是当前字节码对象；实例方法，同步锁是实例对象）
  2. 使用volatile 关键字，防止指令重排，被volatile修饰的变量的值，将不会被本地线程缓存，所有对该变量的读写都是直接操作共享内存，从而确保多个线程能正确的处理该变量
  3. lock锁机制

  手动锁示例代码：

  ```java
  Lock lock = new ReentrantLock();
  lock. lock();
  try {
      System. out. println("获得锁");
  } catch (Exception e) {
      // TODO: handle exception
  } finally {
      System. out. println("释放锁");
      lock. unlock();
  }
  ```

  4. 使用线程安全的类，比如Vector、HashTable、StringBuffer，juc下的类

* **多线程锁的升级原理**（jdk6以后默认开启偏向锁）

  synchronized用的锁存在Java对象头里，Java对象头里的Mark Word默认存储对象的HashCode、分代年龄和锁标记位。在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。

  锁的级别从低到高：不可降级

  无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁

  锁分级别原因：

  没有优化以前，synchronized是重量级锁（悲观锁），使用 wait 和 notify、notifyAll 来切换线程状态非常消耗系统资源；线程的挂起和唤醒间隔很短暂，这样很浪费资源，影响性能。所以 JVM 对 synchronized 关键字进行了优化，把锁分为 无锁、偏向锁、轻量级锁、重量级锁 状态。

  1、无锁：
  没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功，其他修改失败的线程会不断重试直到修改成功。

  2、偏向锁：
  偏向锁的核心思想就是锁会偏向第一个获取它的线程，该线程是不会主动释放偏向锁的，只有当其他线程尝试竞争偏向锁才会被释放。在接下来的执行过程中该锁没有其他的线程获取，则持有偏向锁的线程永远不需要再进行同步。

  当一个线程访问同步块并获取锁的时候，会在对象头和栈帧中的锁记录里存储偏向的线程 ID，以后该线程在进入和退出同步块时不需要进行 CAS 操作来加锁和解锁，只需要检查当前 Mark Word 中存储的线程是否为当前线程，如果是，则表示已经获得对象锁；否则，需要测试 Mark Word 中偏向锁的标志是否为1，如果没有则使用 CAS 操作竞争锁，如果设置了，则尝试使用 CAS 将对象头的偏向锁指向当前线程。

  偏向锁的撤销，需要在某个时间点上没有字节码正在执行时，先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着。如果线程不处于活动状态，则将对象头设置成无锁状态，并撤销偏向锁；如果线程处于活动状态，升级为轻量级锁的状态。

  3、轻量级锁：
  轻量级锁是指当锁是偏向锁的时候，被第二个线程 B 所访问，此时偏向锁就会升级为轻量级锁，线程 B 会通过自旋的形式尝试获取锁，线程不会阻塞，从而提高性能。

  当前只有一个等待线程，则该线程将通过自旋进行等待。但是当自旋超过一定的次数时，轻量级锁便会升级为重量级锁；当一个线程已持有锁，另一个线程在自旋，而此时又有第三个线程来访时，轻量级锁也会升级为重量级锁。

  4、重量级锁：
  指当有一个线程获取锁之后，其余所有等待获取该锁的线程都会处于阻塞状态。

  重量级锁将程序运行交出控制权，将线程挂起，由操作系统来负责线程间的调度，负责线程的阻塞和执行。这样会出现频繁地对线程运行状态的切换，线程的挂起和唤醒，消耗大量的系统资源，导致性能低下。

  重量级锁通过对象内部的监视器（monitor）实现，而其中 monitor 的本质是依赖于底层操作系统的 Mutex Lock 实现，操作系统实现线程之间的切换需要从用户态切换到内核态，切换成本非常高。

  锁状态对比

  ![](https://img-blog.csdnimg.cn/20200620154814777.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzk0NjQ2Mg==,size_16,color_FFFFFF,t_70#pic_center)

  synchronized优化-锁消除:

  　　消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下StringBuffer的append是一个同步方法，但是在add方法中的StringBuffer属于一个局部变量，并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。

  https://blog.csdn.net/weixin_38481963/article/details/88384493

  [一个好的理解就是上面这个链接](https://blog.csdn.net/weixin_38481963/article/details/88384493)

* **什么是死锁，该怎么防止**

  **定义**：线程死锁是指由于两个或者多个线程互相持有对方所需要的资源，导致这些线程处于等待状态，无法前往执行。当线程进入对象的synchronized代码块时，便占有了资源，直到它退出该代码块或者调用wait方法，才释放资源，在此期间，其他线程将不能进入该代码块。当线程互相持有对方所需要的资源时，会互相等待对方释放资源，如果线程都不主动释放所占有的资源，将产生死锁。

  当然死锁的产生是必须要满足一些特定条件的：
  1.互斥条件：进程对于所分配到的资源具有排它性，即一个资源只能被一个进程占用，直到被该进程释放
  2.请求和保持条件：一个进程因请求被占用资源而发生阻塞时，对已获得的资源保持不放。
  3.不剥夺条件：任何一个资源在没被该进程释放之前，任何其他进程都无法对他剥夺占用
  4.循环等待条件：当发生死锁时，所等待的进程必定会形成一个环路（类似于死循环），造成永久阻塞。
  **如何防止**：

  加锁顺序：

  ​	当多个线程需要相同的一些锁，但是按照不同的顺序加锁，死锁就很容易发生。

  如果能确保所有的线程都是按照相同的顺序获得锁，那么死锁就不会发生。

  加锁时限

  ​	另外一个可以避免死锁的方法是在尝试获取锁的时候加一个超时时间，这也就意味着在尝试获取锁的过程中若超过了这个时限该线程则放弃对该锁请求。若一个线程没有在给定的时限内成功获得所有需要的锁，则会进行回退并释放所有已经获得的锁，然后等待一段随机的时间再重试。这段随机的等待时间让其它线程有机会尝试获取相同的这些锁，并且让该应用在没有获得锁的时候可以继续运行(译者注：加锁超时后可以先继续运行干点其它事情，再回头来重复之前加锁的逻辑)。

  死锁检测

  ​	死锁检测是一个更好的死锁预防机制，它主要是针对那些不可能实现按序加锁并且锁超时也不可行的场景。

  每当一个线程获得了锁，会在线程和锁相关的数据结构中（map、graph等等）将其记下。除此之外，每当有线程请求锁，也需要记录在这个数据结构中。

  当一个线程请求锁失败时，这个线程可以遍历锁的关系图看看是否有死锁发生。例如，线程A请求锁7，但是锁7这个时候被线程B持有，这时线程A就可以检查一下线程B是否已经请求了线程A当前所持有的锁。如果线程B确实有这样的请求，那么就是发生了死锁（线程A拥有锁1，请求锁7；线程B拥有锁7，请求锁1）。

  当然，死锁一般要比两个线程互相持有对方的锁这种情况要复杂的多。线程A等待线程B，线程B等待线程C，线程C等待线程D，线程D又在等待线程A。线程A为了检测死锁，它需要递进地检测所有被B请求的锁。从线程B所请求的锁开始，线程A找到了线程C，然后又找到了线程D，发现线程D请求的锁被线程A自己持有着。这是它就知道发生了死锁。那么当检测出死锁时，这些线程该做些什么呢？

  一个可行的做法是释放所有锁，回退，并且等待一段随机的时间后重试。这个和简单的加锁超时类似，不一样的是只有死锁已经发生了才回退，而不会是因为加锁的请求超时了。虽然有回退和等待，但是如果有大量的线程竞争同一批锁，它们还是会重复地死锁（编者注：原因同超时类似，不能从根本上减轻竞争）。

  一个更好的方案是给这些线程设置优先级，让一个（或几个）线程回退，剩下的线程就像没发生死锁一样继续保持着它们需要的锁。如果赋予这些线程的优先级是固定不变的，同一批线程总是会拥有更高的优先级。为避免这个问题，可以在死锁发生的时候设置随机的优先级。

* **ThreadLocal是什么，原理，有哪些使用场景**

  定义：ThreadLocal在每个线程中对该变量会创建一个副本，即每个线程内部都会有一个该变量，而且线程内部任何地方都可以使用，线程之间互不影响，这样一来就不存在线程安全问题，也不会影响程序执行性能。

  但是要注意，虽然ThreadLocal能够解决上面说的问题，但是由于每个线程都创建副本，所以要考虑它对资源的消耗，比如内存的占用会比不使用ThreadLocal要大。

  原理：

  get()方法是用来获取ThreadLocal在当前线程中保存的变量副本，

  set()用来设置当前线程中变量的副本，

  remove()用来移除当前线程中变量的副本，

  initialValue()是一个protected方法，一般是用来在使用时进行重写的，它是一个延迟加载方法。

  首先，在每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，这个threadLocals就是用来存储实际的变量副本的，键值为当前ThreadLocal变量，value为变量副本（即T类型的变量）。

  初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，就会对Thread类中的threadLocals进行初始化，并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，存到threadLocals。

  ​    然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找。

  使用场景：

  数据库连接

  ```java
  package OSChina.Thread;
  
  import java.sql.Connection;
  import java.sql.DriverManager;
  
  public class ThreadDao {
      private static ThreadLocal<Connection> connectionHolder = new ThreadLocal<Connection>();
      public Connection initialValue(){
          return DriverManager.getConnection(DB_URL);
      }
      
      public static Connection getConnection(){
          return connectionHolder.get();
      }
  }
  ```

  session管理：

  ```java
  package OSChina.Thread;
  
  import javax.websocket.Session;
  
  public class ThreadDao {
      private static final ThreadLocal threadSession = new ThreadLocal();
      public static Session getSession() throws Exception{
          Session session = (Session)threadSession.get();
          if(session==null){
              session = getSessionFactory().openSession();
              threadSession.set(session);
          }
          return session;
      }
  }
  ```

* **ThreadLocal什么时候会出现OOM，为什么**

  ThreadLocal里面使用了一个存在**弱引用**的map,当释放掉threadlocal的强引用以后,map里面的value却没有被回收.而这块value永远不会被访问到了. 所以存在着内存泄露. 最好的做法是将调用threadlocal的remove方法.

  在threadlocal的生命周期中,都存在这些引用. 看下图: 实线代表强引用,虚线代表弱引用.


  每个thread中都存在一个map, map的类型是ThreadLocal.ThreadLocalMap。 Map中的key为一个Threadlocal实例. 这个Map的确使用了弱引用,不过弱引用只是针对key. 每个key都弱引用指向threadlocal. 当把threadlocal实例置为null以后,没有任何强引用指向threadlocal实例,所以threadlocal将会被gc回收. 但是,我们的value却不能回收,因为存在一条从current thread连接过来的强引用. 只有当前thread结束以后, current thread就不会存在栈中,强引用断开, Current Thread, Map, value将全部被GC回收.
  　　

  所以得出一个结论就是只要这个线程对象被gc回收，就不会出现内存泄露，但在threadLocal设为null和线程结束这段时间不会被回收的，就发生了我们认为的内存泄露。其实这是一个对概念理解的不一致，也没什么好争论的。最要命的是线程对象不被回收的情况，这就发生了真正意义上的内存泄露。比如使用线程池的时候，线程结束是不会销毁的，会再次使用的。就可能出现内存泄露。

  PS.Java为了最小化减少内存泄露的可能性和影响，在ThreadLocal的get,set的时候都会清除线程Map里所有key为null的value。所以最怕的情况就是，threadLocal对象设null了，开始发生“内存泄露”，然后使用线程池，这个线程结束，线程放回线程池中不销毁，这个线程一直不被使用，或者分配使用了又不再调用get,set方法，那么这个期间就会发生真正的内存泄露。

  划重点-总结一下：

  ThreadLocal是什么？
  每个线程在对内存中开辟的一块工作内存，同时把线程的共享数据拷贝了一份放进去，相当于做的本地副本，不会像synchronized一样每次修改都要同步到主内存中
  ThreadLocal有什么用？
  工作线程的数据交互主要是本地数据和主内存数据的交互，当数据存储在本地内存中，可以大大提高读取效率，避免了线程阻塞造成的cpu的吞吐下降；
  在多线程中每个线程中都要维护sesion，可以提高对独有资源的工作效率；
  发生内存泄露原因？
  synchornized是保证了主内存数据的一致，是时间换空间：通过阻塞一个共享变量，共享一小块内存空间；
  threadLocal是通过建立线程的副本数据，空间换时间
  ThreadLocalMap的Key为弱引用，当threadlocal对象被回收（value在ThreadLocalMap调用get、set、remove的时候就会被清除），这时将key设置为null的entry。但是threadlocal一直不会被回收，导致内存的泄露
  如何避免呢？
  其实在调用threalocalMap的get/set方法时，会对key=null的entry（threadlocal对象=null）进行回收，也可以在调用结束时调用remove方法进行释放。

  **下面是另外的博客的不错的解释：可以对比理解。**

  在ThreadLocal的生命周期中，都存在这些引用。看下图: **实线代表强引用，虚线代表弱引用。**

  ![0?wx_fmt=png](https://ss.csdn.net/p?http://mmbiz.qpic.cn/mmbiz_png/UtWdDgynLdasicN3xUZAG3e71xejQk0F5gXenp950M8DDaOSibicOYVKzpHvudd3u4SzMQD0gr2PQsCicUjt10bvuQ/0?wx_fmt=png)2、ThreadLocal的实现是这样的：每个Thread 维护一个 `ThreadLocalMap` 映射表，这个映射表的 key 是 `ThreadLocal`实例本身，value 是真正需要存储的 Object。

  3、也就是说 `ThreadLocal` 本身并不存储值，它只是作为一个 key 来让线程从 `ThreadLocalMap` 获取 value。值得注意的是图中的虚线，表示 `ThreadLocalMap` 是使用 `ThreadLocal` 的弱引用作为 Key 的，弱引用的对象在 GC 时会被回收。

  4、ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：**`Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value`**永远无法回收，造成内存泄漏。

  5、总的来说就是，ThreadLocal里面使用了一个存在弱引用的map, map的类型是`ThreadLocal.ThreadLocalMap.` Map中的key为一个threadlocal实例。这个Map的确使用了**弱引用**，不过弱引用只是针对key。每个key都弱引用指向threadlocal。 当把threadlocal实例置为null以后，没有任何强引用指向threadlocal实例，所以threadlocal将会被gc回收。

  但是，我们的value却不能回收，而这块value永远不会被访问到了，所以存在着内存泄露。因为存在一条从`current thread`连接过来的强引用。只有当前thread结束以后，`current thread`就不会存在栈中，强引用断开，Current Thread、Map value将全部被GC回收。最好的做法是将调用threadlocal的remove方法，这也是等会后边要说的。

  6、其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：**在ThreadLocal的****`get(),set(),remove()`的时候都会清除线程ThreadLocalMap里所有key为null的value**。这一点在上一节中也讲到过！

  7、但是这些被动的预防措施并不能保证不会内存泄漏：

  1. `（1）使用static的ThreadLocal，延长了ThreadLocal的生命周期，可能导致内存泄漏。`
  2. `（2）分配使用了ThreadLocal又不再调用get(),set(),remove()方法，那么就会导致内存泄漏，因为这块内存一直存在。`

  三、为什么使用弱引用，OOM是否是弱引用的锅？

  1、从表面上看内存泄漏的根源在于使用了弱引用。网上的文章大多着重分析ThreadLocal使用了弱引用会导致内存泄漏，但是另一个问题也同样值得思考：**为什么使用弱引用而不是强引用？**

  我们先来看看官方文档的说法：

  ![0?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/UtWdDgynLdasicN3xUZAG3e71xejQk0F52cAG5zjKkuHQRBHg6IJFTrglJn7rWOibWTquPaWd8ajFleSIzO2cicsg/0?wx_fmt=png)

  下面我们分两种情况讨论：

  **（1）key 使用强引用**：引用的`ThreadLocal`的对象被回收了，但是`ThreadLocalMap`还持有`ThreadLocal`的强引用，如果没有手动删除，`ThreadLocal`不会被回收，导致Entry内存泄漏。

  **（2）key 使用弱引用**：引用的ThreadLocal的对象被回收了，由于`ThreadLocalMap`持有`ThreadLocal`的弱引用，即使没有手动删除，`ThreadLocal`也会被回收。`value`在下一次`ThreadLocalMap`调用`set、get、remove`的时候会被清除。

  比较两种情况，我们可以发现：由于`ThreadLocalMap`的生命周期跟Thread一样长，如果都没有手动删除对应key，**都会**导致内存泄漏，但是**使用弱引用可以多一层保障**：**弱引用****`ThreadLocal`不会内存泄漏，对应的value在下一次`ThreadLocalMap`调用`set、get、remove`的时候会被清除。**

  因此，ThreadLocal内存泄漏的根源是：**由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。**

* **volatile是什么，原理，有哪些使用场景**

  被volatile修饰的变量能够保证每个线程能够获取该变量的最新值，从而避免出现数据脏读的现象。

  原理：在生成汇编代码时会在volatile修饰的共享变量进行写操作的时候会多出Lock前缀的指令。

  主要有这两个方面的影响：

  1. 将当前处理器缓存行的数据写回系统内存；

  2. 通过MESI缓存一致性协议，总线嗅探机制使这个写回内存的操作会使得其他CPU里缓存了该内存地址的数据无效

     当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值。

     这样针对volatile变量通过这样的机制就使得每个线程都能获得该变量的最新值。

     volatile保证了可见性，有序性（被volatile修饰的变量，严格按照代码编写顺序执行，禁止指令重排序）。但无法保证原子性。

     使用场景：https://www.cnblogs.com/ouyxy/p/7242563.html

* **说下synchronized底层实现原理**

  jvm中，对象在内存中的布局

  三块区域：对象头、实例数据和对齐填充。

  原理：通过对对象的内置Monitor锁的获取和释放来实现（每个对象都有自己的Monitor监视器锁（对象））。一个线程的执行，首先读取主内存的共享变量需要过去锁，执行Monitor方法 enter方法，不成功的话，进入等待队列，成功的话，同步object对象的属性（这里是有用户态到内核态的切换，费性能）。执行完JMM8大原子操作中的write后，释放锁执行exit方法。唤醒当前锁对象的等待队列。（两个monitorexit是因为一个是正常出口，一个是异常出口。）

  ​	jdk1.6以后：Synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的，监视器锁本质又是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的。而操作系统实现线程之间的切换需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。因此，这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”。

  Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”：锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态。锁可以升级但不能降级。

  这里要注意：

  - synchronized是可重入的，所以不会自己把，自己锁死

    原理：重入锁是指一个线程获取到该锁之后，该线程可以继续获得该锁。**底层原理维护一个计数器，当线程获取该锁时，计数器加一，再次获得该锁时继续加一，释放锁时，计数器减一，当计数器值为0时，表明该锁未被任何线程所持有，其它线程可以竞争获取锁。

  - synchronized锁一旦被一个线程持有，其他试图获取该锁的线程将被阻塞。

* **synchronized锁粒度，原子性和可见性**

  锁粒度：

  粒度为 4 种：
  修饰一个代码块： 一个线程正在访问一个对象中的 synchronized(this 或 其他对象) 同步代码块时，其他试图访问该对象（要是同一个对象）的线程将被阻塞。

  修饰一个普通方法： 在方法的前面加 synchronized，public synchronized void method()，此方法等于修饰整个方法代码块。

  修饰一个静态的方法：public synchronized static void method()，静态方法是属于类的，同样的，synchronized 修饰的静态方法锁定的是这个类的所有对象。

  修饰一个类：synchronized(ClassName.class)，synchronized 作用于一个类时，是给这个类加锁，该类的所有对象都将加同一把锁。

  - 原子性：synchronized保证语句块内操作是原子的
  - 可见性：synchronized保证可见性（通过“在执行unlock之前，必须先把此变量同步回主内存”实现）
  - 有序性：synchronized保证有序性（通过“一个变量在同一时刻只允许一条线程对其进行lock操作”）

* **sychronized和volatile区别**

  volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取； synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。
  volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的
  volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性
  volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。
  volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化（指令重排序）

* **sychronized和Lock区别**

  1、lock是一个接口，而synchronized是java的一个关键字。

  2、synchronized在发生异常时会自动释放占有的锁，因此不会出现死锁；而lock发生异常时，不会主动释放占有的锁，必须手动来释放锁，可能引起死锁的发生，必须在finally{}中释放。

  3、锁的获取：前者阻塞式，后者分情况。

  4、synchronized原始采用的是CPU悲观锁机制，即线程获得的是独占锁。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。而在CPU转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起CPU频繁的上下文切换导致效率很低。

  而Lock用的是乐观锁方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁实现的机制就是CAS操作（Compare and Swap）。我们可以进一步研究ReentrantLock的源代码，会发现其中比较重要的获得锁的一个方法是compareAndSetState。这里其实就是调用的CPU提供的特殊指令。

  现代的CPU提供了指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而 compareAndSet() 就用这些代替了锁定。这个算法称作非阻塞算法，意思是一个线程的失败或者挂起不应该影响其他线程的失败或挂起的算法。

* **sychronized和ReentrantLock区别是什么**

  synchronized原语和ReentrantLock在一般情况下没有什么区别，但是在非常复杂的同步应用中，请考虑使用ReentrantLock，特别是遇到下面2种需求的时候。

  1.某个线程在等待一个锁的控制权的这段时间需要中断
  2.需要分开处理一些wait-notify，ReentrantLock里面的Condition应用，能够控制notify哪个线程
  3.具有公平锁功能，每个到来的线程都将排队等候

  下面细细道来……

  先说第一种情况，ReentrantLock的lock机制有2种，忽略中断锁和响应中断锁，这给我们带来了很大的灵活性。比如：如果A、B 2个线程去竞争锁，A线程得到了锁，B线程等待，但是A线程这个时候实在有太多事情要处理，就是一直不返回，B线程可能就会等不及了，想中断自己，不再等待这个锁了，转而处理其他事情。这个时候ReentrantLock就提供了2种机制：可中断/可不中断
  第一，B线程中断自己（或者别的线程中断它），但是ReentrantLock不去响应，继续让B线程等待，你再怎么中断，我全当耳边风（synchronized原语就是如此）；
  第二，B线程中断自己（或者别的线程中断它），ReentrantLock处理了这个中断，并且不再等待这个锁的到来，完全放弃。

  区别：

  \1. ReentrantLock 显示的获得、释放锁，synchronized 隐式获得释放锁
  \2. ReentrantLock 可响应中断、可轮回，synchronized 是不可以响应中断的，为处理锁的
  不可用性提供了更高的灵活性
  \3. ReentrantLock 是 API 级别的，synchronized 是 JVM 级别的
  \4. ReentrantLock 可以实现公平锁
  \5. ReentrantLock 通过 Condition 可以绑定多个条件
  \6. 底层实现不一样， synchronized 是同步阻塞，使用的是悲观并发策略，lock 是同步非阻
  塞，采用的是乐观并发策略
  \7. Lock 是一个接口，而 synchronized 是 Java 中的关键字，synchronized 是内置的语言
  实现。
  \8. synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；
  而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死锁现象，
  因此使用 Lock 时需要在 finally 块中释放锁。
  \9. Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用 synchronized 时，
  等待的线程会一直等待下去，不能够响应中断。
  \10. 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。
  \11. Lock 可以提高多个线程进行读操作的效率，既就是实现读写锁等

   * 1 原始结构

   * synchronized是关键字，属于jvm层（monitorenter：底层通过monitor来完成的，wait/notify方法也依赖monitor，只有在同步块或者同步方法中才可以调用wait/notify

   * 。monitorexit）

   * ReentrantLock 是具体类，是api层面的锁

   * 2使用方法

   * synchronized不需要用户手动释放锁，当synchronized方法运行完之后系统自动让线程释放锁；

   * ReentrantLock需要用户手动释放锁，如果没有释放，出现死锁现象；需要lcok（）unlock（）方法配合try/finally语法块来释放；

   * 3 等待是否中断

   * synchronized不可中断，除非抛出异常或者运行完成

   * ReentrantLock可中断：1设置超时方法时间truLock（）；2 lcokInterruptibly（）放代码块中，调用interrupt可中断

   * 4 加锁是否公平

   * synchronized非公平锁；

   * ReentrantLock非公平锁/公平锁

   * 5 锁绑定多个条件

   * synchronized没有；

   * ReentrantLock用来实现分组唤醒线程组，可精确唤醒，synchronized是随机唤醒一个或者唤醒全部

    另外的：由于ReentrantLock是java.util.concurrent包下提供的一套互斥锁，相比Synchronized，ReentrantLock类提供了一些高级功能，主要有以下3项：

            1.等待可中断，持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待，这相当于Synchronized来说可以避免出现死锁的情况。通过lock.lockInterruptibly()来实现这个机制。
        
            2.公平锁，多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁，但公平锁表现的性能不是很好。

    公平锁、非公平锁的创建方式：

    //创建一个非公平锁，默认是非公平锁
    Lock lock = new ReentrantLock();
    Lock lock = new ReentrantLock(false);

    //创建一个公平锁，构造传参true
    Lock lock = new ReentrantLock(true);
            3.锁绑定多个条件，一个ReentrantLock对象可以同时绑定对个对象。ReenTrantLock提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的线程们，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。

* **并发工具**

  并发工具 

  CountDownLatch：

  ![img](https://qqadapt.qpic.cn/txdocpic/0/5cc333b6a0453fd123e4fea25bb35742/0?_type=png&w=739&h=366)

  CyclicBarrier：

  ![img](https://qqadapt.qpic.cn/txdocpic/0/22438617eb52ea815d254358001046f2/0?_type=png&w=792&h=601)

  Semaphore：
  
  ![img](https://qqadapt.qpic.cn/txdocpic/0/c75774ecd01315234a8631d134f20c8d/0?_type=png&w=790&h=606)
  
* **说一下atomic的原理**

  定义：一种轻量级的数据同步的选择。

  原理：unsafe是java提供的获得对对象内存地址访问的类，注释已经清楚的写出了，它的作用就是在更新操作时提供“比较并替换”的作用。实际上就是AtomicInteger中的一个工具。

  valueOffset是用来记录value本身在内存的编译地址的，这个记录，也主要是为了在更新操作在内存中找到value的位置，方便比较。

   value是用来存储整数的时间变量，这里被声明为volatile。volatile只能保证这个变量的可见性。不能保证他的原子性。

   可以看看getAndIncrement这个类似i++的函数，可以发现，是调用了UnSafe中的getAndAddInt。

  如何保证原子性：自旋 + CAS（乐观锁）。在这个过程中，通过compareAndSwapInt比较更新value值，如果更新失败，重新获取旧值，然后更新。


  优缺点：
        CAS相对于其他锁，不会进行内核态操作，有着一些性能的提升。但同时引入自旋，当锁竞争较大的时候，自旋次数会增多。cpu资源会消耗很高。

        换句话说，CAS+自旋适合使用在低并发有同步数据的应用场景。

   





  Java 8做出的改进和努力
        在Java 8中引入了4个新的计数器类型，LongAdder、LongAccumulator、DoubleAdder、DoubleAccumulator。他们都是继承于Striped64。

       在LongAdder 与AtomicLong有什么区别？
  Atomic*遇到的问题是，只能运用于低并发场景。因此LongAddr在这基础上引入了分段锁的概念。可以参考《JDK8系列之LongAdder解析》一起看看做了什么。

       大概就是当竞争不激烈的时候，所有线程都是通过CAS对同一个变量（Base）进行修改，当竞争激烈的时候，会将根据当前线程哈希到对于Cell上进行修改（多段锁）。
  可以看到大概实现原理是：通过CAS乐观锁保证原子性，通过自旋保证当次修改的最终修改成功，通过降低锁粒度（多段锁）增加并发性能。

* **知道哪些锁？公平锁和非公平锁区别？可重入锁是什么？**

  https://www.cnblogs.com/jyroy/p/11365935.html

  https://www.cnblogs.com/lxmyhappy/p/7380073.html

  - 公平锁/非公平锁

  - 可重入锁

  - 独享锁/共享锁

  - 互斥锁/读写锁

  - 乐观锁/悲观锁

  - 分段锁

  - 偏向锁/轻量级锁/重量级锁

  - 自旋锁

    ![](https://img-blog.csdnimg.cn/20181122101753671.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2F4aWFvYm9nZQ==,size_16,color_FFFFFF,t_70)

## 反射

* **什么是反射**

  反射就是在运行时才知道要操作的类是什么，并且可以在运行时获取类的完整构造，并调用对应的方法。

  我们了解了 Method 类的 invoke 方法的具体实现方式。知道了原来 invoke 方法内部有两种实现方式，一种是 native 原生的实现方式，一种是 Java 实现方式，这两种各有千秋。而为了最大化性能优势，JDK 源码使用了代理的设计模式去实现最大化性能。

  Native 版本一开始启动快，但是随着运行时间边长，速度变慢。Java 版本一开始加载慢，但是随着运行时间边长，速度变快。正是因为两种存在这些问题，所以第一次加载的时候我们会发现使用的是 NativeMethodAccessorImpl 的实现，而当反射调用次数超过 15 次之后，则使用 MethodAccessorGenerator 生成的 MethodAccessorImpl 对象去实现反射。

* **什么是java序列化？什么情况下需要序列化**

  序列化：将 Java 对象转换成字节流的过程。

  反序列化：将字节流转换成 Java 对象的过程。

  当 Java 对象需要在网络上传输 或者 持久化存储到文件中时，就需要对 Java 对象进行序列化处理。

  序列化的实现：类实现 Serializable 接口，这个接口没有需要实现的方法。实现 Serializable 接口是为了告诉 jvm 这个类的对象可以被序列化。

  注意事项：

  某个类可以被序列化，则其子类也可以被序列化
  声明为 static 和 transient 的成员变量，不能被序列化。static 成员变量是描述类级别的属性，transient 表示临时数据
  反序列化读取序列化对象的顺序要保持一致

* **动态代理是什么？有哪些应用？**

  代理的使用情况：

  (1)设计模式中有一个设计原则是开闭原则，是说对修改关闭对扩展开放，我们在工作中有时会接手很多前人的代码，里面代码逻辑让人摸不着头脑(sometimes the code is really like shit)，这时就很难去下手修改代码，那么这时我们就可以通过代理对类进行增强。

  (2)我们在使用RPC框架的时候，框架本身并不能提前知道各个业务方要调用哪些接口的哪些方法 。那么这个时候，就可用通过动态代理的方式来建立一个中间人给客户端使用，也方便框架进行搭建逻辑，某种程度上也是客户端代码和框架松耦合的一种表现。

  (3)Spring的AOP机制就是采用动态代理的机制来实现切面编程。

  **静态代理和动态代理**

  我们根据加载被代理类的时机不同，将代理分为静态代理和动态代理。如果我们在代码编译时就确定了被代理的类是哪一个，那么就可以直接使用静态代理；如果不能确定，那么可以使用类的动态加载机制，在代码运行期间加载被代理的类这就是动态代理，比如RPC框架和Spring AOP机制。
  我们看到jdk的代理机制必须要求被代理类实现某个方法，这样在生成代理类的时候才能知道重新那些方法。这样一个没有实现任何接口的类就无法通过jdk的代理机制进行代理，当然解决方法是使用cglib的代理机制进行代理。

  

* **怎么实现动态代理**

  一种是**JDK**动态代理，

  一种是CGLIB字节码机制，当然还有Javassist或ASM库

  ```java
  //JDK动态代理，反射机制
  public class MyInvocationHandler implements InvocationHandler{
  	
  	private Object object;
  	
  	public MyInvocationHandler(Object object){
  		this.object = object;
  	}
   
  	@Override
  	public Object invoke(Object proxy, Method method, Object[] args)
  			throws Throwable {
  		// TODO Auto-generated method stub
  		System.out.println("MyInvocationHandler invoke begin");
  		System.out.println("proxy: "+ proxy.getClass().getName());
  		System.out.println("method: "+ method.getName());
  		for(Object o : args){
  			System.out.println("arg: "+ o);
  		}
  		//通过反射调用 被代理类的方法
  		method.invoke(object, args);
  		System.out.println("MyInvocationHandler invoke end");
  		return null;
  	}
  	
  	public static void main(String [] args){
  		//创建需要被代理的类
  		Student s = new Student();
  		//这一句是生成代理类的class文件，前提是你需要在工程根目录下创建com/sun/proxy目录，不然会报找不到路径的io异常
  		System.getProperties().put("sun.misc.ProxyGenerator.saveGeneratedFiles","true");
  		//获得加载被代理类的 类加载器
  		ClassLoader loader = Thread.currentThread().getContextClassLoader();
  		//指明被代理类实现的接口
  		Class<?>[] interfaces = s.getClass().getInterfaces();
  		// 创建被代理类的委托类,之后想要调用被代理类的方法时，都会委托给这个类的invoke(Object proxy, Method method, Object[] args)方法
  		MyInvocationHandler h = new MyInvocationHandler(s);
  		//生成代理类
  		Person proxy = (Person)Proxy.newProxyInstance(loader, interfaces, h);
  		//通过代理类调用 被代理类的方法
  		proxy.sayHello("yujie.wang", 20);
  		proxy.sayGoodBye(true, 100);
  		System.out.println("end");
  	}
  ```

  从上面的例子中可以看出，代理对象的生成是通过`Proxy.newProxyInstance()`来完成的

  ```
  public static Object newProxyInstance(ClassLoader loader,
                                            Class<?>[] interfaces,
                                            InvocationHandler h)
  ```

  `newProxyInstance()`方法主要以下三个参数

  - 类加载器(ClassLoader)用来加载动态代理类
  - 一个要实现接口的数组，从这点就可以看出，要想**使用JDK动态代理，必须要有接口类**
  - InvocactionHandler接口的一个实现

  **cglib**：本质上说，对于需要被代理的类，它只是动态生成一个子类以覆盖非final的方法，同时绑定钩子回调自定义的拦截器。

  添加CGLIB依赖

  ```
   <dependency>
        <groupId>cglib</groupId>
        <artifactId>cglib</artifactId>
        <version>3.2.4</version>
   /dependency>
  复制代码
  package com.pjmike.proxy;
  
  import net.sf.cglib.proxy.Enhancer;
  import net.sf.cglib.proxy.MethodInterceptor;
  import net.sf.cglib.proxy.MethodProxy;
  
  import java.lang.reflect.Method;
  
  /**
   * CGLIB动态代理实现
   *
   * @author pjmike
   * @create 2018-08-06 16:55
   */
  public class CglibProxy {
      public static void main(String[] args) {
          //Enhancer是CGLIB的核心工具类,是一个字节码增强器，它可以方便的对类进行扩展
          Enhancer enhancer = new Enhancer();
          enhancer.setSuperclass(PersonService.class);
          //设置回调所需的拦截器
          enhancer.setCallback(new MyMethodInterceptor());
          //通过enhancer.create()方法获取代理对象
          //对代理对象所有非final的方法调用都会转发给MethodInterceptor.intercept方法,
          //作用跟JDK动态代理的InvocationHandler类似
          PersonService personService = (PersonService) enhancer.create();
          System.out.println(personService.sayHello("pjmike"));
      }
  }
  
  class PersonService {
      public String sayHello(String name) {
          return "Hello, " + name;
      }
  }
  
  class MyMethodInterceptor implements MethodInterceptor {
  
      @Override
      public Object intercept(Object obj, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {
          return methodProxy.invokeSuper(obj, args);
      }
  }
  复制代码
  ```

  至于上面提到的javassist也是需要直接操作字节码，跟ASM类似，所以这两者使用门槛比较高，一般用于框架的底层实现。比如hibernate底层使用了javassist和cglib.

  **实际应用**

  ### 应用一: Spring AOP的动态代理实现

  Spring AOP的动态代理实现主要有两种方式，JDK动态代理和CGLIB字节码生成。

  默认情况下，如果Spring AOP发现目标对象后实现了相应的interface,则采用JDK动态代理机制为其生成代理对象。如果没有发现接口，则采用CGLIB的方式为目标对象生成动态的代理对象实例

  ### 应用二: RPC框架中的应用

  RPC即远程过程调用，它的实现中使用到了动态代理

## 对象拷贝

* **为什么要使用克隆**

  定义：想对一个对象进行处理，又想保留原有的数据进行接下来的操作，就需要克隆了。Java中克隆针对的是类的实例。

  克隆分浅克隆和深克隆，

  **浅克隆**只会复制对象的值类型，而不会复制对象的引用类型

  实现方式：***\*需要克隆的对象必须实现 `Cloneable` 接口，并重写 `clone()` 方法\****

  **深克隆**

  定义：深克隆就是复制整个对象信息，包含值类型和引用类型。 深克隆的实现方式通常包含以下两种。

  实现方式：

  - 序列化实现深克隆：先将原对象序列化到内存的字节流中，再从字节流中反序列化出刚刚存储的对象，这个新对象和原对象就不存在任何地址上的共享，这样就实现了深克隆。（序列化实现方式：Java 原生序列化、JSON 序列化、Hessian 序列化）；

    此方法的好处：能够在编译期进行泛型检查。

  - 所有引用类型都实现克隆：要复制对象的所有引用类型都要实现克隆，所有对象都是复制的新对象，从而实现了深克隆。

* **深拷贝和浅拷贝的区别**

  区别主要在对引用类型的复制上，具体信息如下：

  - 浅克隆：只会复制对象的值类型，而不会复制对象的引用类型；
  - 深克隆：复制整个对象，包含值类型和引用类型。

* **子类为什么不能直接调用object的clone方法**

  1.在Object中，声明如下protected native Object clone() throws CloneNotSupportedException;(由于使用native,无需实现方法体，该方法没有在object实现)。

  2.为什么要这么设计:

  a:clone是浅拷贝，有一定的缺陷

  b:不同的类，其引用类型不一样

## Java Web

* **cookie和session的区别及各自原理**

  **cookie**：

  http协议是一种无状态协议，在不同请求间是无法进行数据传递的，在请求间数据传递的会话技术，就是cookie。

  生成：由服务器生成，保存在客户端。具体：用户第一次请求（/api/user/list）后，服务器生成，在响应头中返回给客户端，客户端收到响应，保存。之后再发送同类请求会携带这个cookie。删除某一浏览器的cookie不会影响到其他浏览器.

  同类请求：如：/api/user/detail

  结构：若干键值对

  使用：第一次请求，response add cookie ，以后request get cookie获取

  可以设置path和过期时间：

  path：资源路径 如果设置path=request.getContextPath+/api/vendor,那么访问/api/vendor才会携带。

  如果设为“/”，则为项目下全部路径有效。如果不设置，规则为，先取截止到最后一个/，如果没有/就设置为/。

  过期时间：默认是浏览器缓存的，关闭就没了，如果设置了过期时间是会保存到硬盘。如果设置为0就是刚创建就销毁了

  **session**：

  一次会话：从打开浏览器，发出第一个请求开始，一直到关闭浏览器。表示一次会话完成。

  K,V

  原理：request.getSession()时，会自动通过cookie携带的JsessinID在session列表里找，如果没有这个id就创建一个32为随机字符串作为这个id，"JsessinID":JsessinID写入cookie。并且创建一个session。

  失效时间：默认30min，指的是最后一个访问开始。

  如果禁用cookie：

  将导致服务端response中的set-cookie：jsessionid=fff无效，下次请求服务器接收不到cookie中jsessionid，就认为是一次新的请求新的会话，会创建新的session

  会话结束：对于用户表明是关闭了浏览器，实际上是session失效。

  如：用户关闭了浏览器，只是把浏览器缓存中cookie：jsessionid删了，实际这个session存在，信息也就存在，倘若把cookie禁用，把jsessionid记下来，拼到url后面“;jsessionid=fsf”，还是能发送这个jsessionid的，这个session仍可用。

  禁用了cookie重定向问题：

  从/a进入，设置了session，然后从定向到/b，/b中访问不到数据的。如果想访问到，把重定向的路径localhost：8080/b 进行 url=response.encodeRedirectURL(url),就是自动拼接;jsessionid=fsf。但是不安全。

  禁用了cookie非重定向问题：

  esponse.encodeURL

  域空间：

  ServletContext，即application，整个应用跨回话。

  HttpSession，会话范围内的，跨请求。

  HttpServletRequest，同一请求。

  **Cookie和Session的区别**

  1、存放位置不同

  Cookie保存在客户端，Session保存在服务端。

  2 、存取方式的不同

   Cookie中只能保管ASCII字符串，假如需求存取Unicode字符或者二进制数据，需求先进行编码。Cookie中也不能直接存取Java对象。若要存储略微复杂的信息，运用Cookie是比拟艰难的。 

  而Session中能够存取任何类型的数据，包括而不限于String、Integer、List、Map等。Session中也能够直接保管Java Bean乃至任何Java类，对象等，运用起来十分便当。能够把Session看做是一个Java容器类。 

  3、安全性（隐私策略）的不同 

  Cookie存储在浏览器中，对客户端是可见的，客户端的一些程序可能会窥探、复制以至修正Cookie中的内容。而Session存储在服务器上，对客户端是透明的，不存在敏感信息泄露的风险。 假如选用Cookie，比较好的方法是，敏感的信息如账号密码等尽量不要写到Cookie中。最好是像Google、Baidu那样将Cookie信息加密，提交到服务器后再进行解密，保证Cookie中的信息只要本人能读得懂。而假如选择Session就省事多了，反正是放在服务器上，Session里任何隐私都能够有效的保护。 

  4、有效期上的不同 

  只需要设置Cookie的过期时间属性为一个很大很大的数字，Cookie就可以在浏览器保存很长时间。 由于Session依赖于名为JSESSIONID的Cookie，而Cookie JSESSIONID的过期时间默许为–1，只需关闭了浏览器（一次会话结束），该Session就会失效。

  5、对服务器造成的压力不同 

  Session是保管在服务器端的，每个用户都会产生一个Session。假如并发访问的用户十分多，会产生十分多的Session，耗费大量的内存。而Cookie保管在客户端，不占用服务器资源。假如并发阅读的用户十分多，Cookie是很好的选择。

  6、 跨域支持上的不同 

  Cookie支持跨域名访问，例如将domain属性设置为“.baidu.com”，则以“.baidu.com”为后缀的一切域名均能够访问该Cookie。跨域名Cookie如今被普遍用在网络中。而Session则不会支持跨域名访问。Session仅在他所在的域名内有效。
  

* **如果客户端禁止cookie能实现session还能用吗**

  一般默认情况下，在会话中，服务器存储 session 的 sessionid 是通过 cookie 存到浏览器里。

  如果浏览器禁用了 cookie，浏览器请求服务器无法携带 sessionid，服务器无法识别请求中的用户身份，session失效，会不停的生成sessionid。

  但是可以通过其他方法在禁用 cookie 的情况下，可以继续使用session。

  - 通过url重写，把 sessionid 作为参数追加的原 url 中，后续的浏览器与服务器交互中携带 sessionid 参数。
  - 服务器的返回数据中包含 sessionid，浏览器发送请求时，携带 sessionid 参数。
  - 通过 Http 协议其他 header 字段，服务器每次返回时设置该 header 字段信息，浏览器中 js 读取该 header 字段，请求服务器时，js设置携带该 header 字段。

* **什么XSS攻击，怎么避免**

  是一种代码注入攻击。攻击者通过在目标网站上注入恶意脚本，使之在用户的浏览器上运行。利用这些恶意脚本，攻击者可获取用户的敏感信息如 Cookie、SessionID 等，进而危害数据安全。

  避免：输入过滤、转义html、、、

* **什么是CSRF（跨站请求伪造）攻击，怎么避免**

  XSS 利用的是站点内的信任用户，而 CSRF 则通过伪装成（假冒）站点内的信用用户，执行该用户不知情的操作。

  **实例**：

  比如，现在有一个受害者 Bob ，在网站 http://bank.example/ 中有一笔存款。

  Bob 通过对银行的网站发送请求 http://bank.example/withdraw?account=bob&amount=1000000&for=bob2 ，可以使 Bob 把 1000000 的存款转到 bob2 的账号下。

  通常情况下，该请求发送到银行网站后，服务器会先验证该请求是否来自一个合法的 session，该 session 的用户 Bob 已经成功登陆。

  黑客 Mallory 自己在该银行也有账户，他知道银行网站转账操作的 URL。

  Mallory 可以自己发送一个请求给银行：http://bank.example/withdraw?account=bob&amount=1000000&for=Mallory ， 但是这个请求来自 Mallory 而非 Bob，他不能通过安全认证，因此该请求不会起作用。

  这时，Mallory 想到使用 CSRF 的攻击方式，他先自己做一个网站 B，在网站 B中放入如下代码： src=”http://bank.example/withdraw?account=bob&amount=1000000&for=Mallory ”，并且通过广告等方式诱使 Bob 来访问他的网站。

  当 Bob 访问网站 B 时，上述 url 就会从 Bob 的浏览器发向银行，并且这个请求会附带 Bob 浏览器中的 cookie 一起发向银行服务器。

  当然，大多数情况下，该请求会失败，因为银行网站要求 Bob 的认证信息。

  但是，如果 Bob 当时恰巧刚访问银行网站后不久，他的浏览器与银行网站之间的 session 尚未过期（比如 Bob 还未退出银行网站），而浏览器的 cookie 中含有 Bob 的认证信息，银行网站的对应 session 数据还存在。

  这时，悲剧就发生了，这个 url 请求就会得到响应，钱将从 Bob 的账号转移到 Mallory 的账号，而 Bob 当时毫不知情。

  等以后 Bob 发现账户钱少了，即使他去银行查询流水，他也只能发现确实有一个来自于他本人的合法请求转移了资金，没有任何被攻击的痕迹。

  在这个示例中，银行网站却错误地认为，这个转账操作是 Bob 执行的。
  **避免**：

  1.验证 HTTP Referer 字段
  2.在请求地址中添加 token 并验证
  3.在 HTTP 头中自定义属性并验证

* **单点登录的原理**

  单点登录全称Single Sign On（以下简称SSO）。

  [单点登录](https://www.cnblogs.com/ywlaker/p/6113927.html)

  原理：

  相比于单系统登录，sso需要一个独立的认证中心，只有认证中心能接受用户的用户名密码等安全信息，其他系统不提供登录入口，只接受认证中心的间接授权。间接授权通过令牌实现，sso认证中心验证用户的用户名密码没问题，创建授权令牌，在接下来的跳转过程中，授权令牌作为参数发送给各个子系统，子系统拿到令牌，即得到了授权，可以借此创建局部会话，局部会话登录方式与单系统的登录方式相同。这个过程，也就是单点登录的原理

* **你们jwt（json web token）中包含哪些信息？**

  [参考](http://www.ruanyifeng.com/blog/2018/07/json_web_token-tutorial.html)

* **项目中的搜索功能是怎么实现的？ES+kibana  ik分词**

* **elasticsearch的主从、字符串类型是哪个、nested类型是什么、聚合怎么写、查询某个id的语句、创建es的索引、时间类型怎么存的（我说了个utc...他说utc的话你的时间得+8，我蒙了）**

* **引入第三方登录时，怎么使得你自己的token和第三方的token关联起来？**

* **服务端如何防止表单重复提交**

  js禁掉提交按钮
  表单提交后使用Javascript使提交按钮disable。这种方法防止心急的用户多次点击按钮。但是如果客户端把Javascript给禁用的话，这种方法就无效了。

  使用Post/Redirect/Get模式
  在提交后执行页面重定向，这就是所谓的Post-Redirect-Get (PRG)模式。当用户提交了表单后，去执行一个客户端的重定向，转到提交成功信息页面，这能避免用户按F5导致的重复提交，而其也不会出现浏览器表单重复提交的警告，也能消除按浏览器前进和后退按导致的同样问题。

  在session中存放一个特殊标志
  在服务器端，生成一个唯一的标识符，将它存入session，同时将它写入表单的隐藏字段中，然后将表单页面发给浏览器，用户录入信息后点击提交，在服务器端，获取表单中隐藏字段的值，与session中的唯一标识符比较，相等说明是首次提交，就处理本次请求，然后将session中的唯一标识符移除；不相等说明是重复提交，就不再处理，这样Web应用有了更高级的XSRF保护。

  在数据库里添加约束
  在数据库里添加唯一约束或创建唯一索引，防止出现重复数据。这是最有效的防止重复提交数据的方法。

  使用Cookie处理
  使用Cookie记录表单提交的状态，根据其状态可以检查是否已经提交表单

* **打印日志的框架，错误日志怎么配置**

  如：Slf4j.

* **网络抖动，重复提交，怎么处理幂等性**

  **幂等性**指任意多次执行所产生的影响均与一次执行的影响相同。多次调用对系统的产生的影响是一样的，即对资源的作用是一样的，但是返回值允许不同。在我们编程中主要操作就是CURD，其中读取（Retrieve）操作和删除（Delete）操作是天然幂等的，受影响的就是创建（Create）、更新（Update）。

  <img src="https://pic4.zhimg.com/80/v2-be9789ec26d66644c71d5c1ccadba78f_1440w.jpg" style="zoom:67%;" />

  * redis+token机制

    <img src="https://pic2.zhimg.com/80/v2-f751ac6f6156414a759cb6b8c6b238bd_1440w.jpg" style="zoom:67%;" />

    每次请求：先掉接口获取token（服务端同时把token放到redis中），然后携带token，请求业务接口，服务端判断是否存在该token，若存在，则为第一次请求。执行完，把token删掉

    缺点：每次请求都调两次，一次获取token，一次携带判断。

  * 去重表机制

    往去重表里插入数据的时候，利用数据库的唯一索引特性，保证唯一的逻辑。唯一序列号可以是一个字段，也可以是多字段的唯一性组合。

    

    ![img](https://pic1.zhimg.com/80/v2-f4cadeaf3234b2527e3c8c131845ef30_1440w.jpg)

    

    这里要注意的是，**去重表和业务表应该在同一库中**，这样就保证了在同一个事务，即使业务操作失败了，也会把去重表的数据回滚。**这个很好的保证了数据一致性**。

    另外，使用数据库防重表的方式它有个严重的缺点，那就是系统容错性不高，如果幂等表所在的数据库连接异常或所在的服务器异常，则会导致整个系统幂等性校验出问题。

  * ### **乐观锁机制**

    乐观锁解决了计算赋值型的修改场景。例如：

    ```sql
    update user 
    set point = point + 20, version = version + 1
     where
    userid=1
     and
     version=1
    ```

    加上了版本号后，就让此计算赋值型业务，具备了幂等性。

    ### **乐观锁缺点**

    在操作业务前，需要先查询出当前的version版本。

    ### **唯一主键机制**

    这个机制是**利用了数据库的主键唯一约束的特性**，解决了在**insert场景**时幂等问题。但主键的要求不是自增的主键，这样就需要业务**生成全局唯一**的主键，之前老顾的文章也介绍过**分布式唯一主键ID**的生成，可自行查阅。如果是**分库分表场景下**，**路由规则要保证相同请求下**，**落地在同一个数据库和同一表中**，要不然**数据库主键约束就不起效果**了，因为是不同的数据库和表主键不相关。因为对主键有一定的要求，这个方案就跟业务有点耦合了，**无法用自增主键了**。

    ### **Redis实现**

    Redis实现的方式就是将唯一序列号作为Key，唯一序列号可以拿几个字段MD5加密生产的密文，value可以是你想填的任何信息。唯一序列号也可以是一个字段，例如订单的订单号，也可以是多字段的唯一性组合。当然这里需要设置一个 key 的过期时间，否则 Redis 中会存在过多的 key。

    ### **状态机**

    对于很多业务有一个业务流转状态的，每个状态都有前置状态和后置状态，以及最后的结束状态。例如流程的待审批，审批中，驳回，重新发起，审批通过，审批拒绝。订单的待提交，待支付，已支付，取消。

    以订单为例，已支付的状态的前置状态只能是待支付，而取消状态的前置状态只能是待支付，通过这种状态机的流转我们就可以控制请求的幂等。

    ```java
    public enum OrderStatusEnum {
    
        UN_SUBMIT(0, 0, "待提交"),
        UN_PADING(0, 1, "待支付"),
        PAYED(1, 2, "已支付待发货"),
        DELIVERING(2, 3, "已发货"),
        COMPLETE(3, 4, "已完成"),
        CANCEL(0, 5, "已取消"),
        ;
    
        //前置状态
        private int preStatus;
    
        //状态值
        private int status;
    
        //状态描述
        private String desc;
    
        OrderStatusEnum(int preStatus, int status, String desc) {
            this.preStatus = preStatus;
            this.status = status;
            this.desc = desc;
        }
    
        //...
    }
    ```

    假设当前状态是已支付，如果支付接口又收到了支付请求，则会抛出异常会拒绝此处处理。

* maven如何解决循环依赖，依赖冲突

## 数据库MySql

* **如何避免sql注入**

  1.**PreparedStatement**

  采用预编译语句集，它内置了处理SQL注入的能力，只要使用它的setXXX方法传值即可。

  2.**传入的参数校验**

* **数据库的三范式**

  1NF：强调的是**列的原子性**，即列不能够再分成其他几列。 

  2NF：非主键列是否完全依赖于主键，不可依赖于主键的一部分。

  ​	比如主键是联合主键key_a_b,某些字段仅依赖a，则不满足2NF。

  2NF：非主键列是直接依赖于主键，不可直接依赖于非主键列。

* **最左匹配原则？原理？**

  **指的是**：在MySQL建立**联合索引**时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。

  ​	且要在索引数据结构为B+tree。一种多路平衡查询树

  **原理**：B+tree数据结构

  <img src="https://img2020.cnblogs.com/blog/1804577/202005/1804577-20200521182659976-48843100.png" style="zoom:50%;" />

  构建一棵B+树只能根据一个值来确定索引关系，所以数据库依赖联合索引最左的字段来构建。

  可以看到a的值是有顺序的，1，1，2，2，3，3，而b的值是没有顺序的1，2，1，4，1，2。但是我们又可发现a在等值的情况下，b值又是按顺序排列的，但是这种顺序是相对的。这是因为MySQL创建联合索引的规则是首先会对联合索引的最左边第一个字段排序，在第一个字段的排序基础上，然后在对第二个字段进行排序。所以b=2这种查询条件没有办法利用索引。

  **mysql索引数据结构还有一种hash？为什么很少用？**

    1).Hash 索引仅仅能满足"=","IN"和"<=>"查询，不能使用范围查询。
      由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。
    2).Hash 索引无法被用来避免数据的排序操作。
      由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算；
    3).Hash 索引不能利用部分索引键查询。
      对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。
    4).Hash 索引在任何时候都不能避免表扫描。
      前面已经知道，Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。
    5).Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。
      对于选择性比较低的索引键，如果创建 Hash 索引，那么将会存在大量记录指针信息存于同一个 Hash 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下

       简单地说，哈希索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。
  从上面的图来看，B+树索引和哈希索引的明显区别是：
      1).如果是等值查询，那么哈希索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值；当然了，这个前提是，键值都是唯一的。如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据；
      2).从示意图中也能看到，如果是范围查询检索，这时候哈希索引就毫无用武之地了，因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索；
      3).同理，哈希索引也没办法利用索引完成排序，以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询）；
      4).哈希索引也不支持多列联合索引的最左匹配规则；
      5).B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题。

  **总结 B+ Tree索引和Hash索引区别** 哈希索引适合等值查询，但是不无法进行范围查询 哈希索引没办法利用索引完成排序 哈希索引不支持多列联合索引的最左匹配规则 如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题

  **为什么不用多个单值索引，而用联合索引？**

  - **减少开销**。建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！
  - **覆盖索引**。对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。减少io操作，特别的随机io其实是dba主要的优化策略。所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。
  - **效率高**。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select *from table where col1=1 and col2=2 and col3=3,假设假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出1000W*10%=100w条数据，然后再回表从100w条数据中找到符合col2=2 and col3= 3的数据，然后再排序，再分页；如果是联合索引，通过索引筛选出1000w*10%* 10% *10%=1w，效率提升可想而知！

* **聚簇索引和非聚簇索引**

  - 聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据

    优点：
    1.当你需要取出一定范围内的数据时，用聚簇索引也比用非聚簇索引好。

    2.当通过聚簇索引查找目标数据时理论上比非聚簇索引要快，因为非聚簇索引定位到对应主键时还要多一次目标记录寻址,即多一次I/O。

    3.使用覆盖索引扫描的查询可以直接使用页节点中的主键值。

    缺点：

    1.**插入速度严重依赖于插入顺序**，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键。

    2.**更新主键的代价很高，因为将会导致被更新的行移动**。因此，对于InnoDB表，我们一般定义主键为不可更新。

    3.**二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。**

    二级索引的叶节点存储的是主键值，而不是行指针（非聚簇索引存储的是指针或者说是地址），这是为了减少当出现行移动或数据页分裂时二级索引的维护工作，但会让二级索引占用更多的空间。

    4.**采用聚簇索引插入新值比采用非聚簇索引插入新值的速度要慢很多**，因为插入要保证主键不能重复，判断主键不能重复，采用的方式在不同的索引下面会有很大的性能差距，聚簇索引遍历所有的叶子节点，非聚簇索引也判断所有的叶子节点，但是聚簇索引的叶子节点除了带有主键还有记录值，记录的大小往往比主键要大的多。这样就会导致聚簇索引在判定新记录携带的主键是否重复时进行昂贵的I/O代价。

  - 非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点存放的是数据记录的地址（或者数据的主键）

* **mysql innodb的索引结构？**

  innodb：B+tree

  ​	聚簇：主键索引：InnoDB的数据文件本身就是索引文件。MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。

  ​	非聚簇：而二级索引（非主键索引）：的叶子节点存放的是主键值。因此，通过二级索引查询首先查到是主键值，然后InnoDB再根据查到的主键值通过主键索引找到相应的数据块。（这个二次查询的过程叫回表）

  ​		注意：非主键索引一定会查询多次吗？不一定，如果是覆盖索引，仅需一次。（查询的数据，仅需要遍历索引树即可得到）

  **澄清一个概念**：innodb中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引，辅助索引叶子节点存储的不再是行的物理位置，而是所在行的主键值）。

  MyISAM：B+tree
  	非聚簇：主键索引：叶节点的data域存放的是数据记录的地址

  ​					二级索引：是按列值与行号来组织索引的。叶节点的data域存放的是数据记录的地址

* **一张自增表里共有7条数据，删除了最后2条，重启mysql，有插入了一条数据，此时id是几**

  innodb是6。myIsam是 8。

  原理：innodb在MySQL5.7及之前的版本，AUTO_INCREMENT值存储的内存中，所以，当我们重新启动服务器后，内存里面的数据清空，那么自增的ID将重新按照现有表的纪录计算。

  但在在8.0以后版本加入了持久化，将自增值得变更记录在redo log 中，重启的时候依靠redo log恢复重启之前的值。

  相反，如果是MyISAM类型的数据表，将最大纪录ID保持在文件里，这样，虽然，重启了服务器，下次插入新纪录的时候，自增ID通过读取文件而计算得到。

  解决自增值回退的问题：

  1.不重启服务器，当然不合理。

  2.不删除无用数据，加入deleted逻辑删除字段。

* **在MySQL 5.6中，对索引做了哪些优化吗？**

  Index Condition Pushdown Optimization）

  > **科普时间—— Index Condition Pushdown（索引下推）** MySQL 5.6引入了索引下推优化，默认开启，使用SET optimizer_switch = ‘index_condition_pushdown=off’;可以将其关闭。官方文档中给的例子和解释如下： people表中（zipcode，lastname，firstname）构成一个索引

  ```sql
  SELECT * FROM people WHERE zipcode=‘95054’ AND lastname LIKE ‘%etrunia%’ AND address LIKE ‘%Main Street%’;
  ```

  如果没有使用索引下推技术，则MySQL会通过zipcode='95054’从存储引擎中查询对应的数据，返回到MySQL服务端，然后MySQL服务端基于lastname LIKE '%etrunia%'和address LIKE '%Main Street%'来判断数据是否符合条件。 如果使用了索引下推技术，则MYSQL首先会返回符合zipcode='95054’的索引，然后根据lastname LIKE '%etrunia%'筛选出符合条件的索引后再返回到MySQL服务端，然后MySQL服务端基于address LIKE '%Main Street%'来判断数据是否符合条件，这样返回给MySQL服务端的索引数又会减少。有了索引下推优化，可以在有like条件查询的情况下，减少回表次数。

* **sql查询优化**

  1.定位慢查询

  ​	事先设置慢查询的时间，然后去慢查询日志去看。

  2.使用explain分析sql执行过程。（各参数意思及索引使用情况，尽量查询和排序合理使用索引，避免usingfilesort）

  3.避免索引失效

  ​	尽量避免null字段，因为where a is null索引失效，可以设置为0代替。

  4.避免查询初大量不需要的字段

  5.事务的合理使用。避免大事务的使用，来提升并发吞吐量。

  6.避免select * 

  7.索引的数量不能太多，过多增加硬盘开销，也增加了insert或update复杂度

* **如何获取当前数据库的版本**

  select version();

* **说一下ACID是什么**

  事务四大特性(ACID)
  1、原子性（Atomicity）
       事务开始后所有操作，要么全部做完，要么全部不做。事务是一个不可分割的整体。事务在执行过程中出错，会回滚到事务开始之前的状态，以此来保证事务的完整性。
  2、一致性（Consistency）
      事务在开始和结束后，能保证数据库完整性约束的正确性即数据的完整性。转账为例，A向B转账，我们必须保证A扣了钱，B一定能收到钱。
  3、隔离性（Isolation）
       事务之间的完全隔离，两个事务互不影响。如A向一张银行卡转账，避免在同一时间过多的操作导致账户金额的缺损，所以在A转入结束之前是不允许其他事务对此卡操作。
  4、持久性（Durability）
       事务的对数据的修改是永久性的。通俗的解释为事务完成后，对数据的操作都要进行落盘（持久化）。事务一旦完成就是不可逆的，数据库表现为事务一旦完成就无法回滚。

* **char和varchar的区别**

  1、char(n)类型
      char类型时定长的类型，即当定义的是char(10)，输入的是"abc"这三个字符时，它们占的空间一样是10个字节，包括7个空字节。当输入的字符长度超过指定的数时，char会截取超出的字符。而且，当存储char值时，MySQL是自动删除输入字符串末尾的空格。

      char是适合存储很短的、一般固定长度的字符串。例如，char非常适合存储密码的MD5值，因为这是一个定长的值。对于非常短的列，char比varchar在存储空间上也更有效率。

  2、varchar(n)类型
       varchar(n)类型用于存储可变长的，长度为n个字节的可变长度且非Unicode的字符数据。n必须是介于1和8000之间的数值，存储大小为输入数据的字节的实际长度+1/2. 比如varchar(10), 然后输入abc三个字符，那么实际存储大小为3个字节。除此之外，varchar还需要使用1或2个额外字节记录字符串的长度，如果列的最大长度小于等于255字节（是定义的最长长度，不是实际长度），则使用1个字节表示长度，否则使用2个字节来表示。

      所以，从空间上考虑，varcahr较合适；从效率上考虑，用char合适。二者之间需要权衡。

* **float和double的区别**

  它们都代表浮点数。FLOAT用于单精度，而DOUBLE是双精度数字。

  MySQL的单精度值使用四个字节，双精度值使用八个字节。

  float单精度
  优点: float单精度在一些处理器上比double双精度更快而且只占用double双精度一半的空间
  缺点: 但是当值很大或很小的时候，它将变得不精确。

  double双精度
  优点: double 跟 float比较, 必然是 double 精度高，尾数可以有 16 位,而  float 尾数精度只有 7 位
  缺点: double 双精度是消耗内存的,并且是 float 单精度的两倍! ,double 的运算速度比 float 慢得多, 因为double 尾数比float  的尾数多, 所以计算起来必然是有开销的!

  如何选择double 和 float 的使用场景!
  首先: 能用单精度时不要用双精度 以省内存，加快运算速度!
  float: 当然你需要小数部分并且对精度的要求不高时，选择float单精度浮点型比较好!
  double: 因为小数位精度高的缘故，所以双精度用来进行高速数学计算、科学计算、卫星定位计算等处理器上双精度型实际上比单精度的快, 所以: 当你需要保持多次反复迭代的计算精确性时，或在操作值很大的数字时，双精度型是最好的选择。

  double和float:

  float 表示的小数点位数少,double能表示的小数点位数多，更加精确！ 就这么简单

  double和float 后面的长度m,d代表的是什么?

  double(m,d) 和float(m,d) 这里的m,d代表的是什么呢 ？  很多小伙伴也是不清不楚的!  我还是来继续解释一下吧
  其实跟前面整数int(n)一样，这些类型也带有附加参数：一个显示宽度m和一个小数点后面带的个数d
  比如: 语句 float(7,3) 规定显示的值不会超过 7 位数字，小数点后面带有 3 位数字 、double也是同理

* **mysql的内、左、右连接的区别**

  left join （左连接）：返回包括左表中的所有记录和右表中连接字段相等的记录。
  　　right join （右连接）：返回包括右表中的所有记录和左表中连接字段相等的记录。
  　　inner join （等值连接或者叫内连接）：只返回两个表中连接字段相等的行。
  　　full join （全外连接）：返回左右表中所有的记录和左右表中连接字段相等的记录。

* **怎么验证mysql的索引是否满足需求**

  explain 查看SQL 执行计划，确认*索引是否满足需求*。

  EXPLAIN：

  id：标识执行顺序，id大的先执行，相同的自上而下执行；

  select_type:

  SIMPLE：简单的查询，不包含子查询或UNION

  PRIMARY：包含子查询，的外层

  SUBQUERY：在select或where包含的子查询

  DERIVED：from列表中包含的子查询，标记为衍生

  UNION：第二个select包含在UNION之后

  UNION RESULT:连表的结果

  table：表名

  type：访问类型：性能从好到坏

  system：表中只有一行记录

  const：常量；主键或者unique index

  eq_ref:对于每个来自前面的表的行的组合，从该表中只取一行

  ref：非唯一性的索引扫描：如where uid=？

  range：范围，如between and ，in，<

  index: 只遍历索引树，如select index from table

  all：遍历全表或者遍历全表来匹配行

  possible keys：理论用到的索引，如果possible keys为null key不为null，意思是，要查的字段刚好是索引。

  key：实际用到的索引

  key_len：索引中使用的字节数，越小越好

  ref：显示使用哪个列或常数与key一起从表中选择行

  rows:执行查询时检查的行数

  8.索引失效：

  （1）*order by 和group by 要最左前缀原则，可以与where搭配 补全

  （2）*range会使后面的index失效

  a.最左前缀法则：如：idx_a_b_c ，where b = ？；where b=？and c=？都是失效的。但是where a=？and c=？ a能用索引，c用不了

  b.索引列不能做计算，函数，转换：如果where substr（a，4）=？

  c.range会使后面的index失效，如：where a= ？and b>? and c=? 起作用的只有a，b

  d.尽量使用覆盖索引（只查索引字段），减少select*

  e.!= ,<>,is null,is not null会失效

  f.like当中左边%会失效，解决：使用覆盖索引（只查索引的列）；注意右边%type是range

  g.字符串类型没用单引号，因为会自动类型转换，违背了b

  h.用or会失效，如 where a=？ or a=？，where a=？ or b=？ 都会失效

  eg：where a = ？ and c=？ order by b 其实是用到了a,b，a用于查找，b用于排序。排序后的字段不能用索引了。因为索引的作用是查找和排序，此例是连续的

  eg：idx_abc

  where a = ？ and b=？ order by c,b,虽然order by保持顺序，但是b是常亮，相当于order by c 不会产生using filesort

  只有order by 会using filesort

  eg:order by 后面两个 一个asc一个desc也不可以

  9.on和where区别

  https://blog.csdn.net/cs958903980/article/details/60139792

  on是在生成临时表的时候使用的条件，不管on的条件是否起到作用，都会返回左表 (table_name1) 的行。

  where则是在生成临时表之后使用的条件，此时已经不管是否使用了left join了，只要条件不为真的行，全部过滤掉。

  10.索引优化，

  两表联查，左连接，右表加索引，性能好，因为 右表type=ref，

  如果本表加索引，本表type为index

  尽可能用小的结果集驱动大的

* **说一下数据库的事务隔离**

  事务的隔离级别：默认repeatable-read
  **read-uncommitted**：
  会发生脏读：一个事务读取到另外事务没有commit的数据。面向监狱编程
  会发生不可重复读的问题
  会发生幻读：
  **read-committed**：
  会发生不可重复读的问题。同一个事务每次读到同一数据不一致。解决了脏读
  会发生幻读：
  **repeatable-read**：
  会发生幻读：同一个事务中，对同一条件查询结果条数不一样或者如开启事务a，b，在a事务中，select出一条数据，然后b insert一条，然后b提交，这是a update提示成功两天。解决了不可重复读的问题
  **serializable**：一个事务没有commit其他事务不能执行。解决所有问题

* **说一下mysql常用的引擎**

  MyISAM和innoDB引擎对比

  |              | MyISAM           | innoDB                           |
  | ------------ | ---------------- | -------------------------------- |
  | 索引类型     | 非聚簇           | 聚簇和非聚簇                     |
  | 支持事务     | 否               | 是                               |
  | 支持表锁     | 是               | 是                               |
  | 支持行锁     | 否               | 是（默认）                       |
  | 支持外键     | 否               | 是                               |
  | 支持全文索引 | 是               | 是（5.6以后支持）                |
  | 适用操作类型 | 大量select下使用 | 大量insert、delete和update下使用 |

  InnoDB 支持事务，支持行级别锁定，支持 B-tree、Full-text 等索引，不支持 Hash 索引；
  MyISAM 不支持事务，支持表级别锁定，支持 B-tree、Full-text 等索引，不支持 Hash 索引；
  此外，Memory 不支持事务，支持表级别锁定，支持 B-tree、Hash 等索引，不支持 Full-text 索引；

* **说一下mysql的行锁、表锁、共享锁、排他锁**

  锁（表锁，偏读）

  读锁：共享锁

  myisam：不适合写为主

  lock table tableA read

  session1 tableA加了读锁

  |      | session1 | session2        |
  | ---- | -------- | --------------- |
  | 可读 | tableA   | all             |
  | 可写 | 不可     | A阻塞，其他可以 |

  写锁：排它锁

  session1 tableA加了写锁

  lock table tableA write

  | 可读 | tableA | A阻塞，其他可以 |
  | ---- | ------ | --------------- |
  | 可写 | tableA | A阻塞，其他可以 |

  12.锁（行锁，偏写）

  CAP：强一致性，高可用，分区容错性

  session1 开启事务

  | session1         | session2     | session2       |
  | ---------------- | ------------ | -------------- |
  | 更新了id=1的数据 | 更新id=1阻塞 | 更新其他行可以 |
  | commit           | 更新成功     | /              |

  REPEATABLE-READ隔离级别时，无索引或失效行锁变表锁：Mysql 的行锁是通过索引实现的！

  13.间隙锁：也是索引实现的。防止幻读但是也带来的问题。一个事务 update table set column=？ where a>? and 。另个实物insert和update就都可能会阻塞。

  锁的是区间，或者不存在的数据 eg：现有age字段：1，5，9； 如果where age=2，锁的是1到5，where age=10锁的是大于10

  锁不存在的数据，如果字段是唯一索引就不会是间隙锁 

  14.

  可重复读 有 表锁，行锁，间隙锁

  读已提交 有 行锁

* **乐观锁和悲观锁，实现方式，业务场景**

  悲观锁：

  共享锁和排他锁都是悲观锁的实现。阻塞式。

  比较适合写入操作比较频繁的场景，如果出现大量的读取操作，每次读取的时候都会进行加锁，这样会增加大量的锁的开销，降低了系统的吞吐量。

  乐观锁：非阻塞式。

  通过version字段，每次更新，需先查询获取version，然后update的时候比较两个version是否一样，若一样，执行成功并且加1.

  比较适合读取操作比较频繁的场景，如果出现大量的写入操作，数据发生冲突的可能性就会增大，为了保证数据的一致性，应用层需要不断的重新获取数据，这样会增加大量的查询操作，降低了系统的吞吐量。

  总结：两种所各有优缺点，读取频繁使用乐观锁，写入频繁使用悲观锁。

  像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适,之所以用悲观锁就是因为两个用户更新同一条数据的概率高，也就是冲突比较严重的情况下，所以才用悲观锁.

  **悲观锁比较适合强一致性的场景，但效率比较低，特别是读的并发低。乐观锁则适用于读多写少，并发冲突少的场景。**

* **向mysql中插入1000w条数据，怎么操作**

  使用存储过程

  [参考](https://blog.csdn.net/weixin_43324314/article/details/105358579)

* **主从复制**

  15.主从复制：

  原理：通过二进制文件bin-log,三个线程：

  1.binlog输出线程:每当有从库连接到主库的时候，主库都会创建一个线程然后发送binlog内容到从库。在从库里，当复制开始的时候，从库就会创建两个线程进行处理：

  2.从库I/O线程:当START SLAVE语句在从库开始执行之后，从库创建一个I/O线程，该线程连接到主库并请求主库发送binlog里面的更新记录到从库上。从库I/O线程读取主库的binlog输出线程发送的更新并拷贝这些更新到本地文件，其中包括relay log文件。

  3.从库的SQL线程:从库创建一个SQL线程，这个线程读取从库I/O线程写到relay log的更新事件并执行。  

  可以知道，对于每一个主从复制的连接，都有三个线程。拥有多个从库的主库为每一个连接到主库的从库创建一个binlog输出线程，每一个从库都有它自己的I/O线程和SQL线程。

* **mycat**

  16.数据库中间件Mycat

  干什么的：

  读写分离：

  目前可配置的负载均衡类型有4种

  数据分片：

  垂直拆分：把占用空间大的，长的字段差分出来成一个子表

  水平拆分：按照一定的规则（id，hash某个字段，字段%节点数，时间）等，将一个表拆成多个表，这些表的和=总表数据

  垂直+水平：

  多数据源整合：

  原理：拦截

  注意的问题：分库，关联的表分到一起，用ER表，跟大哥走。

  字典类型表，冗余，每个库都要有，

  主键自增方式，0通过文件，不推荐，1数据库一个表，每次分配一个可用自增区间，用完了再取，比如每次100。

  2通过时间戳，太长18位

  3也可以通过业务自己编写主键

  

  水平拆分

  如果回答按月，他会继续问下去，比如跨月查询怎么办？

  按uid来hash来存，他会问跨用户查呢？

## Redis

* **是什么？有哪些使用场景和注意的问题**

  Redis是现在最受欢迎的NoSQL数据库之一，Redis是一个使用ANSI C编写的开源、包含多种数据结构、支持网络、基于内存、可选持久性的键值对存储数据库，其具备如下特性：

  基于内存运行，性能高效
  支持分布式，理论上可以无限扩展
  key-value存储系统
  开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API
  相比于其他数据库类型，Redis具备的特点是：

  C/S通讯模型
  单进程单线程模型
  丰富的数据类型
  操作具有原子性
  持久化
  高并发读写
  支持lua脚本

  **使用场景**：

  缓存系统（“热点”数据：高频读、低频写）、计数器、消息队列系统、排行榜、社交网络和实时系统。

* **什么是哨兵模式**

  Redis Sentinel 是 Redis 高可用 的实现方案。Sentinel 是一个管理多个 Redis 实例的工具，它可以实现对 Redis 的 监控、通知、自动故障转移。

  监控

  Sentinel 会不断的检查 主服务器 和 从服务器 是否正常运行。

  通知

  当被监控的某个 Redis 服务器出现问题，Sentinel 通过 API 脚本 向 管理员 或者其他的 应用程序 发送通知。

  自动故障转移

  当 主节点 不能正常工作时，Sentinel 会开始一次 自动的 故障转移操作，它会将与 失效主节点 是 主从关系 的其中一个 从节点 升级为新的 主节点，并且将其他的 从节点 指向 新的主节点。

  配置提供者

  在 Redis Sentinel 模式下，客户端应用 在初始化时连接的是 Sentinel 节点集合，从中获取 主节点 的信息。

* **redis为什么这么快？**

  1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；没有hash冲突的情况下。

  2、数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；

  3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；

  4、使用多路I/O复用模型，非阻塞IO；

  ​	redis 采用网络IO多路复用技术来保证在多连接的时候， 系统的高吞吐量。

  多路-指的是多个socket连接，复用-指的是复用一个线程。多路复用主要有三种技术：select，poll，epoll。epoll是最新的也是目前最好的多路复用技术。

  这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。

  （另外的理解：所谓的非阻塞网络io模型，这有点类似于java里面的nio。当有多个请求发送到服务端的时候，实际上会有一个文件事件处理器同时监听多个套接字，并且根据套接字目前执行的任务来关联不同的事件处理器。

  这些不同的套接字用于给事件处理器将其分发给不同的逻辑程序处理，事件处理器只需要将它们做绑定即可。这些处理事件可能会并发地出现，但是io多路复用程序是会将所有产生的套接字都存入一个 有序且同步的队列中（单线程的核心点），最后redis会有逐一地对这个队列中的元素进行处理。

  这里就是为啥单线程的原因。在一开始学习这块知识点的时候，为了更好地深入理解，我去用了nio程序来做比对。

  不同的套接字事件对应的处理器也听类似的，例如说accept，read，write等事件，应对不同连接的时候处理逻辑也不同。

  我当时是结合了实际业务来进行设计的，由于商品有多种，因此对于商品的库存数目采用了key-value的结构，按照商品的id作为key，库存作为value存储。对于库存的减少是采用了decr指令操作，这条指令实际上是一条原子性操作，之所以原子性操作是因为redis的单线程特性。）

  5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

* **redis和memecache的区别**

  Redis中，并不是所有的数据都一直存储在内存中的，这是和Memcache相比一个最大的区别。
  Redis在很多方面具备数据库的特征，或者说就是一个数据库系统，而Memcache只是简单的K/V缓存。
  他们的扩展都需要做集群；实现方式：master-slave、Hash。
  在100k以上的数据中，Memcache性能要高于Redis。
  如果要说内存使用效率，使用简单的key-value存储的话，Memcached的内存利用率更高，而如果Redis采用hash结构来做key-value存储，由于其组合式的压缩，其内存利用率会高于Memcache。当然，这和你的应用场景和数据特性有关。
  如果你对数据持久化和数据同步有所要求，那么推荐你选择Redis，因为这两个特性Memcache都不具备。即使你只是希望在升级或者重启系统后缓存数据不会丢失，选择Redis也是明智的。
  Redis和Memcache在写入性能上面差别不大，读取性能上面尤其是批量读取性能上面Memcache更强
  共同点:Memcache，Redis 都是内存数据库

  区别:

  Memcache

  Memcache可以利用多核优势，单实例吞吐量极高，可以达到几十万QPS,适用于最大程度扛量

  只支持简单的key/value数据结构，不像Redis可以支持丰富的数据类型。

  无法进行持久化，数据不能备份，只能用于缓存使用，且重启后数据全部丢失

  Redis

  支持多种数据结构，如string,list,dict,set,zset,hyperloglog

  单线程请求，所有命令串行执行，并发情况下不需要考虑数据一致性问题。

  支持持久化操作，可以进行aof及rdb数据持久化到磁盘，从而进行数据备份或数据恢复等操作，较好的防止数据丢失的手段。

  支持通过Replication进行数据复制，通过master-slave机制，可以实时进行数据的同步复制，支持多级复制和增量复制.

* **redis为什么是单线程的**

  官方：因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。

  Redis的数据结构并不全是简单的Key-Value，还有list，hash等复杂的结构，这些结构有可能会进行很细粒度的操作，比如在很长的列表后面添加一个元素，在hash当中添加或者删除

  一个对象。这些操作可能就需要加非常多的锁，导致的结果是同步开销大大增加。

  总之，在单线程的情况下，就不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。Redis采用了单线程的模型，保证了每个操作的原子性，也减少了线程的上下文切换和竞争。

* **redis采用多线程会有哪些问题**

  线程的上下文切换和锁的竞争。

* **什么是缓存穿透。。。如何解决**

  * 缓存穿透

    指缓存和数据库中都没有的数据，而用户不断发起请求，我们数据库的 id 都是1开始自增上去的，如发起为id值为 -1 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库。

    解决：

    1.会在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id <=0的直接拦截等。

    2.缓存空对象：简单，但是可能出现空对象过多占用内存。

    3.布隆过滤器：就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。可能误报，但不漏报。准确度取决于布隆过滤器的大小和hash函数的个数。要实时更新。不能删除元素

  * 缓存雪崩

    同一时间大面积失效，那一瞬间Redis跟没有一样，那这个数量级别的请求直接打到数据库。

    1.redis宕机2.大部分数据失效。数据库有周期性的压力。

    解决方案：1.搭建高可用集群，防止单机redis宕机2.设置不同的过期时间（把每个Key的失效时间都加个随机值），防止同一时间内大量key失效。或者干脆不设置过期时间，永久有效。

  * 缓存击穿

    指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。

    解决：1.设置热点数据不过期	2.加互斥锁：保证，第一个请求访问数据库，之后的访问只集中在缓存。

* **redis支持的数据类型**

  [参考](https://juejin.cn/post/6844904051377700871)

  - String（字符串）

    Number或者字符串类型

  - List（列表）

    列表对象的编码可以是linkedlist或者ziplist，对应的底层数据结构是链表和压缩列表。列表对象相关命令可参考：Redis命令-List。

    默认情况下，当列表对象保存的所有字符串元素的长度都小于64字节，且元素个数小于512个时，列表对象采用的是ziplist编码，否则使用 linkedlist编码。

    可以通过配置文件修改该上限值。

  - Hash（字典）

    哈希对象的编码可以是ziplist或者hashtable。

  - Set（集合）

    集合对象的编码可以是 intset 或者 hashtable。当集合对象保存的元素都是整数，并且个数不超过 512 个时，使用 intset 编码，否则使用 hashtable 编码。

  - Sorted Set（有序集合）

    有序集合的编码可以是 ziplist 或者 skiplist。当有序集合保存的元素个数小于 128 个，且所有元素成员长度都小于 64 字节时，使用 ziplist 编码，否则使用 skiplist 编码。

* **redis支持的java客户端有哪些**

  Redisson、Jedis、lettuce 等等，官方推荐使用 Redisson。

* **jedis和redission有哪些区别**

  Jedis 和 Redisson 都是Java中对Redis操作的封装。Jedis 只是简单的封装了 Redis 的API库，可以看作是Redis客户端，它的方法和Redis 的命令很类似。Redisson 不仅封装了 redis ，还封装了对更多数据结构的支持，以及锁等功能，相比于Jedis 更加大。不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务。但Jedis相比于Redisson 更原生一些，更灵活。

* **怎么保证缓存和数据库数据的一致性**

  1.采用分布式锁：

  每个想要操作缓存和数据库的线程都必须先申请分布式锁
  如果成功获得锁，则进行数据库和缓存操作，操作完毕释放锁
  如果没有获得锁，根据不同业务可以选择阻塞等待或者轮训，或者直接返回的策略

  利用分布式锁是解决分布式事务的一种方案，但是在一定程度上会降低系统的性能，而且分布式锁的设计要考虑到down机和死锁的意外情况，而最常见的分布式锁就是利用redis，但是也会有不少坑

  2.删除缓存：

  相对于分布式锁的方案，而程序员实际中最喜欢使用的还是删除缓存的方式，在一个可能会发生不一致的场景下，**我们会以数据库为主**，在操作完数据库之后，不去更新缓存，而是删除缓存。这在一定意义上相当于只操作数据库，把需要维护的两个数据源变成了一个数据源。

  **这种方式要求必须先操作数据库**，后操作缓存，不然的话发生不一致的几率会大很多。为什么这么说呢?因为就算是先操作数据库也会有发生不一致的几率，但是毕竟在整个操作过程中，删除缓存的操作只占整个流程时间的一小部分而已，而且我们可以利用缓存的过期时间来保证数据的最终一致性，所以在一些可以容忍数据短暂不一致的场景下可以采用这种方案的。

  删除缓存方案带来的另外一个劣势是：如果同样的数据会被频繁更新，缓存会被频繁删除，当有读请求的时候又会被频繁的从数据库加载，所以这种方案适用于那种对缓存命中率不敏感的系统中。

  3.单线程

  发生缓存和数据库不一致的原因在于多个线程的同时操作，如果相同的数据始终只会有一个线程去操作，不一致的情况就会避免了，比如nodejs，可以充分利用nodejs单线程的优势。提到单线程不能不提一下Actor模型，actor模型在对于同样的对象上可以看做是单线程模式，具体有兴趣的同学可以查看之前的推文

  [分布式高并发下Actor模型如此优秀](https://mp.weixin.qq.com/s/eEiypRysw5jsC7iYUp_yAg)

  单线程的模式基本上和分布式锁的方案类似，只不过单线程不需要锁就可以实现操作的顺序化，这也是单线程的优势所在。

  4.以缓存为主数据库

  如果是以缓存为主呢？假如我们的应用程序只和缓存组件通信，至于持久化数据库由专门的程序负责，这样行不行呢？在理论上是可以的

  ![image](https://segmentfault.com/img/remote/1460000037611698)

  不过这种方案需要考虑几个方面：

  - 数据从缓存持久化到数据采用什么样的解决方案，是同步进行还是异步进行呢？
  - 在新数据请求的时候，如果缓存不存在，要采用什么样的方式来填充数据
  - 如果缓存模块挂掉了该怎么办？

  以缓存为主的方案的优势是数据优先进入IO速度快的设备，对于那些请求量大，但是可以容忍一定数据丢失的应用非常合适，比如应用log数据的收集系统，这种系统其中一个最大的特点就是可以容忍一定数据的丢失，但是并发的请求数会非常大。所以我们就可以利用缓存设备前置的方案来应对这种应用场景

* **redis的持久化策略**

  [参考](https://segmentfault.com/a/1190000009537768)

  ## RDB持久化（全量备份）快照持久化-默认开启

  RDB持久化是指在指定时间间隔内将内存中的数据集快照写入磁盘。实际上fork子线程，先将数据集写入临时文件，写入成功后，在替换之前的文件，用二进制压缩文件，RDB是Redis默认的持久化方式，会在对应目录下生产一个dump.rdb文件，重启会通过加载dump.rdb文件恢复数据。

  如何生成快照？

  1.手动执行命令

  2.自动生成，根据配置的（指定时间间隔和key的改动数量）

  **RDB优点：**

  1. 方便持久化：只有一个dump.rdb文件；
  2. 容灾性好：一个文件可以保存到安全的磁盘；
  3. 性能好：fork子线程来完成写操作，主线程继续处理命令；
  4. 效率高：如何数据集偏大，RDB启动效率比AOF高

  **RDB缺点：**

  1. 数据安全性低：因为RDB是每隔一段时间进行持久化，可能会造成数据丢失。
  2. 由于RDB是通过fork子线程协助完成数据持久化工作的，因此如果数据集较大时，可能会导致整个服务停止服务几百毫秒，甚至一分钟。

  ## AOF持久化（增量备份）只追加文件持久化 - 默认不开启

  AOF持久化是以日志的形式记录记录每一个增删操作然后追加到文件中。AOF的出现是为了弥补RDB备份的不足（数据不一致性）。

  与RDB持久化相比，AOF的持久化实时性更好。采用该策略的时候，redis会将被执行的写命令添加到aof文件的末尾，该文件被保留在磁盘中。当重启redis服务的时候会优先（相对于rdb文件而言）读取aof文件，完成对redis数据的恢复。

  **AOF的备份策略：**

  Redis的配置文件中存在三种不同的AOF持久化方式：

  - appendfsync always：每次有数据修改发生时都会同步。
  - appendfsync everysec：每秒同步一次
  - appendsync no：让操作系统决定何时进行同步。

  **AOF优点：**

  1. AOF实时性哈好，数据安全性更高；
  2. AOF通过append模式写文件，即使中途服务器宕机，也可以通过`redis-check-aof`工具解决数据一致性问题。
  3. AOF机制的rewrite模式（文件过大会对命令进行合并重写），可以删除其中某些命令（比如误操作的命令）

  **AOF缺点：**

  1. AOF文件比RDB文件大，且恢复慢；
  2. 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。

* **redis的订阅模式**

  Redis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。

  Redis 客户端可以订阅任意数量的频道。

  下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系：

  ![img](https://www.runoob.com/wp-content/uploads/2014/11/pubsub1.png)

  当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端：

  ![img](https://www.runoob.com/wp-content/uploads/2014/11/pubsub2.png)

  订阅的方式：

  **发布与订阅**

  字典+链表

  在这个字典中，key 代表的是频道名称，value 是一个链表，这个链表里面存放的是所有订阅这个频道的客户端。

  **模式订阅结构**

  pubsub_patterns 属性是一个链表，不是字典。

   client 属性是用来存放对应客户端信息，pattern 是用来存放客户端对应的匹配模式。

* **redis怎么实现分布式锁，redis分布式锁操作的原子性，redis内部如何实现的**

  基于redis的分布式锁常用命令是 一条原子性操作的命令

  SETNX key value 

  SETEX redislock 60 redislock 用设置过期时间的。

  原理：

  ```java
  if(SETEX(k,v,t)){
  	try{
  		//业务代码；
  	}catch(){}
  	finally{
  		DEL(key);
  	}
  }
  ```

  

* **redis分布式锁有什么缺陷**

  [redis做分布式锁可能不那么简单](https://mp.weixin.qq.com/s/D3JKfgXA9Yz6xIB8MPfVyA)

  1.超时问题

   如果设置过期时间太久：业务代码期间 挂掉，其他等待锁的线程等待时间就会长。

   如果设置过期时间太短：业务代码没执行完，锁释放了，导致并发问题。

  2.锁获取失败怎么处理

  当锁被一个调用方获取之后，其他调用方在获取锁失败之后，是继续轮询还是直接业务失败呢？如果是继续轮询的话，同步情况下当前线程会一直处于阻塞状态，所以这里轮询的情况还是建议使用异步。

  3.可重入性怎么实现

  可重入性是指已经拥有锁的客户端再次请求加锁，如果锁支持同一个客户端重复加锁，那么这个锁就是可重入的。如果基于redis的分布式锁要想支持可重入性，需要客户端封装，可以使用threadlocal存储持有锁的信息。这个封装过程会增加代码的复杂度，所以菜菜不推荐这样做。

  4.redis挂了

  如果在多个客户端获取锁的过程中，redis 挂了怎么办呢？假如一个客户端已经获取到了锁，这个时候redis挂了（假如是redis集群），其他的redis服务器会接着提供服务，这个时候其他客户端可以在新的服务器上获取到锁了，这也导致了锁意义的丢失。有兴趣的同学可以去看看RedLock，这种方案以牺牲性能的代价解决了这个问题。

  5.时间跳跃的问题

  在某些时候，redis的服务器时间发生的跳跃，由于锁的过期时间依赖于服务器时间，所以也会出现两个客户端同时获取到锁的情况发生。

* **redis如何做内存优化**

  Redis中的所有对象在内部都是由一个种叫RedisObject的数据结构来实现。

  [<img src="http://i1.itc.cn/20170216/3084_2c3a0c00_6cbc_c4d9_01fe_8852cc497653_1.png" alt="img" style="zoom:50%;" />

  1.**key与value的优化**

  ​	当我们执行命令: set hello redis时那在内存会是什么样子呢。内存里面这时会存在一个叫"hello"的key 和 对应叫"redis"的value。这时消耗的内存: key + value。

  所以我们得出第一个优化方案时就是优化的key大小。比如：user:1:firends换成u:1:fs那我们就可以节省8个字节了。同样的对于value我们也可以进行优化，对于value的优化方式就多了：

  1、过滤不必要的数据。比如我们缓存一个用户的信息,我们通常只要缓存基本信息比如：呢称，性别，角色类型，生日即可。其它的一些不必要信息，我们可以过滤掉。

  2、精简数据。比如角色类型："VIP"。我们可以指定1代表"VIP"，不直接存储VIP字符串。

  3、数据压缩。存进redis之前我们还可以对内容进行压缩，常用的工具有GZIP、Snappy。

  2.**使用命令的优化**

  ```text
  set redis "hello" 
  append redis " redis"
  -----------------------
  set redis "hello redis"
  ```

  分割线上下的命令效果是等价的，最终get redis 得到的结果都是"hello redis"。但这两者占用的内存大小却是不一样的。

  为什么会这样呢？因为Redis的字符串有一个预分配的设定。当执行set redis "hello"命令时，此时内存中存储的是"hello\0"，默认加一个'\0'表示结束符。当执行append redis " redis"命令之后内存里的存储就变成了"hello redis\0"，额外还多申请一倍的空间，这个空间的上限是1M，所以字段串的append操作是会额外申请一份内存空间！这样做的原因是Redis作者认为如果字符串经常append，与其每一次append重新分配一次内存空间，不如预先分配好，下次append时如果空间够直接存储就行了。所以如果有大量的append字符串操作，并且字符串的长度不大的话，还不如用set 命令重新覆盖 这样比 append追加会更节约内存。

  3.**编码优化**

  Redis的作者对同一个数据类型比如hash map，根据键的数量和值的大小也有不同的底层实现方式。举hash map来说底层的编码方式有两种：ziplist、hash table。从内存和效率来说ziplis与hash table的关系是

  内存：ziplist < hash table 效率：ziplist < hash table。

  这里说一下ziplist的效率是O(n),hash table的效率是O(1) 也就是说Redis这里采用的是以时间换空间的套路。截至redis 4.0 只要hash map的key的数量小于等于 512，value的大小小于等于64字节。hash map的底层数据结构就是ziplist，反之则是hash table。

  这样当hash map里面的数据不是很多时，用ziplist来实现即节省了内存，效率也不用下降很多，因为数据不多。但生产中如果我们有这样的一个hash map，它的key有512个，value有只有一个的大小超过了64字节，刚好是65。这个时候Redis 就默认把ziplist换成了hash table，这是不是很坑！这时可以自己优化转换规则：config set hash-max-ziplist-entries 65。这样value大于65字节才转换成hash table。

  所以大家可以了解一下Redis底层的编码实现和转换规则，根据实际业务特点修改配置。

  4.**对象共享池**

  [参考](https://cachecloud.github.io/2017/02/16/Redis%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/)

  redis启动的时候默认会生成一个0-9999的整数对象共享池。

* **redis的淘汰策略有哪些**

  定义：Redis在生产环境中，采用配置参数maxmemory 的方式来限制内存大小。当实际存储内存超出maxmemory 参数值时，开发者们可以通过这几种方法——Redis内存淘汰策略，来决定如何腾出新空间继续支持读写工作。

  **当前Redis3.0版本支持的淘汰策略有6种：**

  \1. volatile-lru：从设置过期时间的数据集(server.db[i].expires)中挑选出最近最少使用的数据淘汰。没有设置过期时间的key不会被淘汰，这样就可以在增加内存空间的同时保证需要持久化的数据不会丢失。

  \2. volatile-ttl：除了淘汰机制采用LRU，策略基本上与volatile-lru相似，从设置过期时间的数据集(server.db[i].expires)中挑选将要过期的数据淘汰，ttl值越大越优先被淘汰。

  \3. volatile-random：从已设置过期时间的数据集(server.db[i].expires)中任意选择数据淘汰。当内存达到限制无法写入非过期时间的数据集时，可以通过该淘汰策略在主键空间中随机移除某个key。

  \4. allkeys-lru：从数据集(server.db[i].dict)中挑选最近最少使用的数据淘汰，该策略要淘汰的key面向的是全体key集合，而非过期的key集合。

  \5. allkeys-random：从数据集(server.db[i].dict)中选择任意数据淘汰。

  \6. no-enviction：禁止驱逐数据，也就是当内存不足以容纳新入数据时，新写入操作就会报错，请求可以继续进行，线上任务也不能持续进行，采用no-enviction策略可以保证数据不被丢失，这也是系统默认的一种淘汰策略。

  上述是Redis的6种淘汰策略，关于使用这6种策略，开发者还需要根据自身系统特征，正确选择或修改驱逐。

  - 在Redis中，数据有一部分访问频率较高，其余部分访问频率较低，或者无法预测数据的使用频率时，设置allkeys-lru是比较合适的。
  - 如果所有数据访问概率大致相等时，可以选择allkeys-random。
  - 如果研发者需要通过设置不同的ttl来判断数据过期的先后顺序，此时可以选择volatile-ttl策略。
  - 如果希望一些数据能长期被保存，而一些数据可以被淘汰掉时，选择volatile-lru或volatile-random都是比较不错的。
  - 由于设置expire会消耗额外的内存，如果计划避免Redis内存在此项上的浪费，可以选用allkeys-lru 策略，这样就可以不再设置过期时间，高效利用内存了。

  Redis缓存功能，是由edis.c文件中的freeMemoryIfNeeded函数实现的。如果maxmemory被设置，那么每次在执行命令钱，该函数都会被调用来判断内存是否够用、释放内存、返回错误。如果没有足够的内存程序主逻辑将会阻止设置了REDIS_COM_DENYOOM flag的命令执行，对其返回command not allowed when used memory > ‘maxmemory’的错误消息。

  区分不同的淘汰策略选择不同的key，Redis淘汰策略主要分为LRU淘汰、TTL淘汰、随机淘汰三种机制。

  **LRU淘汰**

  LRU(Least recently used，最近最少使用)算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。

  在服务器配置中保存了 lru 计数器 server.lrulock，会定时(redis 定时程序 serverCorn())更新，server.lrulock 的值是根据 server.unixtime 计算出来进行排序的，然后选择最近使用时间最久的数据进行删除。另外，从 struct redisObject 中可以发现，每一个 redis 对象都会设置相应的 lru。每一次访问数据，会更新对应redisObject.lru。

  在Redis中，LRU算法是一个近似算法，默认情况下，Redis会随机挑选5个键，并从中选择一个最久未使用的key进行淘汰。在配置文件中，按maxmemory-samples选项进行配置，选项配置越大，消耗时间就越长，但结构也就越精准。

  **TTL淘汰**

  Redis 数据集数据结构中保存了键值对过期时间的表，即 redisDb.expires。与 LRU 数据淘汰机制类似，TTL 数据淘汰机制中会先从过期时间的表中随机挑选几个键值对，取出其中 ttl ***的键值对淘汰。同样，TTL淘汰策略并不是面向所有过期时间的表中最快过期的键值对，而只是随机挑选的几个键值对。

  **随机淘汰**

  在随机淘汰的场景下获取待删除的键值对，随机找hash桶再次hash指定位置的dictEntry即可。

  Redis中的淘汰机制都是几近于算法实现的，主要从性能和可靠性上做平衡，所以并不是完全可靠，所以开发者们在充分了解Redis淘汰策略之后还应在平时多主动设置或更新key的expire时间，主动删除没有价值的数据，提升Redis整体性能和空间。

* **redis的常见性能问题有哪些？该怎么解决**

  1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。

   

  2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。

   

  3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。

  4). Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内

* **redis主从同步原理**

  [参考1](https://www.cnblogs.com/kismetv/p/9236731.html)

  [参考2](https://juejin.cn/post/6844903943764443149)

  主从复制的问题：

  redis用的分布式锁，在这一时刻可能会失效，假设说秒杀活动的高峰期，主节点挂了，那么分布式锁就会失效，可能会引发后续一连串可怕的事情发生，因此对于接口的压测和限流是非常重要的。 

  emm，还有的话例如说一些知识在redis中存储并没有实际落入db做持久化的数据也会丢失，假设一些购物车中存放的数据，可能会在主从切换中的那段时间里面突然发现 "加入购物车" 失效了！

  选举原理？https://blog.csdn.net/sanwenyublog/article/details/53385616

## 分布式

### 分布式事务

* **谈谈对分布式事务的理解**

  事务提供一种“要么什么都不做，要么做全套（All or Nothing）”机制。

  inndb的事务实现原理：

  事务的ACID是通过InnoDB日志和锁来保证。事务的隔离性是通过数据库锁的机制实现的，持久性通过redo log（重做日志）来实现，原子性和一致性通过Undo log来实现。UndoLog的原理很简单，为了满足事务的原子性，在操作任何数据之前，首先将数据备份到一个地方（这个存储数据备份的地方称为UndoLog）。然后进行数据的修改。如果出现了错误或者用户执行了ROLLBACK语句，系统可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。 和Undo Log相反，RedoLog记录的是新数据的备份。在事务提交前，只要将RedoLog持久化即可，不需要将数据持久化。当系统崩溃时，虽然数据没有持久化，但是RedoLog已经持久化。系统可以根据RedoLog的内容，将所有数据恢复到最新的状态。

  **定义：**

  分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。

* **常见的解决方案有哪些**

  * 二阶段提交（2PC）/XA

    存在一个负责协调各个本地资源管理器的事务管理器，本地资源管理器一般是由数据库实现，事务管理器在第一阶段的时候询问各个资源管理器是否都就绪？如果收到每个资源的回复都是 yes，则在第二阶段提交事务，如果其中任意一个资源的回复是 no, 则回滚事务。

    优点： 尽量保证了数据的强一致，实现成本较低，在各大主流数据库都有自己实现，对于MySQL是从5.5开始支持。

    存在的问题：

    同步阻塞：当参与事务者存在占用公共资源的情况，其中一个占用了资源，其他事务参与者就只能阻塞等待资源释放，处于阻塞状态。

    单点故障：一旦事务管理器出现故障，整个系统不可用

    数据不一致：在阶段二，如果事务管理器只发送了部分 commit 消息，此时网络发生异常，那么只有部分参与者接收到 commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。

    不确定性：当协事务管理器发送 commit 之后，并且此时只有一个参与者收到了 commit，那么当该参与者与事务管理器同时宕机之后，重新选举的事务管理器无法确定该条消息是否提交成功。

    目前支付宝使用两阶段提交思想实现了分布式事务服务 (Distributed Transaction Service, DTS) ，它是一个分布式事务框架，用来保障在大规模分布式环境下事务的最终一致性。具体可参考支付宝官方文档：	

  *  TCC（Try-Confirm-Cancel）

    TCC 事务机制相比于上面介绍的 XA，解决了其几个缺点：

    解决了协调者单点，由主业务方发起并完成这个业务活动。业务活动管理器也变成多点，引入集群。
    同步阻塞：引入超时，超时后进行补偿，并且不会锁定整个资源，将资源转换为业务逻辑形式，粒度变小。
    数据一致性，有了补偿机制之后，由业务活动管理器控制一致性
    TCC(Try Confirm Cancel)
    Try 阶段：尝试执行，完成所有业务检查（一致性）, 预留必须业务资源（准隔离性）
    Confirm 阶段：确认执行真正执行业务，不作任何业务检查，只使用 Try 阶段预留的业务资源，Confirm 操作满足幂等性。要求具备幂等设计，Confirm 失败后需要进行重试。
    Cancel 阶段：取消执行，释放 Try 阶段预留的业务资源 Cancel 操作满足幂等性 Cancel 阶段的异常和 Confirm 阶段异常处理方案基本上一致。

    在 Try 阶段，是对业务系统进行检查及资源预览，比如订单和存储操作，需要检查库存剩余数量是否够用，并进行预留，预留操作的话就是新建一个可用库存数量字段，Try 阶段操作是对这个可用库存数量进行操作。
    基于 TCC 实现分布式事务，会将原来只需要一个接口就可以实现的逻辑拆分为 Try、Confirm、Cancel 三个接口，所以代码实现复杂度相对较高。

  * 本地消息表

    该方案中会有消息生产者与消费者两个角色，假设系统 A 是消息生产者，系统 B 是消息消费者，其大致流程如下：
    ![img](https://xiaomi-info.github.io/2020/01/02/distributed-transaction/native-message.jpg)

    1. 当系统 A 被其他系统调用发生数据库表更操作，首先会更新数据库的业务表，其次会往相同数据库的消息表中插入一条数据，两个操作发生在同一个事务中
    2. 系统 A 的脚本定期轮询本地消息往 mq 中写入一条消息，如果消息发送失败会进行重试
    3. 系统 B 消费 mq 中的消息，并处理业务逻辑。如果本地事务处理失败，会在继续消费 mq 中的消息进行重试，如果业务上的失败，可以通知系统 A 进行回滚操作

    本地消息表实现的条件：

    1. 消费者与生成者的接口都要支持幂等
    2. 生产者需要额外的创建消息表
    3. 需要提供补偿逻辑，如果消费者业务失败，需要生产者支持回滚操作

    容错机制：

    1. 步骤 1 失败时，事务直接回滚
    2. 步骤 2、3 写 mq 与消费 mq 失败会进行重试
    3. 步骤 3 业务失败系统 B 向系统 A 发起事务回滚操作

    此方案的核心是将需要分布式处理的任务通过消息日志的方式来异步执行。消息日志可以存储到本地文本、数据库或消息队列，再通过业务规则自动或人工发起重试。人工重试更多的是应用于支付场景，通过对账系统对事后问题的处理。

    跨行转账可通过该方案实现。
    用户 A 向用户 B 发起转账，首先系统会扣掉用户 A 账户中的金额，将该转账消息写入消息表中，如果事务执行失败则转账失败，如果转账成功，系统中会有定时轮询消息表，往 mq 中写入转账消息，失败重试。mq 消息会被实时消费并往用户 B 中账户增加转账金额，执行失败会不断重试。

  * 可靠消息最终一致性

    大致流程如下：
    ![img](https://xiaomi-info.github.io/2020/01/02/distributed-transaction/mq-message.jpg)

    1. A 系统先向 mq 发送一条 prepare 消息，如果 prepare 消息发送失败，则直接取消操作
    2. 如果消息发送成功，则执行本地事务
    3. 如果本地事务执行成功，则想 mq 发送一条 confirm 消息，如果发送失败，则发送回滚消息
    4. B 系统定期消费 mq 中的 confirm 消息，执行本地事务，并发送 ack 消息。如果 B 系统中的本地事务失败，会一直不断重试，如果是业务失败，会向 A 系统发起回滚请求

    5.mq 会定期轮询所有 prepared 消息调用系统 A 提供的接口查询消息的处理情况，如果该 prepare 消息本地事务处理成功，则重新发送 confirm 消息，否则直接回滚该消息

    该方案与本地消息最大的不同是去掉了本地消息表，其次本地消息表依赖消息表重试写入 mq 这一步由本方案中的轮询 prepare 消息状态来重试或者回滚该消息替代。其实现条件与余容错方案基本一致。目前市面上实现该方案的只有阿里的 RocketMq。

    **该方案应用场景也比较多，比如用户注册成功后发送邮件、电商系统给用户发送优惠券等需要保证最终一致性的场景**

    * 尽最大努力通知

    最大努力通知是最简单的一种柔性事务，适用于一些最终一致性时间敏感度低的业务，且被动方处理结果 不影响主动方的处理结果。

    这个方案的大致意思就是：

    1. 系统 A 本地事务执行完之后，发送个消息到 MQ；
    2. 这里会有个专门消费 MQ 的服务，这个服务会消费 MQ 并调用系统 B 的接口；
    3. 要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B, 反复 N 次，最后还是不行就放弃。

    最大努力通知最常见的场景就是支付回调，支付服务收到第三方服务支付成功通知后，先更新自己库中订单支付状态，然后同步通知订单服务支付成功。如果此次同步通知失败，会通过异步脚步不断重试地调用订单服务的接口。

### 分布式缓存

 缓存雪崩、缓存穿透如何理解？

 如何在业务中避免相关问题？

 如何保证数据库与缓存的一致性？

 如何进行缓存预热？

缓存的高可用
 缓存集群如何失效？

 一致性哈希有哪些应用？

 缓存如何监控和优化热点 key？

### 分布式session

方案一：客户端存储

**直接将信息存储在cookie中**cookie是存储在客户端上的一小段数据，客户端通过http协议和服务器进行cookie交互，通常用来存储一些不敏感信息

**缺点**

- 数据存储在客户端，存在安全隐患
- cookie存储大小、类型存在限制
- 数据存储在cookie中，如果一次请求cookie过大，会给网络增加更大的开销

方案二：session复制

session复制是小型企业应用使用较多的一种**服务器集群session管理机制**，在真正的开发使用的并不是很多，通过对web服务器(例如Tomcat)进行搭建集群。

**存在的问题**

- session同步的原理是在同一个局域网里面通过发送广播来异步同步session的，一旦服务器多了，并发上来了，session需要同步的数据量就大了，需要将其他服务器上的session全部同步到本服务器上，会带来一定的网路开销，在用户量特别大的时候，会出现内存不足的情况

**优点：**

- 服务器之间的session信息都是同步的，任何一台服务器宕机的时候不会影响另外服务器中session的状态，配置相对简单
- Tomcat内部已经支持分布式架构开发管理机制，可以对tomcat修改配置来支持session复制，在集群中的几台服务器之间同步session对象，使每台服务器上都保存了所有用户的session信息，这样任何一台本机宕机都不会导致session数据的丢失，而服务器使用session时，也只需要在本机获取即可

**如何配置：**

在Tomcat安装目录下的config目录中的server.xml文件中，将注释打开，tomcat必须在同一个网关内，要不然收不到广播，同步不了session

在web.xml中开启session复制：`<distributable/>`

方案三：session绑定：

Nginx介绍：

Nginx是一款自由的、开源的、高性能的http服务器和反向代理服务器

Nginx能做什么

反向代理、负载均衡、http服务器（动静代理）、正向代理

如何使用nginx进行session绑定

我们利用nginx的反向代理和负载均衡，之前是客户端会被分配到其中一台服务器进行处理，具体分配到哪台服务器进行处理还得看服务器的负载均衡算法(轮询、随机、ip-hash、权重等)，但是我们可以基于nginx的`ip-hash策略`，可以对客户端和服务器进行绑定，同一个客户端就只能访问该服务器，无论客户端发送多少次请求都被同一个服务器处理

在nginx安装目录下的conf目录中的nginx.conf文件

```
upstream aaa {  
    Ip_hash;  
    server 39.105.59.4:8080;  
    Server 39.105.59.4:8081;  
}  
server {  
listen80;  
    server_name www.wanyingjing.cn;  
#root /usr/local/nginx/html;  
#index index.html index.htm;  
    location / {  
        proxy_pass http:39.105.59.4;  
index index.html index.htm;  
    }  
}
```

**缺点：**

- 容易造成单点故障，如果有一台服务器宕机，那么该台服务器上的session信息将会丢失
- 前端不能有负载均衡，如果有，session绑定将会出问题

**优点：**

- 配置简单

方案四：基于redis存储session方案

**基于redis存储session方案流程示意图**

![img](https://segmentfault.com/img/remote/1460000022404399)

**引入pom依赖：**

```
<dependency>    
   <groupId>org.springframework.boot</groupId>    
   <artifactId>spring-session-data-redis</artifactId>
</dependency>
<dependency>    
   <groupId>org.springframework.boot</groupId>    
   <artifactId>spring-boot-data-starter-redis</artifactId>
</dependency>
```

**配置redis**

```
#redis数据库索引(默认是0)
spring.redis.database=0
spring.redis.host=127.0.0.1
spring.redis.port=6379
#默认密码为空
spring.redis.password=
#连接池最大连接数(负数表示没有限制)
spring.redis.jedis.pool.max-active=1000
#连接池最大阻塞等待时间(负数表示没有限制)
spring.redis.jedis.pool.max-wait=-1ms
#连接池中的最大空闲连接
spring.redis.jedis.pool.max-idle=10
#连接池中的最小空闲连接
spring.redis.jedis.pool.min-idle=2
#连接超时时间(毫秒)
spring.redis.timeout=500ms
```

**优点：**

- 这是企业中使用的最多的一种方式
- spring为我们封装好了spring-session，直接引入依赖即可
- 数据保存在redis中，无缝接入，不存在任何安全隐患
- redis自身可做集群，搭建主从，同时方便管理

**缺点：**

- 多了一次网络调用，web容器需要向redis访问

总结

一般会将web容器所在的服务器和redis所在的服务器放在同一个机房，减少网络开销，走内网进行连接

### 分布式锁

[参考1](https://juejin.cn/post/6844903688088059912)

[参考2](https://zhuanlan.zhihu.com/p/42056183)

### 其他

* **有没有写过分布式的业务，分布式存储？你觉得分布式的话会遇到什么问题呢？**

  要解决的问题：

  1.分布式事务

  2.分布式锁

* **秒杀系统怎么做**

  秒杀防超卖：

  首先在活动开始之前，我们会进行一次商品库存的预热处理，将数据库的信息加载到redis中，然后扣除库存的时候会在redis里面进行处理，最后当库存为0的时候，会触发一个方法去触发关闭前端秒杀活动的开关。

  每次当有用户提交下单请求的时候，会先将请求通过mq来进行削峰，在进行扣除库存的时候，会先更新redis里面的库存量，最后再统一更新db。

  **面试官**：为啥不直接更新db呢？

  **小林**：像秒杀这种典型的高并发场景，直接对db层进行写操作对数据库的访问压力实在是太大了，并发量过大容易压垮数据库。

  **面试官**：嗯嗯，那为什么要把库存存储在redis中呢？

  **小林**：具体有两个原因，首先第一点, redis的并发承载能力足以应付我上家公司的秒场景所需。还有一点非常重要的就是，redis是单线程模型，在做库存减1操作的时候不会出现数据竞争导致商品超卖的情况发生。

* **如何防止库存超卖**

  **1.悲观锁**

  这里我们通过使用select...for update语句，在查询商品表库存时将该条记录加锁，待下单减库存完成后，再释放锁。

  //0.开始事务

  begin;/begin work;/start transaction; (三者选一就可以)

  //1.查询出商品信息

  select stock from t_goods where id=1 for update;

  //2.根据商品信息生成订单

  insert into t_orders (id,goods_id) values (null,1);

  //3.修改商品stock减一

  update t_goods set stock=stock-1 where id=1;

  //4.提交事务

  commit;

  这样可以解决并发时库存超卖的问题，然而高并发时，所有的操作都被串行化了，效率很低，将严重影响系统的吞吐量。而且使用悲观锁还有可能造成死锁问题。

  **2.乐观锁**

  现在我们尝试下使用乐观锁，所谓乐观锁，是相对于悲观锁而言的，它假设数据一般情况下不会发生并发，因此不会对数据进行加锁，操作完成提交时才对数据是否冲突进行检测，如果发现冲突则返回错误。

  比较常见的实现方式是，在表中增加一个version字段，操作前先查询version信息，在数据提交时检查version字段是否被修改，如果没有被修改则进行提交，否则认为是过期数据。

  //1.查询出商品信息

  select stock, version from t_goods where id=1;

  //2.根据商品信息生成订单

  insert into t_orders (id,goods_id) values (null,1);

  //3.修改商品库存

  update t_goods set stock=stock-1, version = version+1 where id=1, version=version;

  这样，在并发时，如果线程a尝试修改商品库存时，发现版本号已经被线程b修改了，线程a执行update语句条件不满足便不再执行了，库存也不会被超卖。

  但是这种乐观锁的方式，在高并发时，只有一个线程能执行成功，会造成大量的失败，这给用户的体验显然是很不好的。

  这里我们可以减小锁的颗粒度，最大程度提升系统的吞吐量，提高并发能力：

  //修改商品库存时判断库存是否大于0

  update t_goods set stock=stock-1 where id=1 and stock>0;

  上面的update语句通过stock>0进行乐观锁的控制，在执行时，会在一次原子操作中查询stock的值，并扣减一。

  3.**分布式锁**

  4.**利用redis的原子操作**

  虽然通过以上方按可以防止库存超卖，但是高并发情况下对数据库进行频繁操作，会造成严重的性能问题。因此我们必须在前端对请求进行限制。

  我们可以在Redis中设置一个队列key为商品的id，队列的长度为商品库存量。每次请求到达时pop出一个元素，这样拿到元素的请求即认为秒杀成功，后续通过MQ发送消息异步完成数据库减库存操作。没有拿到元素的请求即认为秒杀失败。

  由于Redis是工作线程是单线程的，而list的pop操作是原子性的，因此并发的请求都被串行化了，库存就不会超卖了。

* **保证接口的幂等性**

  定义：外部多次调用对系统的影响是一致的

  如何保证幂等：

  **token机制**

  1、服务端提供了发送token的接口。我们在分析业务的时候，哪些业务是存在幂等问题的，就必须在执行业务前，先去获取token，服务器会把token保存到redis中。

  2、然后调用业务接口请求时，把token携带过去，一般放在请求头部。

  3、服务器判断token是否存在redis中，存在表示第一次请求，然后删除token,继续执行业务。

  4、如果判断token不存在redis中，就表示是重复操作，直接返回重复标记给client，这样就保证了业务代码，不被重复执行。

  **关键点 先删除token，还是后删除token。**

  后删除token：如果进行业务处理成功后，删除redis中的token失败了，这样就导致了有可能会发生重复请求，因为token没有被删除。这个问题其实是数据库和缓存redis数据不一致问题，后续会写文章进行讲解。

  先删除token：如果系统出现问题导致业务处理出现异常，业务处理没有成功，接口调用方也没有获取到明确的结果，然后进行重试，但token已经删除掉了，服务端判断token不存在，认为是重复请求，就直接返回了，无法进行业务处理了。

  先删除token可以保证不会因为重复请求，业务数据出现问题。出现业务异常，可以让调用方配合处理一下，重新获取新的token，再次由业务调用方发起重试请求就ok了。
  **token机制缺点**
  业务请求每次请求，都会有额外的请求（一次获取token请求、判断token是否存在的业务）。其实真实的生产环境中，1万请求也许只会存在10个左右的请求会发生重试，为了这10个请求，我们让9990个请求都发生了额外的请求。

  **乐观锁机制**

  这种方法适合在更新的场景中，`update t_goods set count = count -1 , version = version + 1 where good_id=2 and version = 1`
  根据version版本，也就是在操作库存前先获取当前商品的version版本号，然后操作的时候带上此version号。我们梳理下，我们第一次操作库存时，得到version为1，调用库存服务version变成了2；但返回给订单服务出现了问题，订单服务又一次发起调用库存服务，当订单服务传如的version还是1，再执行上面的sql语句时，就不会执行；因为version已经变为2了，where条件就不成立。这样就保证了不管调用几次，只会真正的处理一次。
  乐观锁主要使用于处理读多写少的问题

  **唯一主键**
  这个机制是利用了数据库的主键唯一约束的特性，解决了在insert场景时幂等问题。但主键的要求不是自增的主键，这样就需要业务生成全局唯一的主键。

  如果是分库分表场景下，路由规则要保证相同请求下，落地在同一个数据库和同一表中，要不然数据库主键约束就不起效果了，因为是不同的数据库和表主键不相关。

  **防重表**
  使用订单号orderNo做为去重表的唯一索引，把唯一索引插入去重表，再进行业务操作，且他们在同一个事务中。这个保证了重复请求时，因为去重表有唯一约束，导致请求失败，避免了幂等问题。这里要注意的是，去重表和业务表应该在同一库中，这样就保证了在同一个事务，即使业务操作失败了，也会把去重表的数据回滚。这个很好的保证了数据一致性。

* **一致性hash算法**

  场景，分布式系统，如果3个redis（没有主从），每次Redis请求会随机发送到其中一台

  如果

  同一份数据可能在多个Redis数据库，造成数据冗余，不好。
  某一份数据在其中一台Redis数据库已存在，但是再次访问Redis数据库，并没有命中数据已存在的库。无法保证对相同的key的所有访问都发送到相同的Redis中。

  第二种可以用hash算法，如h= hash(key)%3,h为redis的对应编号。但是redis宕机或者新增会导致重新计算。

  一个设计良好的分布式哈希方案应该具有良好的单调性，即服务节点的变更不会造成大量的哈希重定位。一致性哈希算法由此而生~

  **具体实现**：

  一致性哈希是将整个哈希值空间组织成一个虚拟的圆环，如假设哈希函数H的值空间为0-2^32-1（哈希值是32位无符号整形），

  整个空间按顺时针方向组织，0和2^32-1在零点中方向重合。

  接下来，把服务器按照IP或主机名作为关键字进行哈希，这样就能确定其在哈希环的位置。

  然后，我们就可以使用哈希函数H计算值为key的数据在哈希环的具体位置h，根据h确定在环中的具体位置，从此位置沿顺时针滚动，遇到的第一台服务器就是其应该定位到的服务器。

  **好处的表现**：

  因此，一致性哈希算法对于节点的增减都只需重定位换空间的一小部分即可，具有较好的容错性和可扩展性

  **不足**：

  如果节点较少就会出现节点分布不均衡造成数据倾斜问题。会使Redis1的hash范围比Redis2的hash范围大，导致数据大部分都存储在Redis1中，数据存储不平衡。

  **继续优化**：

  引入了**虚拟节点机制**，即对每个节点计算多个哈希值，每个计算结果位置都放置在对应节点中，这些节点**称为虚拟节点**。

  具体做法可以在服务器IP或主机名的后面增加编号来实现，例如上面的情况，可以为每个服务节点增加三个虚拟节点，于是可以分为 RedisService1#1、 RedisService1#2、 RedisService1#3、 RedisService2#1、 RedisService2#2、 RedisService2#3，具体位置如下图所示：

  对于数据定位的hash算法仍然不变，只是增加了虚拟节点到实际节点的映射。例如，数据C保存到虚拟节点Redis1#2，实际上数据保存到Redis1中。这样，就能解决服务节点少时数据不平均的问题。在实际应用中，通常将虚拟节点数设置为**32甚至更大**，因此即使**很少的服务节点**也能做到相对**均匀的数据分布**。

## 消息中间件

### kafka

* **kafka可以脱离zk单独使用吗？为什么**

  kafka 不能脱离 zookeeper 单独使用，

  因为 kafka 使用 zookeeper 管理和协调 kafka 的节点服务器。

* **kafka有几种数据保留的策略**

  kafka 有两种数据保存策略：

  按照过期时间保留
  按照存储的消息大小保留。

* **kafka同时设置了7天和10G清除数据，到第五天的时候达到了10G，这个时候kafka如何处理**

  这个时候 kafka 会执行数据清除工作，时间和大小不论那个满足条件，都会清空数据。

* **什么情况下，会导致kafka运行变慢**

  cpu 性能瓶颈

  磁盘读写瓶颈

  网络瓶颈

* **使用kafka集群需要注意什么**

  集群的数量不是越多越好，最好不要超过 7 个，

  因为节点越多，消息复制需要的时间就越长，整个群组的吞吐量就越低。

### RabbitMQ

省略了rabbitmq

![](https://img-blog.csdnimg.cn/20200228145533604.png)

* **使用场景**

  以常见的订单系统为例，用户点击【下单】按钮之后的业务逻辑可能包括：扣减库存、生成相应单据、发红包、发短信通知。在业务发展初期这些逻辑可能放在一起同步执行，随着业务的发展订单量增长，需要提升系统服务的性能，这时可以将一些不需要立即生效的操作拆分出来异步执行，比如发放红包、发短信通知等。这种场景下就可以用 MQ ，在下单的主流程（比如扣减库存、生成相应单据）完成之后发送一条消息到 MQ 让主流程快速完结，而由另外的单独线程拉取MQ的消息（或者由 MQ 推送消息），当发现 MQ 中有发红包或发短信之类的消息时，执行相应的业务逻辑。

  以上是用于业务解耦的情况，其它常见场景包括最终一致性、广播、错峰流控等等。

  主要是：应用解藕、跨系统异步通信、应用内同步变异步

  通知
  这里就用到了前文一个重要的特点，发布订阅，下游系统一直在监听MQ的数据，如果MQ有数据，下游系统则会按照 先进先出 这样的规则， 逐条进行消费 ，而上游系统只需要将数据存入MQ里，这样就既降低了不同系统之间的耦合度，同时也确保了消息通知的及时性，而且也不影响上游系统的性能。

  限流
  上文有说了一个非常重要的特性，MQ 数据是只有一条数据在使用中。 在很多存在并发，而又对数据一致性要求高，而且对性能要求也高的场景，如何保证，那么MQ就能起这个作用了。不管多少流量进来，MQ都会让你遵守规则，排除处理，不会因为其他原因，导致并发的问题，而出现很多意想不到脏数据。

  数据分发
  MQ的发布订阅肯定不是只是简单的一对一，一个上游和一个下游的关系，MQ中间件基本都是支持一对多或者广播的模式，而且都可以根据规则选择分发的对象。这样上游的一份数据，众多下游系统中，可以根据规则选择是否接收这些数据，这样扩展性就很强了。
  PS:上文中的上游和下游，在MQ更多的是叫做生产者（producer）和消费者（consumer）。

* **有哪些重要的角色**

  - 生产者：消息的创建者，负责创建和推送数据到消息服务器；
  - 消费者：消息的接收方，用于处理数据和确认消息；
  - 代理：就是 RabbitMQ 本身，用于扮演“快递”的角色，本身不生产消息，只是扮演“快递”的角色

* **有哪些重要的组件**

  - ConnectionFactory（连接管理器）：应用程序与Rabbit之间建立连接的管理器，程序代码中使用。
  - Channel（信道）：消息推送使用的通道。
  - Exchange（交换器）：用于接受、分配消息。
  - Queue（队列）：用于存储生产者的消息。
  - RoutingKey（路由键）：用于把生成者的数据分配到交换器上。
  - BindingKey（绑定键）：用于把交换器的消息绑定到队列上。

* **vhost的作用**

  vhost 可以理解为虚拟 broker （中间人的意思），即 mini-RabbitMQ server。其内部均含有独立的 queue、exchange 和 binding 等，但最最重要的是，其拥有独立的权限系统，可以做到 vhost 范围的用户控制。当然，从 RabbitMQ 的全局角度，vhost 可以作为不同权限隔离的手段（一个典型的例子就是不同的应用可以跑在不同的 vhost 中）。

* **消息是怎么发送到的**

  首先客户端必须连接到 RabbitMQ 服务器才能发布和消费消息，客户端和 rabbit server 之间会创建一个 tcp 连接，一旦 tcp 打开并通过了认证（认证就是你发送给 rabbit 服务器的用户名和密码），你的客户端和 RabbitMQ 就创建了一条 amqp 信道（channel），信道是创建在“真实” tcp 上的虚拟连接，amqp 命令都是通过信道发送出去的，每个信道都会有一个唯一的 id，不论是发布消息，订阅队列都是通过这个信道完成的。

* **怎么保证消息的稳定性**

  即保证消息不会丢失：
  消息持久化；ACK确认机制；设置集群镜像模式；消息补偿机制；事务机制

  由于事务机制过于耗费性能所以一般不用。

  第一种：消息持久化
  RabbitMQ的消息是默认放在内存的，如果不特别声明消息持久到磁盘，当节点关掉或者crash（碰撞）掉，消息就会丢失。
  那么要把数据持久到磁盘就要满足三个条件，缺一不可
  ：
  Exchange（互换） 设置持久化

  Queue（队列）（） 设置持久化

  Message（信息）持久化发送：发送消息设置发送模式deliveryMode=2，代表持久化消息

  第二种：ACK确认机制
  就是多个消费者收到消息，收到一半就没了，消费者就死掉了；
  这个使用就要使用Message acknowledgment 机制，就是消费端消费完成要通知服务端，服务端才把消息从内存删除，一个消费者出了问题，没有同步消息给服务端，还有其他的消费端去消费，保证了消息不丢的case

  第三种：设置集群镜像模式
  RabbitMQ三种部署模式：

  单点模式：最简单的模式，非集群模式，节点挂了，消息不可用了，业务瘫痪，只能等待；

  普通模式：必须消息是持久的，默认是集群模式，某个节点挂了，消息不可用了，业务瘫痪了，此时只能等待节点恢复重启使用；

  镜像模式：把队列做成镜像需要的队列，存放于多个节点，
  属于RabbitMQ的HA方案；

  队列的内容仅仅只存在于某一个节点，并不在所有的节点，节点只会仅仅存放数据结构和元数据

  下面介绍下三种HA策略模式：

  1）同步至所有的
  2）同步最多N个机器
  3）只同步至符合指定名称的nodes

  命令处理HA策略模版：rabbitmqctl set_policy [-p Vhost] Name Pattern Definition [Priority]

  1）为每个以“rock.wechat”开头的队列设置所有节点的镜像，并且设置为自动同步模式
  rabbitmqctl set_policy ha-all “^rock.wechat” ‘{“ha-mode”:“all”,“ha-sync-mode”:“automatic”}’
  rabbitmqctl set_policy -p rock ha-all “^rock.wechat” ‘{“ha-mode”:“all”,“ha-sync-mode”:“automatic”}’

  2）为每个以“rock.wechat.”开头的队列设置两个节点的镜像，并且设置为自动同步模式
  rabbitmqctl set_policy -p rock ha-exacly “^rock.wechat”
  ‘{“ha-mode”:“exactly”,“ha-params”:2,“ha-sync-mode”:“automatic”}’

  3）为每个以“node.”开头的队列分配指定的节点做镜像
  rabbitmqctl set_policy ha-nodes “^nodes.”
  ‘{“ha-mode”:“nodes”,“ha-params”:[“rabbit@nodeA”, “rabbit@nodeB”]}’

  但是：HA 镜像队列有一个很大的缺点就是： 系统的吞吐量会有所下降

  第四种：消息补偿机制
  消息补偿机制需要建立在消息要写入DB日志，发送日志，接受日志，两者的状态必须记录，然后根据DB日志记录check 消息发送消费是否成功，不成功，进行消息补偿措施，重新发送消息处理

  案例：消息是先入库，然后生产者将数据包装成消息发给MQ。经过消费者消费之后对DB数据的状态进行更改。这中间有任何步骤失败，数据的状态都是没有更新的。这时通过一个定时任务不停的去刷库，找到有问题的数据将它重新扔到生产者那里进行重新投递。

* **怎么避免消息丢失**

  可以和上面问题和在一起，这里就做总结了：

  下面也是从三个方面介绍：

  1.生产者生产消息到RabbitMQ Server 可靠性保证

  ​	发送端采用Confirm模式，注意Server端没成功通知发送端，需要重发操作需要额外处理
  ​	消息的持久化处理

  2.RabbitMQ Server中存储的消息如何保证

  ​	镜像模式至少采用3节点，2个磁盘节点和1个内存节点来保证。

  ​	注意：HA 镜像队列有一个很大的缺点就是： 系统的吞吐量会有所下降

  所以采用镜像模式，要根据具体的业务规则定制话处理，没那么重要的业务，消息丢了也没关系的场景，又要求必须高的性能的时候，镜像也可以不用设置。

  3.RabbitMQ Server到消费者消息如何不丢

  ​	消费者获取到消息之后，没有来得及处理完毕，自己直接宕机了,因为消息者默认采用自动ack，此时RabbitMQ的自动ack机制会通知MQ Server这条消息已经处理好了，此时消息就丢了，并不是预期的。

  那么我们采用手动ack机制来解决这个问题，消费端处理完逻辑之后再通知MQ Server，这样消费者没处理完消息不会发送ack,如果在消费者拿到消息，没来得及处理的情况下自己挂了，此时MQ集群会自动感知到，它就会自觉的重发消息给其他的消费者服务实例。

* **要保证消息持久化成功的条件有哪些**

  1. 声明队列必须设置持久化 durable 设置为 true.
  2. 消息推送投递模式必须设置持久化，deliveryMode 设置为 2（持久）。
  3. 消息已经到达持久化交换器。
  4. 消息已经到达持久化队列。

  以上四个条件都满足才能保证消息持久化成功

* **持久化有什么缺点**

  持久化的缺地就是降低了服务器的吞吐量，因为使用的是磁盘而非内存存储，从而降低了吞吐量。可尽量使用 ssd 硬盘来缓解吞吐量的问题。

* **有几种广播模式**

  1. fanout: 所有bind到此exchange的queue都可以接收消息（纯广播，绑定到RabbitMQ的接受者都能收到消息）；
  2. direct: 通过routingKey和exchange决定的那个唯一的queue可以接收消息；
  3. topic:所有符合routingKey(此时可以是一个表达式)的routingKey所bind的queue可以接收消息；

* **怎么实现延迟消息队列**

  1. 通过消息过期后进入死信交换器，再由交换器转发到延迟消费队列，实现延迟功能；
  2. 使用 RabbitMQ-delayed-message-exchange 插件实现延迟功能。

* **集群有什么用**

  高可用：某个服务器出现问题，整个 RabbitMQ 还可以继续使用；

  高容量：集群可以承载更多的消息量。

* **集群搭建需要注意哪些问题**

  各节点之间使用“--link”连接，此属性不能忽略。

  各节点使用的 erlang cookie 值必须相同，此值相当于“秘钥”的功能，用于各节点的认证。

  整个集群中必须包含一个磁盘节点。

* **节点的类型有哪些**

  磁盘节点：消息会存储到磁盘。

  内存节点：消息都存储在内存中，重启服务器消息丢失，性能高于磁盘类型。

* **每个节点是其他节点的完整拷贝吗？为什么？**

  不是，原因有以下两个：

  1. 存储空间的考虑：如果每个节点都拥有所有队列的完全拷贝，这样新增节点不但没有新增存储空间，反而增加了更多的冗余数据；
  2. 性能的考虑：如果每条消息都需要完整拷贝到每一个集群节点，那新增节点并没有提升处理消息的能力，最多是保持和单节点相同的性能甚至是更糟。

* **集群中唯一一个磁盘节点崩溃了会发生什么情况**

  如果唯一磁盘的磁盘节点崩溃了，不能进行以下操作：

  不能创建队列

  不能创建交换器

  不能创建绑定

  不能添加用户

  不能更改权限

  不能添加和删除集群节点

  唯一磁盘节点崩溃了，集群是可以保持运行的，但你不能更改任何东西。

* **对集群节点停止顺序有要求吗**

  RabbitMQ 对集群的停止的顺序是有要求的，应该先关闭内存节点，最后再关闭磁盘节点。如果顺序恰好相反的话，可能会造成消息的丢失。

* **MQ怎么知道消息被指定的消费者消费？怎么使不同的生产者生产的消息被不同的消费者消费？**

  消费者消息确认机制。

* **mq中一条消息出现了异常，怎么处理**

  同上的考察点

* **mq1000个消息始终不被消费怎么处理（消息堆积）**

  1. 从生产者端解决

     一般我们的系统容量或者处理能力都是规划好的，出现消息堆积的情况，大部分是由于流量暴增引起，这个时候可以考虑控制生产者的速率，对前端机器流量进行限速限流。

  2. 从消费者端解决。

     消费者端解决的思路有两种

     - 假如消费者数还有增加的空间，那么我们加消费者解决。
     - 假如没有拓展的可能，但吞吐量还没达到MQ的上限，只是消费者消费能力不足，比如消费者总体消费能力已经到达上线（数据库写入能力等），或者类似Kafka的消费者数量与partition数有关，如果前期设计没有做好水平拓展的设计，这个时候多少个partition就只能对应多少个消费者。**这个时候我们可以先把一部分消息先打到另外一个MQ中或者先落到日志文件中，再拓展消费者进行消费，优先恢复上游业务**。

  3. 从整理系统上进行解决。

     第2点有提到就是有些MQ的设计限制，导致的消费者数是没法动态拓展的，这个时候可以考虑将原先队列进行拆分，比如新建一个topic 分担一部分消息，这个方式需要对系统的上下游都要进行调整，在实际操作难度可能比较高，处理起来可能也比较耗时，如果在事前有做好这个设计那事发后就能很好进行调整。

### 其他问题

* **了解几种消息中间件产品？各产品有缺点介绍**

  ![image.png](https://i.loli.net/2021/03/20/dFj3DOqvYny1NTm.png)

  综上，各种对比之后，有如下建议：

  一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；

  后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；

  不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。

  所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。

  如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。

  **市面上主流的mq对比总结**
  ActiveMQ
  官网 http://activemq.apache.org/
  优缺点
  优点。历史悠久，支持多种语言的客户端和协议，支持多种语言Java, .NET, C++ 等，基于JMS Provider的实现
  缺点：吞吐量不高，多队列的时候性能下降，存在消息丢失的情况，比较少大规模使用
  Kafka
  官网 http://kafka.apache.org/
  优缺点
  优点。是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理大规模的网站中的所有动作流数据(网页浏览，搜索和其他用户的行动)，副本集机制，实现数据冗余，保障数据尽量不丢失；支持多个生产者和消费者。一般在大数据领域使用较为广泛。
  缺点：不支持批量和广播消息，运维难度大，文档比较少, 需要掌握Scala
  RabbitMQ
  官网 http://www.rabbitmq.com/
  优缺点
  优点。是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不错
  缺点：使用Erlang开发，阅读和对源码做二次开发难度大
  RocketMQ
  官网 http://rocketmq.apache.org/
  优缺点
  优点。阿里开源的一款的消息中间件, 纯Java开发，具有高吞吐量、高可用性、适合大规模分布式系统应用的特点, 性能强劲(零拷贝技术)，支持海量堆积, 支持指定次数和时间间隔的失败消息重发,支持consumer端tag过滤、延迟消息等，在阿里内部进行大规模使用，适合在电商，互联网金融等领域使用
  缺点：部分实现不是按照标准JMS规范，有些系统要迁移或者引入队列需要修改代码

* **mq使用场景和要考虑的问题**

  [参考](https://www.huaweicloud.com/articles/d39984b7249c2eb3f1dc4973e621d1d6.html)

## nginx

* **反向代理和负载均衡**

  什么是正向代理和反向代理？
  正向代理就是一个人发送一个请求直接就到达了目标的服务器
  反方代理就是请求统一被Nginx接收，nginx反向代理服务器接收到之后，按照一定的规 则分发给了后端的业务处理服务器进行处理了

  使用“反向代理服务器的优点是什么?
  反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和web服务器之间的中间层。这对于安全方面来说是很好的，特别是当您使用web托管服务时。

  负载均衡策略：

  1.轮询（默认）

  2.权重weight

  3.ip_hash：能有效解决session共享的问题。

  4.fair（第三方插件）：对比 weight、ip_hash更加智能的负载均衡算法，fair算法可以根据页面大小和加载时间长短智能地进行负载均衡，响应时间短的优先分配。

  5.url_hash(第三方插件)

## maven

* **怎么解决循环依赖、依赖冲突**

  通过idea，把重复的删掉。

* maven的生命周期：

  clean compile test package install deploy

## 设计模式

* **说一下熟悉的设计模式**

  * 单例模式

  饿汉式：没有线程安全问题，没有懒加载，成员变量少的时候，性能还可以；

  懒汉式：有线程安全问题，通过DCL解决。

  ![img](https://qqadapt.qpic.cn/txdocpic/0/87b4209a6eee4ffb2bd083bd9ac1b06d/0?_type=png&w=621&h=345)

* **简单工厂和抽象工厂的区别**

## 数据结构和算法

* **红黑的实现原理和场景**
* **给你两个二叉搜索树，如何使用线性的时间复杂度，将他们合并成一颗二叉搜索树**
* **给定一个二叉搜索树，编写一个函数kthSmallest来查找其中第k个最小的元素**
* **给定一个二叉树，找到该树中两个指定节点的最近公共祖先**
* **二叉树的序列号和反序列化**
* **如何找出一个单项链表的中间元素**
* **写一个函数，打印树的中序遍历**
* **用java写一个方法，判断一个树是否是二叉搜索树**
* **用java写一个方法，判断一个树是否是平衡树**
* **用java实现二分搜索算法**
* **用java实现插入排序**
* **用java实现冒泡排序**
* **实现从一个数组中移除重复元素**
* **如何找出最大和最小的数在一个数组中**
* **为什么char数组能比String更好的去存储password**
* **给你一个长度为n的数组，其中只有一个数字出现了奇数次，其他均出现偶数次，问，如何使用优秀的时空复杂度快速找到这个数字**
* **给你一个长度为n的数组，其中只有一个数字出现了大于等于n/2次，问，如何使用优秀的时空复杂度快速找到这个数字**
* **一个包含1-100数字的数组中，有一个数字丢失了，如何快速找出它**
